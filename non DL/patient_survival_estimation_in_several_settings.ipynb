{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Na3gkP9YSJpY"
      },
      "source": [
        "Content :\n",
        "\n",
        "- **A.** survival estimation based on general population survival information using linear and non-linear models calculated only for one static time stamp.\n",
        "\n",
        "- **B.** survival estimation for continuous time period still based on population trends.\n",
        "\n",
        "- **C.** individualised survival estimation for continuous time with linear and non-linear models\n",
        "\n",
        "</br>\n",
        "\n",
        "All used data is available here: \n",
        "1. https://drive.google.com/file/d/1eM02JjvUuMblT652Flyp0XHDWTi7G_rQ/view?usp=sharing \n",
        "2. https://drive.google.com/file/d/1kC9EyOqqiWFd2_j5BeedBZry6kJlPemI/view?usp=sharing "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6NzLKfypU5KJ"
      },
      "source": [
        "# **A.1.** Build and Evaluate a Linear Risk model\n",
        "\n",
        "Welcome to the first assignment in Course 2!\n",
        "\n",
        "In this assignment, you'll build a risk score model for retinopathy in diabetes patients using logistic regression.\n",
        "\n",
        "As we develop the model, we will learn about the following topics:\n",
        "\n",
        "- Data preprocessing\n",
        "  - Log transformations\n",
        "  - Standardization\n",
        "- Basic Risk Models\n",
        "  - Logistic Regression\n",
        "  - C-index\n",
        "  - Interactions Terms\n",
        "  \n",
        "### Diabetic Retinopathy\n",
        "Retinopathy is an eye condition that causes changes to the blood vessels in the part of the eye called the retina.\n",
        "This often leads to vision changes or blindness.\n",
        "Diabetic patients are known to be at high risk for retinopathy. \n",
        "    \n",
        "### Logistic Regression    \n",
        "Logistic regression is an appropriate analysis to use for predicting the probability of a binary outcome. In our case, this would be the probability of having or not having diabetic retinopathy.\n",
        "Logistic Regression is one of the most commonly used algorithms for binary classification. It is used to find the best fitting model to describe the relationship between a set of features (also referred to as input, independent, predictor, or explanatory variables) and a binary outcome label (also referred to as an output, dependent, or response variable). Logistic regression has the property that the output prediction is always in the range $[0,1]$. Sometimes this output is used to represent a probability from 0%-100%, but for straight binary classification, the output is converted to either $0$ or $1$ depending on whether it is below or above a certain threshold, usually $0.5$.\n",
        "\n",
        "It may be  confusing that the term regression appears in the name even though logistic regression is actually a classification algorithm, but that's just a name it was given for historical reasons."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BIxEItDU5Kc"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [1. Import Packages](#1)\n",
        "- [2. Load Data](#2)\n",
        "- [3. Explore the Dataset](#3)\n",
        "- [4. Mean-Normalize the Data](#4)\n",
        "    - [Exercise 1 - make_standard_normal](#ex-1)\n",
        "- [5. Build the Model](#5)\n",
        "    - [Exercise 2 - lr_model](#ex-2)\n",
        "- [6. Evaluate the Model Using the C-Index](#6)\n",
        "    - [Exercise 3 - cindex](#ex-3)\n",
        "- [7. Evaluate the Model on the Test Set](#7)\n",
        "- [8. Improve the Model](#8)\n",
        "    - [Exercise 4 - add_interactions](#ex-4)\n",
        "- [9. Evalute the Improved Model](#9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DU20mFeib5Kd"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1.  Import Packages\n",
        "\n",
        "We'll first import all the packages that we need for this assignment. \n",
        "\n",
        "- `numpy` is the fundamental package for scientific computing in python.\n",
        "- `pandas` is what we'll use to manipulate our data.\n",
        "- `matplotlib` is a plotting library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qHjB-KVmwmtR"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from IPython.display import display\n",
        "\n",
        "import sklearn\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_kOKvTVzWTMn"
      },
      "outputs": [],
      "source": [
        "#@title helper functions\n",
        "\n",
        "\n",
        "def generate_data(n=200):\n",
        "    df = pd.DataFrame(\n",
        "        columns=['Age', 'Systolic_BP', 'Diastolic_BP', 'Cholesterol']\n",
        "    )\n",
        "    df.loc[:, 'Age'] = np.exp(np.log(60) + (1 / 7) * np.random.normal(size=n))\n",
        "    df.loc[:, ['Systolic_BP', 'Diastolic_BP', 'Cholesterol']] = np.exp(\n",
        "        np.random.multivariate_normal(\n",
        "            mean=[np.log(100), np.log(90), np.log(100)],\n",
        "            cov=(1 / 45) * np.array([\n",
        "                [0.5, 0.2, 0.2],\n",
        "                [0.2, 0.5, 0.2],\n",
        "                [0.2, 0.2, 0.5]]),\n",
        "            size=n))\n",
        "    return df\n",
        "\n",
        "\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "\n",
        "def f(x):\n",
        "    p = 0.4 * (np.log(x[0]) - np.log(60)) + 0.33 * (\n",
        "            np.log(x[1]) - np.log(100)) + 0.3 * (\n",
        "                np.log(x[3]) - np.log(100)) - 2.0 * (\n",
        "                np.log(x[0]) - np.log(60)) * (\n",
        "                np.log(x[3]) - np.log(100)) + 0.05 * np.random.logistic()\n",
        "    if p > 0.0:\n",
        "        return 1.0\n",
        "    else:\n",
        "        return 0.0\n",
        "\n",
        "\n",
        "def load_data(n=200):\n",
        "    np.random.seed(0)\n",
        "    df = generate_data(n)\n",
        "    for i in range(len(df)):\n",
        "        df.loc[i, 'y'] = f(df.loc[i, :])\n",
        "        X = df.drop('y', axis=1)\n",
        "        y = df.y\n",
        "    return X, y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_bMe2McWezG"
      },
      "outputs": [],
      "source": [
        "#@title tests\n",
        "\n",
        "### tests for helper functions\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "def datatype_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += datatype_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}. Got {} but expected type {}\".format(error,\n",
        "                                                                          key, type(target_output[key]), type(expected_output[key])))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += datatype_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}, Got {}  but expected type {}\".format(error,\n",
        "                                                                          i, type(target_output[i]), type(expected_output[i])))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        assert isinstance(target_output, type(expected_output))\n",
        "        return 1\n",
        "            \n",
        "def equation_output_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += equation_output_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(expected_output[key], \n",
        "                                         target_output[key])\n",
        "                print(\"Error: {} for variable {}.\".format(error,\n",
        "                                                                          key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += equation_output_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable in position {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            np.testing.assert_array_almost_equal(target_output, expected_output)\n",
        "        else:\n",
        "            assert target_output == expected_output\n",
        "        return 1\n",
        "    \n",
        "def shape_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += shape_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += shape_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            assert target_output.shape == expected_output.shape\n",
        "        return 1\n",
        "                \n",
        "def multiple_test(test_cases, target):\n",
        "    success = 0\n",
        "    for test_case in test_cases:\n",
        "        try:\n",
        "            target_answer = target(*test_case['input'])\n",
        "            if test_case['name'] == \"datatype_check\":\n",
        "                success += datatype_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"equation_output_check\":\n",
        "                success += equation_output_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"shape_check\":\n",
        "                success += shape_check(test_case['expected'], target_answer, test_case['error'])\n",
        "        except:\n",
        "            print(\"Error: \" + test_case['error'])\n",
        "            \n",
        "    if success == len(test_cases):\n",
        "        print(\"\\033[92m All tests passed.\")\n",
        "    else:\n",
        "        print('\\033[92m', success,\" Tests passed\")\n",
        "        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n",
        "        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n",
        "\n",
        "\n",
        "### general tests\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "### ex1\n",
        "def make_standard_normal_test_case():\n",
        "    tmp_train = pd.DataFrame({'field1': [1,2,10], 'field2': [4,5,11]})\n",
        "    tmp_test = pd.DataFrame({'field1': [1,3,10], 'field2': [4,6,11]})\n",
        "    \n",
        "    return tmp_train, tmp_test\n",
        "\n",
        "def make_standard_normal_test(target):\n",
        "    tmp_train, tmp_test = make_standard_normal_test_case()\n",
        "    \n",
        "    print(\"Tmp Train:\\n\\n\", tmp_train, \"\\n\")\n",
        "    print(\"Tmp Test:\\n\\n\", tmp_test, \"\\n\")\n",
        "    \n",
        "    tmp_train_transformed, tmp_test_transformed = target(tmp_train,tmp_test)\n",
        "    \n",
        "    print(\"Tmp Train After Standard Normal:\\n\\n\", tmp_train_transformed, \"\\n\")\n",
        "    print(\"Tmp Test After Standard Normal:\\n\\n\", tmp_test_transformed, \"\\n\")\n",
        "    \n",
        "    print(f\"Training set transformed field1 has mean {tmp_train_transformed['field1'].mean(axis=0)} and standard deviation {tmp_train_transformed['field1'].std(axis=0):.4f} \")\n",
        "    print(f\"Test set transformed, field1 has mean {tmp_test_transformed['field1'].mean(axis=0)} and standard deviation {tmp_test_transformed['field1'].std(axis=0):.4f}\")\n",
        "    print(f\"Skew of training set field1 before transformation: {tmp_train['field1'].skew(axis=0)}\")\n",
        "    print(f\"Skew of training set field1 after transformation: {tmp_train_transformed['field1'].skew(axis=0)}\")\n",
        "    print(f\"Skew of test set field1 before transformation: {tmp_test['field1'].skew(axis=0)}\")\n",
        "    print(f\"Skew of test set field1 after transformation: {tmp_test_transformed['field1'].skew(axis=0)}\\n\")\n",
        "    \n",
        "    def test_target(tmp_train_transformed, tmp_test_transformed):\n",
        "        \n",
        "        return tmp_train_transformed['field1'].mean(axis=0), tmp_test_transformed['field1'].mean(axis=0), tmp_train['field1'].skew(axis=0), tmp_train_transformed['field1'].skew(axis=0), tmp_test['field1'].skew(axis=0), tmp_test_transformed['field1'].skew(axis=0)\n",
        "        \n",
        "    expected_output = (np.array([-7.401486830834377e-17, 0.11441332564321975, 1.6523167403329906, 1.0857243344604632, 1.3896361387064917, 0.13709698849045696]))\n",
        "    \n",
        "    \n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [tmp_train_transformed, tmp_test_transformed],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Data-type mismatch.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [tmp_train_transformed, tmp_test_transformed],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong shape.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [tmp_train_transformed, tmp_test_transformed],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong output.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, test_target)\n",
        "    \n",
        "\n",
        "\n",
        "##############################################        \n",
        "### ex2\n",
        "def lr_model_test(target, X_train, y_train):\n",
        "    tmp_model = target(X_train[0:3], y_train[0:3])\n",
        "    \n",
        "    \n",
        "    def test_target(tmp_model):\n",
        "        return tmp_model.predict(X_train[4:5]), tmp_model.predict(X_train[5:6])\n",
        "      \n",
        "    # Output for learner\n",
        "    x, y = test_target(tmp_model)\n",
        "    print('X_train[4:5] value:',x,'\\nX_train[5:6] value:',y, \"\\n\")\n",
        "\n",
        "    expected_output = (np.array([1.]), np.array([1.]))\n",
        "\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [tmp_model],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Data-type mismatch.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [tmp_model],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong shape.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [tmp_model],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong output.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, test_target)\n",
        "\n",
        "\n",
        "##############################################        \n",
        "### ex3\n",
        "\n",
        "def cindex_test_case():\n",
        "    y_true = np.array([1.0, 0.0, 0.0, 1.0])\n",
        "    scores_1 = np.array([0, 1, 1, 0])\n",
        "    scores_2 = np.array([1, 0, 0, 1])\n",
        "    scores_3 = np.array([0.5, 0.5, 0.0, 1.0])\n",
        "    \n",
        "    return y_true, scores_1, scores_2, scores_3 \n",
        "\n",
        "def cindex_test(target):\n",
        "    y_true, scores_1, scores_2, scores_3 = cindex_test_case()\n",
        "    \n",
        "    print(\"Test Case 1:\\n\")\n",
        "    print(\"Y_true: \", y_true)\n",
        "    print(\"Scores: \", scores_1)\n",
        "    print(\"cindex for test case 1: \", target(y_true, scores_1))\n",
        "    \n",
        "    print(\"\\nTest Case 2:\\n\")\n",
        "    print(\"Y_true: \", y_true)\n",
        "    print(\"Scores: \", scores_2)\n",
        "    print(\"cindex for test case 2: \", target(y_true, scores_2))\n",
        "    \n",
        "    print(\"\\nTest Case 3:\\n\")\n",
        "    print(\"Y_true: \", y_true)\n",
        "    print(\"Scores: \", scores_3)\n",
        "    print(\"cindex for test case 3: \", target(y_true, scores_3), \"\\n\")\n",
        "     \n",
        "    \n",
        "    expected_output_1 = 0.0\n",
        "    expected_output_2 = 1.0\n",
        "    expected_output_3 = 0.875\n",
        "    \n",
        "    \n",
        "    ### test cases\n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [y_true, scores_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Data-type mismatch for test case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [y_true, scores_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Wrong shape for test case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true, scores_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Wrong output for test case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true, scores_2],\n",
        "            \"expected\": expected_output_2,\n",
        "            \"error\": \"Wrong output for test case 2.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true, scores_3],\n",
        "            \"expected\": expected_output_3,\n",
        "            \"error\": \"Wrong output for test case 3.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, target)\n",
        "        \n",
        "\n",
        "##############################################    \n",
        "### ex4\n",
        "def add_interactions_test(target, X_train):\n",
        "    print(\"Original Data\\n\")\n",
        "    print(X_train.loc[:, ['Age', 'Systolic_BP']].head())\n",
        "    print(\"\\nData with Interactions\\n\")\n",
        "    print(target(X_train.loc[:, ['Age', 'Systolic_BP']].head()), \"\\n\")\n",
        "    \n",
        "    \n",
        "    def test_target(X_train,target):\n",
        "        tmp_df = target(X_train.loc[:, ['Age', 'Systolic_BP']].head())\n",
        "        return tuple(tmp_df['Age_x_Systolic_BP'])\n",
        "    \n",
        "    expected_output = (0.062064, -0.519367, 0.401800, -2.366725, 0.024344) \n",
        "        \n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [X_train,target],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Data-type mismatch.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [X_train,target],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong shape.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [X_train,target],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong output.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, test_target)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3J7NXuQadLnY"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2. Load Data\n",
        "\n",
        "First we will load in the dataset that we will use for training and testing our model.\n",
        "\n",
        "- Run the next cell to load the data that is stored in csv files.\n",
        "- There is a function `load_data` which randomly generates data, but for consistency, please use the data from the csv files."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FN5Y5hU5yXnE"
      },
      "outputs": [],
      "source": [
        "# This function creates randomly generated data\n",
        "# X, y = load_data(6000)\n",
        "\n",
        "# For stability, load data from files that were generated using the load_data\n",
        "X = pd.read_csv('./X_data.csv',index_col=0)\n",
        "y_df = pd.read_csv('./y_data.csv',index_col=0)\n",
        "y = y_df['y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5yF06E6sZMmD"
      },
      "source": [
        "`X` and `y` are Pandas DataFrames that hold the data for 6,000 diabetic patients. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOc63sByU5Ks"
      },
      "source": [
        "<a name='3'></a>\n",
        "##  3. Explore the Dataset\n",
        "\n",
        "The features (`X`) include the following fields:\n",
        "* Age: (years)\n",
        "* Systolic_BP: Systolic blood pressure (mmHg)\n",
        "* Diastolic_BP: Diastolic blood pressure (mmHg)\n",
        "* Cholesterol: (mg/DL)\n",
        "    \n",
        "We can use the `head()` method to display the first few records of each.    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "qp1SgI7PT024",
        "outputId": "c0297341-6c4d-4744-eb98-e6e0d815bac1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-51bdaf18-1770-40d8-aa26-c593f7ac1b5b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Systolic_BP</th>\n",
              "      <th>Diastolic_BP</th>\n",
              "      <th>Cholesterol</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>77.196340</td>\n",
              "      <td>85.288742</td>\n",
              "      <td>80.021878</td>\n",
              "      <td>79.957109</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>63.529850</td>\n",
              "      <td>99.379736</td>\n",
              "      <td>84.852361</td>\n",
              "      <td>110.382411</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>69.003986</td>\n",
              "      <td>111.349455</td>\n",
              "      <td>109.850616</td>\n",
              "      <td>100.828246</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>82.638210</td>\n",
              "      <td>95.056128</td>\n",
              "      <td>79.666851</td>\n",
              "      <td>87.066303</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>78.346286</td>\n",
              "      <td>109.154591</td>\n",
              "      <td>90.713220</td>\n",
              "      <td>92.511770</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51bdaf18-1770-40d8-aa26-c593f7ac1b5b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51bdaf18-1770-40d8-aa26-c593f7ac1b5b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51bdaf18-1770-40d8-aa26-c593f7ac1b5b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "         Age  Systolic_BP  Diastolic_BP  Cholesterol\n",
              "0  77.196340    85.288742     80.021878    79.957109\n",
              "1  63.529850    99.379736     84.852361   110.382411\n",
              "2  69.003986   111.349455    109.850616   100.828246\n",
              "3  82.638210    95.056128     79.666851    87.066303\n",
              "4  78.346286   109.154591     90.713220    92.511770"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0o8DaDayXnM"
      },
      "source": [
        "The target (`y`) is an indicator of whether or not the patient developed retinopathy.\n",
        "\n",
        "* y = 1 : patient has retinopathy.\n",
        "* y = 0 : patient does not have retinopathy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2d6L8BHO3-QJ",
        "outputId": "0a4f51e4-8427-4368-eda3-7f0e9c9087fd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0    1.0\n",
              "1    1.0\n",
              "2    1.0\n",
              "3    1.0\n",
              "4    1.0\n",
              "Name: y, dtype: float64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DAobb_-hFtAn"
      },
      "source": [
        "Before we build a model, let's take a closer look at the distribution of our training data. To do this, we will split the data into train and test sets using a 75/25 split.\n",
        "\n",
        "For this, we can use the built in function provided by sklearn library.  See the documentation for [sklearn.model_selection.train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C9FxG6hDyXnQ"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fvqevMtFsHh"
      },
      "outputs": [],
      "source": [
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, train_size=0.75, random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYgcS0vjdbpc"
      },
      "source": [
        "Plot the histograms of each column of `X_train` below: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "EBckdYHyUudi",
        "outputId": "bfdf98c4-fb7c-48f9-c56e-34eae2873eed"
      },
      "outputs": [],
      "source": [
        "for col in X.columns:\n",
        "    X_train_raw.loc[:, col].hist()\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5TpFQyjuU5K5"
      },
      "source": [
        "As we can see, the distributions have a generally bell shaped distribution, but with slight rightward skew.\n",
        "\n",
        "Many statistical models assume that the data is normally distributed, forming a symmetric Gaussian bell shape (with no skew) more like the example below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "UhVpI4DgU5K6",
        "outputId": "99723301-2145-4295-d23b-9af8731c8550"
      },
      "outputs": [],
      "source": [
        "from scipy.stats import norm\n",
        "data = np.random.normal(50,12, 5000)\n",
        "fitting_params = norm.fit(data)\n",
        "norm_dist_fitted = norm(*fitting_params)\n",
        "t = np.linspace(0,100, 100)\n",
        "plt.hist(data, bins=60, density=True)\n",
        "plt.plot(t, norm_dist_fitted.pdf(t))\n",
        "plt.title('Example of Normally Distributed Data')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jhZ3UKs3U-FG"
      },
      "source": [
        "We can transform our data to be closer to a normal distribution by removing the skew. One way to remove the skew is by applying the log function to the data.\n",
        "\n",
        "Let's plot the log of the feature variables to see that it produces the desired effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r3fiFAipU9nm",
        "outputId": "a3028329-90eb-4e3c-e792-40d68ff9eeee"
      },
      "outputs": [],
      "source": [
        "for col in X_train_raw.columns:\n",
        "    np.log(X_train_raw.loc[:, col]).hist()\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "84vqBnYZT80j"
      },
      "source": [
        "We can see that the data is more symmetric after taking the log."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gnj1zUmaG94h"
      },
      "source": [
        "<a name='4'></a>\n",
        "## 4. Mean-Normalize the Data\n",
        "\n",
        "Let's now transform our data so that the distributions are closer to standard normal distributions.\n",
        "\n",
        "First we will remove some of the skew from the distribution by using the log transformation.\n",
        "Then we will \"standardize\" the distribution so that it has a mean of zero and standard deviation of 1. Recall that a standard normal distribution has mean of zero and standard deviation of 1. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwFX_KTuU5K8"
      },
      "source": [
        "<a name='ex-1'></a>\n",
        "### Exercise 1 - make_standard_normal\n",
        "* Write a function that first removes some of the skew in the data, and then standardizes the distribution so that for each data point $x$,\n",
        "$$\\overline{x} = \\frac{x - mean(x)}{std(x)}$$\n",
        "* Keep in mind that we want to pretend that the test data is \"unseen\" data. \n",
        "    * This implies that it is unavailable to us for the purpose of preparing our data, and so we do not want to consider it when evaluating the mean and standard deviation that we use in the above equation. Instead we want to calculate these values using the training data alone, but then use them for standardizing both the training and the test data.\n",
        "    * For a further discussion on the topic, see this article [\"Why do we need to re-use training parameters to transform test data\"](https://sebastianraschka.com/faq/docs/scale-training-test.html). "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRC-CM9aU5K9"
      },
      "source": [
        "#### Note\n",
        "- For the sample standard deviation, please calculate the unbiased estimator:\n",
        "$$s = \\sqrt{\\frac{\\sum_{i=1}^n(x_{i} - \\bar{x})^2}{n-1}}$$\n",
        "- In other words, if you numpy, set the degrees of freedom `ddof` to 1.\n",
        "- For pandas, the default `ddof` is already set to 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EFoUE5BU5K9"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "    <ul>\n",
        "        <li> When working with Pandas DataFrames, you can use the aggregation functions <code>mean</code> and <code>std</code> functions. Note that in order to apply an aggregation function separately for each row or each column, you'll set the axis parameter to either 0 or 1. One produces the aggregation along columns and the other along rows, but it is easy to get them confused. So experiment with each option below to see which one you should use to get an average for each column in the dataframe.\n",
        "<code>\n",
        "avg = df.mean(axis=0)\n",
        "avg = df.mean(axis=1) \n",
        "</code>\n",
        "        </li>\n",
        "        <li>Remember to use **training** data statistics when standardizing both the training and the test data.</li>\n",
        "    </ul>\n",
        "</p>\n",
        "</details> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wwqPOiZGRfhv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def make_standard_normal(df_train, df_test):\n",
        "    \"\"\"\n",
        "    In order to make the data closer to a normal distribution, take log\n",
        "    transforms to reduce the skew.\n",
        "    Then standardize the distribution with a mean of zero and standard deviation of 1. \n",
        "  \n",
        "    Args:\n",
        "      df_train (dataframe): unnormalized training data.\n",
        "      df_test (dataframe): unnormalized test data.\n",
        "  \n",
        "    Returns:\n",
        "      df_train_normalized (dateframe): normalized training data.\n",
        "      df_test_normalized (dataframe): normalized test data.\n",
        "    \"\"\"\n",
        "    \n",
        "    # Remove skew by applying the log function to the train set, and to the test set\n",
        "    df_train_unskewed = np.log(df_train)\n",
        "    df_test_unskewed = np.log(df_test)\n",
        "    \n",
        "    #calculate the mean and standard deviation of the training set\n",
        "    mean = df_train_unskewed.mean(axis=0)\n",
        "    stdev = df_train_unskewed.std(axis=0)\n",
        "    \n",
        "    # standardize the training set\n",
        "    df_train_standardized = (df_train_unskewed - mean) / stdev\n",
        "    \n",
        "    # standardize the test set (see instructions and hints above)\n",
        "    df_test_standardized = (df_test_unskewed - mean) / stdev\n",
        "\n",
        "    return df_train_standardized, df_test_standardized"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LeMVPQZU5K-",
        "outputId": "afff7122-cecb-4728-e4a9-610c9c7aa62b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Tmp Train:\n",
            "\n",
            "    field1  field2\n",
            "0       1       4\n",
            "1       2       5\n",
            "2      10      11 \n",
            "\n",
            "Tmp Test:\n",
            "\n",
            "    field1  field2\n",
            "0       1       4\n",
            "1       3       6\n",
            "2      10      11 \n",
            "\n",
            "Tmp Train After Standard Normal:\n",
            "\n",
            "      field1    field2\n",
            "0 -0.845330 -0.774414\n",
            "1 -0.258557 -0.354556\n",
            "2  1.103887  1.128970 \n",
            "\n",
            "Tmp Test After Standard Normal:\n",
            "\n",
            "      field1    field2\n",
            "0 -0.845330 -0.774414\n",
            "1  0.084683 -0.011508\n",
            "2  1.103887  1.128970 \n",
            "\n",
            "Training set transformed field1 has mean -7.401486830834377e-17 and standard deviation 1.0000 \n",
            "Test set transformed, field1 has mean 0.11441332564321975 and standard deviation 0.9749\n",
            "Skew of training set field1 before transformation: 1.6523167403329906\n",
            "Skew of training set field1 after transformation: 1.0857243344604632\n",
            "Skew of test set field1 before transformation: 1.3896361387064917\n",
            "Skew of test set field1 after transformation: 0.13709698849045696\n",
            "\n",
            "\u001b[92m All tests passed.\n"
          ]
        }
      ],
      "source": [
        "### test cell \n",
        "make_standard_normal_test(make_standard_normal)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XpqHiFfwyXne"
      },
      "source": [
        "#### Expected Output\n",
        "```\n",
        "Training set transformed field1 has mean -7.401486830834377e-17 and standard deviation 1.0000 \n",
        "Test set transformed, field1 has mean 0.11441332564321975 and standard deviation 0.9749\n",
        "Skew of training set field1 before transformation: 1.6523167403329906\n",
        "Skew of training set field1 after transformation: 1.0857243344604632\n",
        "Skew of test set field1 before transformation: 1.3896361387064917\n",
        "Skew of test set field1 after transformation: 0.13709698849045696\n",
        "\n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gran7yoORxQ9"
      },
      "source": [
        "#### Transform training and test data \n",
        "Use the function that you just implemented to make the data distribution closer to a standard normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDC2ThP_K3Ea"
      },
      "outputs": [],
      "source": [
        "X_train, X_test = make_standard_normal(X_train_raw, X_test_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnmdKuXDyXnk"
      },
      "source": [
        "After transforming the training and test sets, we'll expect the training set to be centered at zero with a standard deviation of $1$.\n",
        "\n",
        "We will avoid observing the test set during model training in order to avoid biasing the model training process, but let's have a look at the distributions of the transformed training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WUYtMPVyyXnk",
        "outputId": "a9745928-dd9d-4f13-edeb-fd1cb6a22ac3"
      },
      "outputs": [],
      "source": [
        "for col in X_train.columns:\n",
        "    X_train[col].hist()\n",
        "    plt.title(col)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ovLMYBz6dteZ"
      },
      "source": [
        "<a name='5'></a>\n",
        "## 5. Build the Model\n",
        "\n",
        "Now we are ready to build the risk model by training logistic regression with our data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xy2dY05LU5LB"
      },
      "source": [
        "<a name='ex-2'></a>\n",
        "### Exercise 2 - lr_model\n",
        "\n",
        "* Implement the `lr_model` function to build a model using logistic regression with the `LogisticRegression` class from `sklearn`. \n",
        "* See the documentation for [sklearn.linear_model.LogisticRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression.fit)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiKIDiIXU5LB"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "    <ul>\n",
        "        <li>You can leave all the parameters to their default values when constructing an instance of the <code>sklearn.linear_model.LogisticRegression</code> class. If you get a warning message regarding the <code>solver</code> parameter, however, you may want to specify that particular one explicitly with <code>solver='lbfgs'</code>. \n",
        "        </li>\n",
        "        <br></br>\n",
        "    </ul>\n",
        "</p>\n",
        "</details> "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iLvr0IgoyXnz"
      },
      "outputs": [],
      "source": [
        "\n",
        "def lr_model(X_train, y_train):\n",
        "    # create the model object\n",
        "    model = LogisticRegression()\n",
        "    \n",
        "    # fit the model to the training data\n",
        "    model.fit(X_train,y_train)\n",
        "    #return the fitted model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLGxKNVeU5LC"
      },
      "source": [
        "#### Test Your Work\n",
        "\n",
        "Note: the `predict` method returns the model prediction *after* converting it from a value in the $[0,1]$ range to a $0$ or $1$ depending on whether it is below or above $0.5$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Fr-HA-TyXnv",
        "outputId": "8e080603-00c7-447f-e335-8da2785a9506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train[4:5] value: [1.] \n",
            "X_train[5:6] value: [1.] \n",
            "\n",
            "\u001b[92m All tests passed.\n"
          ]
        }
      ],
      "source": [
        "### test cell \n",
        "lr_model_test(lr_model, X_train, y_train)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpafSX3tyXny"
      },
      "source": [
        "#### Expected Output\n",
        "```\n",
        "X_train[4:5] value: [1.] \n",
        "X_train[5:6] value: [1.] \n",
        "\n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FhuY1GjlyXn1"
      },
      "source": [
        "Now that we've tested our model, we can go ahead and build it. Note that the `lr_model` function also fits  the model to the training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sG6nr4hCyXn2"
      },
      "outputs": [],
      "source": [
        "model_X = lr_model(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YI34GRSgeAaL"
      },
      "source": [
        "<a name='6'></a>\n",
        "## 6. Evaluate the Model Using the C-index\n",
        "\n",
        "Now that we have a model, we need to evaluate it. We'll do this using the c-index. \n",
        "* The c-index measures the discriminatory power of a risk score. \n",
        "* Intuitively, a higher c-index indicates that the model's prediction is in agreement with the actual outcomes of a pair of patients.\n",
        "* The formula for the c-index is\n",
        "\n",
        "$$ \\mbox{cindex} = \\frac{\\mbox{concordant} + 0.5 \\times \\mbox{ties}}{\\mbox{permissible}} $$\n",
        "\n",
        "* A permissible pair is a pair of patients who have different outcomes.\n",
        "* A concordant pair is a permissible pair in which the patient with the higher risk score also has the worse outcome.\n",
        "* A tie is a permissible pair where the patients have the same risk score.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Fk1UI-3U5LF"
      },
      "source": [
        "<a name='ex-3'></a>\n",
        "### Exercise 3 - cindex\n",
        "\n",
        "* Implement the `cindex` function to compute c-index.\n",
        "* `y_true` is the array of actual patient outcomes, 0 if the patient does not eventually get the disease, and 1 if the patient eventually gets the disease.\n",
        "* `scores` is the risk score of each patient.  These provide relative measures of risk, so they can be any real numbers. By convention, they are always non-negative.\n",
        "* Here is an example of input data and how to interpret it:\n",
        "```Python\n",
        "y_true = [0,1]\n",
        "scores = [0.45, 1.25]\n",
        "```\n",
        "    * There are two patients. Index 0 of each array is associated with patient 0.  Index 1 is associated with patient 1.\n",
        "    * Patient 0 does not have the disease in the future (`y_true` is 0), and based on past information, has a risk score of 0.45.\n",
        "    * Patient 1 has the disease at some point in the future (`y_true` is 1), and based on past information, has a risk score of 1.25."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6fzYxG0R7Sp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def cindex(y_true, scores):\n",
        "    '''\n",
        "\n",
        "    Input:\n",
        "    y_true (np.array): a 1-D array of true binary outcomes (values of zero or one)\n",
        "        0: patient does not get the disease\n",
        "        1: patient does get the disease\n",
        "    scores (np.array): a 1-D array of corresponding risk scores output by the model\n",
        "\n",
        "    Output:\n",
        "    c_index (float): (concordant pairs + 0.5*ties) / number of permissible pairs\n",
        "    '''\n",
        "    n = len(y_true)\n",
        "    assert len(scores) == n\n",
        "\n",
        "    concordant = 0\n",
        "    permissible = 0\n",
        "    ties = 0\n",
        "    \n",
        "    # use two nested for loops to go through all unique pairs of patients\n",
        "    for i in range(n):\n",
        "        for j in range(i+1, n): #choose the range of j so that j>i\n",
        "            \n",
        "            # Check if the pair is permissible (the patient outcomes are different)\n",
        "            if y_true[i] != y_true[j]:\n",
        "                # Count the pair if it's permissible\n",
        "                permissible =permissible + 1\n",
        "\n",
        "                # For permissible pairs, check if they are concordant or are ties\n",
        "\n",
        "                # check for ties in the score\n",
        "                if scores[i] == scores[j]:\n",
        "                    # count the tie\n",
        "                    ties = ties + 1\n",
        "                    # if it's a tie, we don't need to check patient outcomes, continue to the top of the for loop.\n",
        "                    continue\n",
        "\n",
        "                # case 1: patient i doesn't get the disease, patient j does\n",
        "                if y_true[i] == 0 and y_true[j] == 1:\n",
        "                    # Check if patient i has a lower risk score than patient j\n",
        "                    if scores[i] < scores[j]:\n",
        "                        # count the concordant pair\n",
        "                        concordant = concordant + 1\n",
        "                    # Otherwise if patient i has a higher risk score, it's not a concordant pair.\n",
        "                    # Already checked for ties earlier\n",
        "\n",
        "                # case 2: patient i gets the disease, patient j does not\n",
        "                if y_true[i] == 1 and y_true[j] == 0:\n",
        "                    # Check if patient i has a higher risk score than patient j\n",
        "                    if scores[i] > scores[j]:\n",
        "                        #count the concordant pair\n",
        "                        concordant = concordant + 1\n",
        "                    # Otherwise if patient i has a lower risk score, it's not a concordant pair.\n",
        "                    # We already checked for ties earlier\n",
        "\n",
        "    # calculate the c-index using the count of permissible pairs, concordant pairs, and tied pairs.\n",
        "    c_index = (concordant + (0.5 * ties)) / permissible\n",
        "    \n",
        "    return c_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzmPPfVQN8ET",
        "outputId": "88986d34-6cc3-41ae-d00c-dbf356630418",
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test Case 1:\n",
            "\n",
            "Y_true:  [1. 0. 0. 1.]\n",
            "Scores:  [0 1 1 0]\n",
            "cindex for test case 1:  0.0\n",
            "\n",
            "Test Case 2:\n",
            "\n",
            "Y_true:  [1. 0. 0. 1.]\n",
            "Scores:  [1 0 0 1]\n",
            "cindex for test case 2:  1.0\n",
            "\n",
            "Test Case 3:\n",
            "\n",
            "Y_true:  [1. 0. 0. 1.]\n",
            "Scores:  [0.5 0.5 0.  1. ]\n",
            "cindex for test case 3:  0.875 \n",
            "\n",
            "\u001b[92m All tests passed.\n"
          ]
        }
      ],
      "source": [
        "### test cell \n",
        "cindex_test(cindex)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qHKVO2ipyXoA"
      },
      "source": [
        "#### Expected Output\n",
        "\n",
        "```\n",
        "Test Case 1:\n",
        "\n",
        "cindex for test case 1:  0.0\n",
        "\n",
        "Test Case 2:\n",
        "\n",
        "cindex for test case 2:  1.0\n",
        "\n",
        "Test Case 3:\n",
        "\n",
        "cindex for test case 3:  0.875 \n",
        "\n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GOEaZigmOPVF"
      },
      "source": [
        "<a name='7'></a>\n",
        "## 7. Evaluate the Model on the Test Set\n",
        "\n",
        "Now, you can evaluate your trained model on the test set.  \n",
        "\n",
        "To get the predicted probabilities, we use the `predict_proba` method. This method will return the result from the model *before* it is converted to a binary 0 or 1. For each input case, it returns an array of two values which represent the probabilities for both the negative case (patient does not get the disease) and positive case (patient the gets the disease). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_J5TbdH_LSjB",
        "outputId": "71980a79-872f-43d8-fb1d-acd388384d71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c-index on test set is 0.8182\n"
          ]
        }
      ],
      "source": [
        "scores = model_X.predict_proba(X_test)[:, 1]\n",
        "c_index_X_test = cindex(y_test.values, scores)\n",
        "print(f\"c-index on test set is {c_index_X_test:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Iy7rIiyyXoD"
      },
      "source": [
        "#### Expected output\n",
        "```CPP\n",
        "c-index on test set is 0.8182\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-BC_HAM6MXWU"
      },
      "source": [
        "Let's plot the coefficients to see which variables (patient features) are having the most effect. You can access the model coefficients by using `model.coef_`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "lZeo6AJbMdCq",
        "outputId": "507dfaee-fd4d-48dd-80d5-d94b64c045d0"
      },
      "outputs": [],
      "source": [
        "coeffs = pd.DataFrame(data = model_X.coef_, columns = X_train.columns)\n",
        "coeffs.T.plot.bar(legend=None);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3n-i3VOwU5LI"
      },
      "source": [
        "### Question: \n",
        "> __Which three variables have the largest impact on the model's predictions?__"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KbLT-zkNgLT"
      },
      "source": [
        "<a name='8'></a>\n",
        "## 8. Improve the Model\n",
        "\n",
        "You can try to improve your model by including interaction terms. \n",
        "* An interaction term is the product of two variables. \n",
        "    * For example, if we have data \n",
        "    $$ x = [x_1, x_2]$$\n",
        "    * We could add the product so that:\n",
        "    $$ \\hat{x} = [x_1, x_2, x_1*x_2]$$\n",
        "    \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJlZn2wzU5LJ"
      },
      "source": [
        "<a name='ex-4'></a>\n",
        "### Exercise 4 - add_interactions\n",
        "\n",
        "Write code below to add all interactions between every pair of variables to the training and test datasets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "biuVl-lGSaJp"
      },
      "outputs": [],
      "source": [
        "\n",
        "def add_interactions(X):\n",
        "    \"\"\"\n",
        "    Add interaction terms between columns to dataframe.\n",
        "\n",
        "    Args:\n",
        "    X (dataframe): Original data\n",
        "\n",
        "    Returns:\n",
        "    X_int (dataframe): Original data with interaction terms appended. \n",
        "    \"\"\"\n",
        "    features = X.columns\n",
        "    m = len(features)\n",
        "    X_int = X.copy(deep=True)\n",
        "\n",
        "    # 'i' loops through all features in the original dataframe X\n",
        "    for i in range(m):\n",
        "          \n",
        "          # get the name of feature 'i'\n",
        "          feature_i_name = features[i]\n",
        "          \n",
        "          # get the data for feature 'i'\n",
        "          feature_i_data = X[feature_i_name]\n",
        "          \n",
        "          # choose the index of column 'j' to be greater than column i\n",
        "          for j in range(i+1, m):\n",
        "              \n",
        "              # get the name of feature 'j'\n",
        "              feature_j_name = features[j]\n",
        "              \n",
        "              # get the data for feature j'\n",
        "              feature_j_data = X[feature_j_name]\n",
        "              \n",
        "              # create the name of the interaction feature by combining both names\n",
        "              # example: \"apple\" and \"orange\" are combined to be \"apple_x_orange\"\n",
        "              feature_i_j_name = f\"{feature_i_name}_x_{feature_j_name}\"\n",
        "              \n",
        "              # Multiply the data for feature 'i' and feature 'j'\n",
        "              # store the result as a column in dataframe X_int\n",
        "              X_int[feature_i_j_name] = feature_i_data[::-1] * feature_j_data[::-1]\n",
        "\n",
        "    return X_int"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x5Q7eUpBcyLG"
      },
      "outputs": [],
      "source": [
        "### this test needs adjustment - it tries to compare results in different formats\n",
        "### which causes exactly same target and calculated numeric results not to be a match\n",
        "# add_interactions_test(add_interactions, X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGLzRH44U5LK"
      },
      "source": [
        "#### Expected Output\n",
        "```\n",
        "Original Data\n",
        "\n",
        "           Age  Systolic_BP\n",
        "1824 -0.912451    -0.068019\n",
        "253  -0.302039     1.719538\n",
        "1114  2.576274     0.155962\n",
        "3220  1.163621    -2.033931\n",
        "2108 -0.446238    -0.054554\n",
        "\n",
        "Data with Interactions\n",
        "\n",
        "           Age  Systolic_BP  Age_x_Systolic_BP\n",
        "1824 -0.912451    -0.068019           0.062064\n",
        "253  -0.302039     1.719538          -0.519367\n",
        "1114  2.576274     0.155962           0.401800\n",
        "3220  1.163621    -2.033931          -2.366725\n",
        "2108 -0.446238    -0.054554           0.024344\n",
        " \n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rKKiFF5Pdwtv"
      },
      "source": [
        "Once you have correctly implemented `add_interactions`, use it to make transformed version of `X_train` and `X_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYcDf7nsd2nh"
      },
      "outputs": [],
      "source": [
        "X_train_int = add_interactions(X_train)\n",
        "X_test_int = add_interactions(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6IgFZWxLqTa"
      },
      "source": [
        "<a name='9'></a>\n",
        "## 9. Evaluate the Improved Model\n",
        "\n",
        "Now we can train the new and improved version of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VBIl4ngwU5LL"
      },
      "outputs": [],
      "source": [
        "model_X_int = lr_model(X_train_int, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcWFDeD2U5LM"
      },
      "source": [
        "Let's evaluate our new model on the test set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn7U6_bEfWKI",
        "outputId": "ddba4710-a4c2-42e4-aac8-7d01356e83c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "c-index on test set without interactions is 0.8182\n",
            "c-index on test set with interactions is 0.8281\n"
          ]
        }
      ],
      "source": [
        "scores_X = model_X.predict_proba(X_test)[:, 1]\n",
        "c_index_X_int_test = cindex(y_test.values, scores_X)\n",
        "\n",
        "scores_X_int = model_X_int.predict_proba(X_test_int)[:, 1]\n",
        "c_index_X_int_test = cindex(y_test.values, scores_X_int)\n",
        "\n",
        "print(f\"c-index on test set without interactions is {c_index_X_test:.4f}\")\n",
        "print(f\"c-index on test set with interactions is {c_index_X_int_test:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-tYVyw-6jLfV"
      },
      "source": [
        "You should see that the model with interaction terms performs a bit better than the model without interactions.\n",
        "\n",
        "Now let's take another look at the model coefficients to try and see which variables made a difference. Plot the coefficients and report which features seem to be the most important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 389
        },
        "id": "9PpyFFqFjRpW",
        "outputId": "ea2b1a29-f068-41d0-88b6-7909c0c4e192"
      },
      "outputs": [],
      "source": [
        "int_coeffs = pd.DataFrame(data = model_X_int.coef_, columns = X_train_int.columns)\n",
        "int_coeffs.T.plot.bar();"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bvx65OqOCUT"
      },
      "source": [
        "### Questions:\n",
        "> __Which variables are most important to the model?__<br>\n",
        "> __Have the relevant variables changed?__<br>\n",
        "> __What does it mean when the coefficients are positive or negative?__<br>\n",
        "\n",
        "You may notice that Age, Systolic_BP, and Cholesterol have a positive coefficient. This means that a higher value in these three features leads to a higher prediction probability for the disease. You also may notice that the interaction of Age x Cholesterol has a negative coefficient. This means that a higher value for the Age x Cholesterol product reduces the prediction probability for the disease.\n",
        "\n",
        "To understand the effect of interaction terms, let's compare the output of the model we've trained on sample cases with and without the interaction. Run the cell below to choose an index and look at the features corresponding to that case in the training set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xj8v7ZxSShC7",
        "outputId": "2c7878ed-ea95-44fe-846e-b3c9ca36c4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Age                           2.502061\n",
            "Systolic_BP                   1.713547\n",
            "Diastolic_BP                  0.268265\n",
            "Cholesterol                   2.146349\n",
            "Age_x_Systolic_BP             4.287400\n",
            "Age_x_Diastolic_BP            0.671216\n",
            "Age_x_Cholesterol             5.370296\n",
            "Systolic_BP_x_Diastolic_BP    0.459685\n",
            "Systolic_BP_x_Cholesterol     3.677871\n",
            "Diastolic_BP_x_Cholesterol    0.575791\n",
            "Name: 5970, dtype: float64\n"
          ]
        }
      ],
      "source": [
        "index = index = 3432\n",
        "case = X_train_int.iloc[index, :]\n",
        "print(case)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0LbyZ8a39hSw"
      },
      "source": [
        "We can see that they have above average Age and Cholesterol. We can now see what our original model would have output by zero-ing out the value for Cholesterol and Age."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HcpczwN9sB4",
        "outputId": "f8a3793a-be84-403c-c58e-6a472eabd7a2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Age                           2.502061\n",
              "Systolic_BP                   1.713547\n",
              "Diastolic_BP                  0.268265\n",
              "Cholesterol                   2.146349\n",
              "Age_x_Systolic_BP             4.287400\n",
              "Age_x_Diastolic_BP            0.671216\n",
              "Age_x_Cholesterol             0.000000\n",
              "Systolic_BP_x_Diastolic_BP    0.459685\n",
              "Systolic_BP_x_Cholesterol     3.677871\n",
              "Diastolic_BP_x_Cholesterol    0.575791\n",
              "Name: 5970, dtype: float64"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "new_case = case.copy(deep=True)\n",
        "new_case.loc[\"Age_x_Cholesterol\"] = 0\n",
        "new_case"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iasI8KMLmcPO",
        "outputId": "8752d197-8e0d-44fa-f481-5ea8af004f43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Output with interaction: \t0.9448\n",
            "Output without interaction: \t0.9965\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "print(f\"Output with interaction: \\t{model_X_int.predict_proba([case.values])[:, 1][0]:.4f}\")\n",
        "print(f\"Output without interaction: \\t{model_X_int.predict_proba([new_case.values])[:, 1][0]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCzTv5IFU5LP"
      },
      "source": [
        "#### Expected output\n",
        "```CPP\n",
        "Output with interaction: [0.94482095]\n",
        "Output without interaction: [0.99653789]\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdYQijiWnhyZ"
      },
      "source": [
        "We see that the model is less confident in its prediction with the interaction term than without (the prediction value is lower when including the interaction term). With the interaction term, the model has adjusted for the fact that the effect of high cholesterol becomes less important for older patients compared to younger patients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMWP1Iq01T3q"
      },
      "source": [
        "# **A.2.** Risk Models Using Tree-based Models\n",
        "\n",
        "Welcome to the second assignment of Course 2!\n",
        "\n",
        "\n",
        "In this assignment, you'll gain experience with tree based models by predicting the 10-year risk of death of individuals from the NHANES I epidemiology dataset (for a detailed description of this dataset you can check the [CDC Website](https://wwwn.cdc.gov/nchs/nhanes/nhefs/default.aspx/)). This is a challenging task and a great test bed for the machine learning methods we learned this week.\n",
        "\n",
        "As you go through the assignment, you'll learn about: \n",
        "\n",
        "- Dealing with Missing Data\n",
        "  - Complete Case Analysis.\n",
        "  - Imputation\n",
        "- Decision Trees\n",
        "  - Evaluation.\n",
        "  - Regularization.\n",
        "- Random Forests \n",
        "  - Hyperparameter Tuning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kT5tm3-j1T3w"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [1. Import Packages](#1)\n",
        "- [2. The Dataset](#2)\n",
        "    - [2.1 Explore the Dataset](#2-1)\n",
        "    - [2.2 Dealing with Missing Data](#2-2)\n",
        "        - [Exercise 1 - fraction_rows_missing](#ex-1)\n",
        "- [3. Decision Trees](#3)\n",
        "    - [Exercise 2 - dt_hyperparams](#ex-2)\n",
        "- [4. Random Forests](#4)\n",
        "    - [Exercise 3 - random_forest_grid_search](#ex-3)\n",
        "- [5. Imputation](#5)\n",
        "    - [5.1 Error Analysis](#5-1)\n",
        "        - [Exercise 4 - bad_subset](#ex-4)\n",
        "    - [5.2 Imputation Approaches](#5-2)\n",
        "        - [Exercise 5 - hyperparams](#ex-5)\n",
        "        - [Exercise 6 - hyperparams](#ex-6)\n",
        "- [6. Comparison](#6)\n",
        "- [7. Explanations: SHAP](#7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F6k2pItifWeK"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1. Import Packages\n",
        "\n",
        "We'll first import all the common packages that we need for this assignment. \n",
        "\n",
        "- `shap` is a library that explains predictions made by machine learning models.\n",
        "- `sklearn` is one of the most popular machine learning libraries.\n",
        "- `itertools` allows us to conveniently manipulate iterable objects such as lists.\n",
        "- `pydotplus` is used together with `IPython.display.Image` to visualize graph structures such as decision trees.\n",
        "- `numpy` is a fundamental package for scientific computing in Python.\n",
        "- `pandas` is what we'll use to manipulate our data.\n",
        "- `seaborn` is a plotting library which has some convenient functions for visualizing missing data.\n",
        "- `matplotlib` is a plotting library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vb0jYx2_444Z",
        "outputId": "80e16030-25d9-4c27-83d8-4f25428299da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m575.9/575.9 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m349.7/349.7 KB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m77.1/77.1 KB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for autograd-gamma (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q shap\n",
        "!pip install -q lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "V5s0iQ82okBv"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import lifelines\n",
        "import shap\n",
        "import six\n",
        "from six import StringIO\n",
        "import sklearn\n",
        "import itertools\n",
        "import pydotplus\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from IPython.display import Image, display \n",
        "\n",
        "from sklearn.tree import export_graphviz\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.experimental import enable_iterative_imputer\n",
        "from sklearn.impute import IterativeImputer, SimpleImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "cellView": "form",
        "id": "8EjEHAKi1j1g"
      },
      "outputs": [],
      "source": [
        "#@title helper functions\n",
        "\n",
        "\n",
        "def cindex(y_true, scores):\n",
        "    return lifelines.utils.concordance_index(y_true, scores)\n",
        "\n",
        "\n",
        "def load_data(threshold, data_x, data_y):\n",
        "    X, y = nhanesi(data_x, data_y)\n",
        "    df = X.drop([X.columns[0]], axis=1)\n",
        "    df.loc[:, 'time'] = y\n",
        "    df.loc[:, 'death'] = np.ones(len(X))\n",
        "    df.loc[df.time < 0, 'death'] = 0\n",
        "    df.loc[:, 'time'] = np.abs(df.time)\n",
        "    df = df.dropna(axis='rows')\n",
        "    mask = (df.time > threshold) | (df.death == 1)\n",
        "    df = df[mask]\n",
        "    X = df.drop(['time', 'death'], axis='columns')\n",
        "    y = df.time < threshold\n",
        "\n",
        "    X_dev, X_test, y_dev, y_test = train_test_split(X, y, test_size=0.2, random_state=10)\n",
        "    feature_y = 'Systolic BP'\n",
        "    frac = 0.7\n",
        "\n",
        "    drop_rows = X_dev.sample(frac=frac, replace=False,\n",
        "                             weights=[prob_drop(X_dev.loc[i, 'Age']) for i in\n",
        "                                      X_dev.index], random_state=10)\n",
        "    drop_rows.loc[:, feature_y] = None\n",
        "    drop_y = y_dev[drop_rows.index]\n",
        "    X_dev.loc[drop_rows.index, feature_y] = None\n",
        "\n",
        "    return X_dev, X_test, y_dev, y_test\n",
        "\n",
        "\n",
        "def prob_drop(age):\n",
        "    return 1 - (np.exp(0.25 * age - 5) / (1 + np.exp(0.25 * age - 5)))\n",
        "\n",
        "\n",
        "def nhanesi(data_x, data_y, display=False):\n",
        "    \"\"\"Same as shap, but we use local data.\"\"\"\n",
        "    X = pd.read_csv(data_x)\n",
        "    y = pd.read_csv(data_y)[\"y\"]\n",
        "    if display:\n",
        "        X_display = X.copy()\n",
        "        X_display[\"Sex\"] = [\"Male\" if v == 1 else \"Female\" for v in X[\"Sex\"]]\n",
        "        return X_display, np.array(y)\n",
        "    return X, np.array(y)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "cellView": "form",
        "id": "9wENhyLN1v4X"
      },
      "outputs": [],
      "source": [
        "#@title tests\n",
        "\n",
        "### test helper functions\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "def datatype_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += datatype_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}. Got {} but expected type {}\".format(error,\n",
        "                                                                          key, type(target_output[key]), type(expected_output[key])))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += datatype_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}, Got {}  but expected type {}\".format(error,\n",
        "                                                                          i, type(target_output[i]), type(expected_output[i])))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        assert isinstance(target_output, type(expected_output))\n",
        "        return 1\n",
        "            \n",
        "def equation_output_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += equation_output_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(expected_output[key], \n",
        "                                         target_output[key])\n",
        "                print(\"Error: {} for variable {}.\".format(error,\n",
        "                                                                          key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += equation_output_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable in position {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            np.testing.assert_array_almost_equal(target_output, expected_output)\n",
        "        else:\n",
        "            assert target_output == expected_output\n",
        "        return 1\n",
        "    \n",
        "def shape_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += shape_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += shape_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            assert target_output.shape == expected_output.shape\n",
        "        return 1\n",
        "                \n",
        "def multiple_test(test_cases, target):\n",
        "    success = 0\n",
        "    for test_case in test_cases:\n",
        "        try:\n",
        "            target_answer = target(*test_case['input'])\n",
        "            if test_case['name'] == \"datatype_check\":\n",
        "                success += datatype_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"equation_output_check\":\n",
        "                success += equation_output_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"shape_check\":\n",
        "                success += shape_check(test_case['expected'], target_answer, test_case['error'])\n",
        "        except:\n",
        "            print(\"Error: \" + test_case['error'])\n",
        "            \n",
        "    if success == len(test_cases):\n",
        "        print(\"\\033[92m All tests passed.\")\n",
        "    else:\n",
        "        print('\\033[92m', success,\" Tests passed\")\n",
        "        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n",
        "        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n",
        "\n",
        "### general tests\n",
        "\n",
        "#np.random.seed(3)\n",
        "\n",
        "### ex1\n",
        "\n",
        "def fraction_rows_missing_test_case():\n",
        "    df_test = pd.DataFrame({'a':[None, 1, 1, None], 'b':[1, None, 0, 1]})\n",
        "    \n",
        "    return df_test\n",
        "\n",
        "def fraction_rows_missing_test(target, X_train, X_val, X_test):\n",
        "    df_test = fraction_rows_missing_test_case()\n",
        "    \n",
        "    print(\"Example dataframe:\\n\\n\", df_test, \"\\n\")\n",
        "    print(\"Computed fraction missing: \", target(df_test))\n",
        "    print(\"Fraction of rows missing from X_train: \", target(X_train))\n",
        "    print(\"Fraction of rows missing from X_val: \", target(X_val))\n",
        "    print(\"Fraction of rows missing from X_test: \", target(X_test))\n",
        "    \n",
        "    expected_output = 0.75\n",
        "    \n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [df_test],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Data-type mismatch.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [df_test],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong shape.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [df_test],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong output.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, target)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YckMl2bwg5Hb"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2. The Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xrqlr_ZQhnr4"
      },
      "source": [
        "Run the next cell to load in the NHANES I epidemiology dataset. This dataset contains various features of hospital patients as well as their outcomes, i.e. whether or not they died within 10 years."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iM2qfgvUs9c_"
      },
      "outputs": [],
      "source": [
        "X_dev, X_test, y_dev, y_test = load_data(10, './NHANESI_subset_X.csv', './NHANESI_subset_y.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zFZtDE61T33"
      },
      "source": [
        "The dataset has been split into a development set (or dev set), which we will use to develop our risk models, and a test set, which we will use to test our models.\n",
        "\n",
        "We further split the dev set into a training and validation set, respectively to train and tune our models, using a 75/25 split (note that we set a random state to make this split repeatable)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "uZ7XuAq51T33"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_dev, y_dev, test_size=0.25, random_state=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6ijpFDIx_I6"
      },
      "source": [
        "<a name='2-1'></a>\n",
        "### 2.1 Explore the Dataset\n",
        "\n",
        "The first step is to familiarize yourself with the data. Run the next cell to get the size of your training set and look at a small sample. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4gvn20Gx-pF"
      },
      "outputs": [],
      "source": [
        "print(\"X_train shape: {}\".format(X_train.shape))\n",
        "X_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_q2vf4XECvg"
      },
      "source": [
        "Our targets `y` will be whether or not the target died within 10 years. Run the next cell to see the target data series."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "drkvmcbQD9S5"
      },
      "outputs": [],
      "source": [
        "y_train.head(20)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P0OwPz5xh-uS"
      },
      "source": [
        "Use the next cell to examine individual cases and familiarize yourself with the features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mms5-w98ykxM"
      },
      "outputs": [],
      "source": [
        "i = 10\n",
        "print(X_train.iloc[i,:])\n",
        "print(\"\\nDied within 10 years? {}\".format(y_train.loc[y_train.index[i]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VTEfpTXpamz"
      },
      "source": [
        "<a name='2-2'></a>\n",
        "### 2.2 Dealing with Missing Data\n",
        "\n",
        "Looking at our data in `X_train`, we see that some of the data is missing: some values in the output of the previous cell are marked as `NaN` (\"not a number\").\n",
        "\n",
        "Missing data is a common occurrence in data analysis, that can be due to a variety of reasons, such as measuring instrument malfunction, respondents not willing or not able to supply information, and errors in the data collection process.\n",
        "\n",
        "Let's examine the missing data pattern. `seaborn` is an alternative to `matplotlib` that has some convenient plotting functions for data analysis. We can use its `heatmap` function to easily visualize the missing data pattern.\n",
        "\n",
        "Run the cell below to plot the missing data: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SPNsph0HirU-"
      },
      "outputs": [],
      "source": [
        "sns.heatmap(X_train.isnull(), cbar=False)\n",
        "plt.title(\"Training\")\n",
        "plt.show()\n",
        "\n",
        "sns.heatmap(X_val.isnull(), cbar=False)\n",
        "plt.title(\"Validation\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9xHjtTU1T38"
      },
      "source": [
        "For each feature, represented as a column, values that are present are shown in black, and missing values are set in a light color.\n",
        "\n",
        "From this plot, we can see that many values are missing for systolic blood pressure (`Systolic BP`).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skXH1FO71T38"
      },
      "source": [
        "<a name='ex-1'></a>\n",
        "### Exercise 1 - fraction_rows_missing\n",
        "\n",
        "In the cell below, write a function to compute the fraction of cases with missing data. This will help us decide how we handle this missing data in the future."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jv9djGfN1T39"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li> The <code>pandas.DataFrame.isnull()</code> method is helpful in this case.</li>\n",
        "    <li> Use the <code>pandas.DataFrame.any()</code> method and set the <code>axis</code> parameter.</li>\n",
        "    <li> Divide the total number of rows with missing data by the total number of rows. Remember that in Python, <code>True</code> values are equal to 1.</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vGZsIuLE3pUU"
      },
      "outputs": [],
      "source": [
        "def fraction_rows_missing(df):\n",
        "    '''\n",
        "    Return percent of rows with any missing\n",
        "    data in the dataframe. \n",
        "    \n",
        "    Input:\n",
        "        df (dataframe): a pandas dataframe with potentially missing data\n",
        "    Output:\n",
        "        frac_missing (float): fraction of rows with missing data\n",
        "    '''\n",
        "    return sum(df.isnull().any(axis=1)) / len(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0U6tjKIkxaGy"
      },
      "outputs": [],
      "source": [
        "### test cell ex1 - do not modify this test cell   \n",
        "fraction_rows_missing_test(fraction_rows_missing, X_train, X_val, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21zosvB91T3-"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "Computed fraction missing:  0.75\n",
        "Fraction of rows missing from X_train:  0.6986594132504371\n",
        "Fraction of rows missing from X_val:  0.703962703962704\n",
        "Fraction of rows missing from X_test:  0.0\n",
        " All tests passed.\n",
        "``` "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OBXhCGRZjCzM"
      },
      "source": [
        "We see that our train and validation sets have missing values, but luckily our test set has complete cases."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvYzlx7rlG-R"
      },
      "source": [
        "As a first pass, we will begin with a **complete case analysis**, dropping all of the rows with any missing data. Run the following cell to drop these rows from our train and validation sets. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C1Ev-eq83hP_"
      },
      "outputs": [],
      "source": [
        "X_train_dropped = X_train.dropna(axis='rows')\n",
        "y_train_dropped = y_train.loc[X_train_dropped.index]\n",
        "X_val_dropped = X_val.dropna(axis='rows')\n",
        "y_val_dropped = y_val.loc[X_val_dropped.index]\n",
        "\n",
        "### Notice the new shape of X\n",
        "print(\"X_train_dropped shape: {}\".format(X_train_dropped.shape))\n",
        "X_train_dropped.head() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDVUZ810pFNQ"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3. Decision Trees\n",
        "\n",
        "Having just learned about decision trees, you choose to use a decision tree classifier. Use scikit-learn to build a decision tree for the hospital dataset using the train set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7qeLJyEpUxF"
      },
      "outputs": [],
      "source": [
        "dt = DecisionTreeClassifier(max_depth=None, random_state=10)\n",
        "dt.fit(X_train_dropped, y_train_dropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5EGqsTCp3OV"
      },
      "source": [
        "Next we will evaluate our model. We'll use C-Index for evaluation.\n",
        "\n",
        "> Remember from lesson 4 of week 1 that the C-Index evaluates the ability of a model to differentiate between different classes, by quantifying how often, when considering all pairs of patients (A, B), the model says that patient A has a higher risk score than patient B when, in the observed data, patient A actually died and patient B actually lived. In our case, our model is a binary classifier, where each risk score is either 1 (the model predicts that the patient will die) or 0 (the patient will live).\n",
        ">\n",
        "> More formally, defining _permissible pairs_ of patients as pairs where the outcomes are different, _concordant pairs_ as permissible pairs where the patient that died had a higher risk score (i.e. our model predicted 1 for the patient that died and 0 for the one that lived), and _ties_ as permissible pairs where the risk scores were equal (i.e. our model predicted 1 for both patients or 0 for both patients), the C-Index is equal to:\n",
        ">\n",
        "> $$\\text{C-Index} = \\frac{\\#\\text{concordant pairs} + 0.5\\times \\#\\text{ties}}{\\#\\text{permissible pairs}}$$\n",
        "\n",
        "Run the next cell to compute the C-Index on the train and validation set (we've given you an implementation this time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mg9WsT-pqgjZ"
      },
      "outputs": [],
      "source": [
        "y_train_preds = dt.predict_proba(X_train_dropped)[:, 1]\n",
        "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_preds)}\")\n",
        "\n",
        "\n",
        "y_val_preds = dt.predict_proba(X_val_dropped)[:, 1]\n",
        "print(f\"Val C-Index: {cindex(y_val_dropped.values, y_val_preds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJ4UtZgQqng-"
      },
      "source": [
        "Unfortunately your tree seems to be overfitting: it fits the training data so closely that it doesn't generalize well to other samples such as those from the validation set.\n",
        "\n",
        "> The training C-index comes out to 1.0 because, when initializing `DecisionTreeClasifier`, we have left `max_depth` and `min_samples_split` unspecified. The resulting decision tree will therefore keep splitting as far as it can, which pretty much guarantees a pure fit to the training data.\n",
        "\n",
        "To handle this, you can change some of the hyperparameters of our tree."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x9814SDV1T4B"
      },
      "source": [
        "<a name='ex-2'></a>\n",
        "### Exercise 2 - dt_hyperparams\n",
        "\n",
        "Try and find a set of hyperparameters that improves the generalization to the validation set and recompute the C-index. If you do it right, you should get C-index above 0.6 for the validation set. \n",
        "\n",
        "You can refer to the documentation for the sklearn [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3rs3usG1T4B"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li> Try limiting the depth of the tree (max_depth).</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kzO-2H3fzCJ2"
      },
      "source": [
        "### Experiment with different hyperparameters for the DecisionTreeClassifier\n",
        "### until you get a c-index above 0.6 for the validation set\n",
        "dt_hyperparams = {\n",
        "    # set your own hyperparameters below, such as 'min_samples_split': 1\n",
        "    \n",
        "    'None': None\n",
        "    \n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qCjI75zX1T4C"
      },
      "source": [
        "\n",
        "Run the next cell to fit and evaluate the regularized tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VJN4n1b01T4C"
      },
      "outputs": [],
      "source": [
        "dt_hyperparams = {\n",
        "    # set your own hyperparameters below, such as 'min_samples_split': 1\n",
        "    'max_depth': 3,\n",
        "}\n",
        "\n",
        "dt_reg = DecisionTreeClassifier(**dt_hyperparams, random_state=10)\n",
        "dt_reg.fit(X_train_dropped, y_train_dropped)\n",
        "\n",
        "y_train_preds = dt_reg.predict_proba(X_train_dropped)[:, 1]\n",
        "y_val_preds = dt_reg.predict_proba(X_val_dropped)[:, 1]\n",
        "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_preds)}\")\n",
        "print(f\"Val C-Index (expected > 0.6): {cindex(y_val_dropped.values, y_val_preds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SlPbPasC1T4C"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "Train C-Index > 0.6\n",
        "Val C-Index > 0.6\n",
        "```\n",
        "\n",
        "If your output is not greater than `0.6`, try changing and tweaking your hyperparameters in `Ex 2`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2ofWJB76j9B"
      },
      "source": [
        "If you used a low `max_depth` you can print the entire tree. This allows for easy interpretability. Run the next cell to print the tree splits. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GY-15i0b4MKw"
      },
      "outputs": [],
      "source": [
        "dot_data = StringIO()\n",
        "export_graphviz(dt_reg, feature_names=X_train_dropped.columns, out_file=dot_data,  \n",
        "                filled=True, rounded=True, proportion=True, special_characters=True,\n",
        "                impurity=False, class_names=['neg', 'pos'], precision=2)\n",
        "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
        "Image(graph.create_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15KWxfV11T4D"
      },
      "source": [
        "> **Overfitting, underfitting, and the bias-variance tradeoff**\n",
        ">\n",
        "> If you tested several values of `max_depth`, you may have seen that a value of `3` gives training and validation C-Indices of about `0.689` and `0.630`, and that a `max_depth` of `2` gives better agreement with values of about `0.653` and `0.607`. In the latter case, we have further reduced overfitting, at the cost of a minor loss in predictive performance.\n",
        ">\n",
        "> Contrast this with a `max_depth` value of `1`, which results in C-Indices of about `0.597` for the training set and `0.598` for the validation set: we have eliminated overfitting but with a much stronger degradation of predictive performance.\n",
        ">\n",
        "> Lower predictive performance on the training and validation sets is indicative of the model _underfitting_ the data: it neither learns enough from the training data nor is able to generalize to unseen data (the validation data in our case).\n",
        ">\n",
        "> Finding a model that minimizes and acceptably balances underfitting and overfitting (e.g. selecting the model with a `max_depth` of `2` over the other values) is a common problem in machine learning that is known as the _bias-variance tradeoff_."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3FQOUmmwtNtX"
      },
      "source": [
        "<a name='4'></a>\n",
        "## 4. Random Forests\n",
        "\n",
        "No matter how you choose hyperparameters, a single decision tree is prone to overfitting. To solve this problem, you can try **random forests**, which combine predictions from many different trees to create a robust classifier. \n",
        "\n",
        "As before, we will use scikit-learn to build a random forest for the data. We will use the default hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OKQco4cItPY2"
      },
      "outputs": [],
      "source": [
        "rf = RandomForestClassifier(n_estimators=100, random_state=10)\n",
        "rf.fit(X_train_dropped, y_train_dropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYu0LeEww2lV"
      },
      "source": [
        "Now compute and report the C-Index for the random forest on the training and validation set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ehZ4LRbw8Un",
        "outputId": "76e760ff-b13e-45bf-fc7e-1f68872fce26"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train C-Index: 1.0\n",
            "Val C-Index: 0.6660488696808511\n"
          ]
        }
      ],
      "source": [
        "y_train_rf_preds = rf.predict_proba(X_train_dropped)[:, 1]\n",
        "print(f\"Train C-Index: {cindex(y_train_dropped.values, y_train_rf_preds)}\")\n",
        "\n",
        "y_val_rf_preds = rf.predict_proba(X_val_dropped)[:, 1]\n",
        "print(f\"Val C-Index: {cindex(y_val_dropped.values, y_val_rf_preds)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkcdnwYgw80C"
      },
      "source": [
        "Training a random forest with the default hyperparameters results in a model that has better predictive performance than individual decision trees as in the previous section, but this model is overfitting.\n",
        "\n",
        "We therefore need to tune (or optimize) the hyperparameters, to find a model that both has good predictive performance and minimizes overfitting.\n",
        "\n",
        "The hyperparameters we choose to adjust will be:\n",
        "\n",
        "- `n_estimators`: the number of trees used in the forest.\n",
        "- `max_depth`: the maximum depth of each tree.\n",
        "- `min_samples_leaf`: the minimum number (if `int`) or proportion (if `float`) of samples in a leaf.\n",
        "\n",
        "The approach we implement to tune the hyperparameters is known as a grid search:\n",
        "\n",
        "- We define a set of possible values for each of the target hyperparameters.\n",
        "\n",
        "- A model is trained and evaluated for every possible combination of hyperparameters.\n",
        "\n",
        "- The best performing set of hyperparameters is returned.\n",
        "\n",
        "The cell below implements a hyperparameter grid search, using the C-Index to evaluate each tested model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "eHX56jeLzvA7"
      },
      "outputs": [],
      "source": [
        "def holdout_grid_search(clf, X_train_hp, y_train_hp, X_val_hp, y_val_hp, hyperparams, fixed_hyperparams={}):\n",
        "    '''\n",
        "    Conduct hyperparameter grid search on hold out validation set. Use holdout validation.\n",
        "    Hyperparameters are input as a dictionary mapping each hyperparameter name to the\n",
        "    range of values they should iterate over. Use the cindex function as your evaluation\n",
        "    function.\n",
        "\n",
        "    Input:\n",
        "        clf: sklearn classifier\n",
        "        X_train_hp (dataframe): dataframe for training set input variables\n",
        "        y_train_hp (dataframe): dataframe for training set targets\n",
        "        X_val_hp (dataframe): dataframe for validation set input variables\n",
        "        y_val_hp (dataframe): dataframe for validation set targets\n",
        "        hyperparams (dict): hyperparameter dictionary mapping hyperparameter\n",
        "                            names to range of values for grid search\n",
        "        fixed_hyperparams (dict): dictionary of fixed hyperparameters that\n",
        "                                  are not included in the grid search\n",
        "\n",
        "    Output:\n",
        "        best_estimator (sklearn classifier): fitted sklearn classifier with best performance on\n",
        "                                             validation set\n",
        "        best_hyperparams (dict): hyperparameter dictionary mapping hyperparameter\n",
        "                                 names to values in best_estimator\n",
        "    '''\n",
        "    best_estimator = None\n",
        "    best_hyperparams = {}\n",
        "    \n",
        "    # hold best running score\n",
        "    best_score = 0.0\n",
        "\n",
        "    # get list of param values\n",
        "    lists = hyperparams.values()\n",
        "    \n",
        "    # get all param combinations\n",
        "    param_combinations = list(itertools.product(*lists))\n",
        "    total_param_combinations = len(param_combinations)\n",
        "\n",
        "    # iterate through param combinations\n",
        "    for i, params in enumerate(param_combinations, 1):\n",
        "        # fill param dict with params\n",
        "        param_dict = {}\n",
        "        for param_index, param_name in enumerate(hyperparams):\n",
        "            param_dict[param_name] = params[param_index]\n",
        "            \n",
        "        # create estimator with specified params\n",
        "        estimator = clf(**param_dict, **fixed_hyperparams)\n",
        "\n",
        "        # fit estimator\n",
        "        estimator.fit(X_train_hp, y_train_hp)\n",
        "        \n",
        "        # get predictions on validation set\n",
        "        preds = estimator.predict_proba(X_val_hp)\n",
        "        \n",
        "        # compute cindex for predictions\n",
        "        estimator_score = cindex(y_val_hp, preds[:,1])\n",
        "\n",
        "        print(f'[{i}/{total_param_combinations}] {param_dict}')\n",
        "        print(f'Val C-Index: {estimator_score}\\n')\n",
        "\n",
        "        # if new high score, update high score, best estimator\n",
        "        # and best params \n",
        "        if estimator_score >= best_score:\n",
        "                best_score = estimator_score\n",
        "                best_estimator = estimator\n",
        "                best_hyperparams = param_dict\n",
        "\n",
        "    # add fixed hyperparamters to best combination of variable hyperparameters\n",
        "    best_hyperparams.update(fixed_hyperparams)\n",
        "    \n",
        "    return best_estimator, best_hyperparams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5WzvI-r1T4F"
      },
      "source": [
        "<a name='ex-3'></a>\n",
        "### Exercise 3 - random_forest_grid_search\n",
        "\n",
        "In the cell below, define the values you want to run the hyperparameter grid search on, and run the cell to find the best-performing set of hyperparameters.\n",
        "\n",
        "Your objective is to get a C-Index above `0.6` on both the train and validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL4TXgZl1T4G"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>n_estimators: try values greater than 100</li>\n",
        "    <li>max_depth: try values in the range 1 to 100</li>\n",
        "    <li>min_samples_leaf: try float values below .5 and/or int values greater than 2</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "qxMYxPSg1T4G"
      },
      "outputs": [],
      "source": [
        "def random_forest_grid_search(X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped):\n",
        "\n",
        "    # Define ranges for the chosen random forest hyperparameters \n",
        "    hyperparams = {\n",
        "        # how many trees should be in the forest (int)\n",
        "        'n_estimators': [1],\n",
        "\n",
        "        # the maximum depth of trees in the forest (int)\n",
        "        \n",
        "        'max_depth': [3, 4],\n",
        "        \n",
        "        # the minimum number of samples in a leaf as a fraction\n",
        "        # of the total number of samples in the training set\n",
        "        # Can be int (in which case that is the minimum number)\n",
        "        # or float (in which case the minimum is that fraction of the\n",
        "        # number of training set samples)\n",
        "        'min_samples_leaf': [1],\n",
        "    }\n",
        "\n",
        "    \n",
        "    fixed_hyperparams = {\n",
        "        'random_state': 10,\n",
        "    }\n",
        "    \n",
        "    rf = RandomForestClassifier\n",
        "\n",
        "    best_rf, best_hyperparams = holdout_grid_search(rf, X_train_dropped, y_train_dropped,\n",
        "                                                    X_val_dropped, y_val_dropped, hyperparams,\n",
        "                                                    fixed_hyperparams)\n",
        "\n",
        "    print(f\"Best hyperparameters:\\n{best_hyperparams}\")\n",
        "\n",
        "    \n",
        "    y_train_best = best_rf.predict_proba(X_train_dropped)[:, 1]\n",
        "    print(f\"Train C-Index: {cindex(y_train_dropped, y_train_best)}\")\n",
        "\n",
        "    y_val_best = best_rf.predict_proba(X_val_dropped)[:, 1]\n",
        "    print(f\"Val C-Index: {cindex(y_val_dropped, y_val_best)}\")\n",
        "    \n",
        "    # add fixed hyperparamters to best combination of variable hyperparameters\n",
        "    best_hyperparams.update(fixed_hyperparams)\n",
        "    \n",
        "    return best_rf, best_hyperparams"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mrmU50-x1T4G"
      },
      "outputs": [],
      "source": [
        "best_rf, best_hyperparams = random_forest_grid_search(X_train_dropped, y_train_dropped, X_val_dropped, y_val_dropped)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hTrzOWH3zl2"
      },
      "source": [
        "Finally, evaluate the model on the test set. This is a crucial step, as trying out many combinations of hyperparameters and evaluating them on the validation set could result in a model that ends up overfitting the validation set. We therefore need to check if the model performs well on unseen data, which is the role of the test set, which we have held out until now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjkGhi9n32tS",
        "outputId": "dd6351e7-f482-462d-dc10-089c10eb4e93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test C-Index: 0.623706805620016\n"
          ]
        }
      ],
      "source": [
        "\n",
        "y_test_best = best_rf.predict_proba(X_test)[:, 1]\n",
        "\n",
        "print(f\"Test C-Index: {cindex(y_test.values, y_test_best)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-SBpNi31T4H"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "Test C-Index > 0.6\n",
        "```\n",
        "\n",
        "If your output is not greater than `0.6`, try changing and tweaking your hyperparameters in `Ex 3`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WsHviHfFKiD8"
      },
      "source": [
        "<a name='5'></a>\n",
        "## 5. Imputation\n",
        "\n",
        "You've now built and optimized a random forest model on our data. However, there was still a drop in test C-Index. This might be because you threw away more than half of the data of our data because of missing values for systolic blood pressure. Instead, we can try filling in, or imputing, these values. \n",
        "\n",
        "First, let's explore to see if our data is missing at random or not. Let's plot histograms of the dropped rows against each of the covariates (aside from systolic blood pressure) to see if there is a trend. Compare these to the histograms of the feature in the entire dataset. Try to see if one of the covariates has a signficantly different distribution in the two subsets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ymbGANBK1T4H"
      },
      "outputs": [],
      "source": [
        "dropped_rows = X_train[X_train.isnull().any(axis=1)]\n",
        "\n",
        "columns_except_Systolic_BP = [col for col in X_train.columns if col not in ['Systolic BP']]\n",
        "\n",
        "for col in columns_except_Systolic_BP:\n",
        "    sns.distplot(X_train.loc[:, col], norm_hist=True, kde=False, label='full data')\n",
        "    sns.distplot(dropped_rows.loc[:, col], norm_hist=True, kde=False, label='without missing data')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4OFcONx8TbNn"
      },
      "source": [
        "Most of the covariates are distributed similarly whether or not we have discarded rows with missing data. In other words missingness of the data is independent of these covariates.\n",
        "\n",
        "If this had been true across *all* covariates, then the data would have been said to be **missing completely at random (MCAR)**.\n",
        "\n",
        "But when considering the age covariate, we see that much more data tends to be missing for patients over 65. The reason could be that blood pressure was measured less frequently for old people to avoid placing additional burden on them.\n",
        "\n",
        "As missingness is related to one or more covariates, the missing data is said to be **missing at random (MAR)**.\n",
        "\n",
        "Based on the information we have, there is however no reason to believe that the _values_ of the missing data  or specifically the values of the missing systolic blood pressures  are related to the age of the patients. \n",
        "If this was the case, then this data would be said to be **missing not at random (MNAR)**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwGi6hXjUCO8"
      },
      "source": [
        "<a name='5-1'></a>\n",
        "### 5.1 Error Analysis\n",
        "\n",
        "<a name='ex-4'></a>\n",
        "### Exercise 4 - bad_subset\n",
        "Using the information from the plots above, try to find a subgroup of the test data on which the model performs poorly. You should be able to easily find a subgroup of at least 250 cases on which the model has a C-Index of less than 0.69."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pxr-7O0b1T4I"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li> Define a mask using a feature and a threshold, e.g. patients with a BMI below 20: <code>mask = X_test['BMI'] < 20 </code>. </li>\n",
        "    <li> Try to find a subgroup for which the model had little data.</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "TzoMtJL604Ni"
      },
      "outputs": [],
      "source": [
        "\n",
        "def bad_subset(forest, X_test, y_test):\n",
        "    # define mask to select large subset with poor performance\n",
        "    # currently mask defines the entire set\n",
        "    \n",
        "    mask = X_test.Age < 40\n",
        "\n",
        "    X_subgroup = X_test[mask]\n",
        "    y_subgroup = y_test[mask]\n",
        "    subgroup_size = len(X_subgroup)\n",
        "\n",
        "    y_subgroup_preds = forest.predict_proba(X_subgroup)[:, 1]\n",
        "    performance = cindex(y_subgroup.values, y_subgroup_preds)\n",
        "    \n",
        "    return performance, subgroup_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lgxPsNQi1T4J"
      },
      "outputs": [],
      "source": [
        "#### Test Your Work\n",
        "performance, subgroup_size = bad_subset(best_rf, X_test, y_test)\n",
        "print(\"Subgroup size should greater than 250, performance should be less than 0.69\")\n",
        "print(f\"Your Subgroup size: {subgroup_size}, and your C-Index: {performance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQoSCv_n1T4J"
      },
      "source": [
        "#### Expected Output\n",
        "Note, your actual output will vary depending on the hyperparameters and the mask that you chose.\n",
        "\n",
        "```Python\n",
        "Your Subgroup size > 250, and your C-Index < 0.69\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ0kcNcXU0Yy"
      },
      "source": [
        "<a name='5-2'></a>\n",
        "### 5.2 Imputation Approaches\n",
        "\n",
        "Seeing that our data is not missing completely at random, we can handle the missing values by replacing them with substituted values based on the other values that we have. This is known as imputation.\n",
        "\n",
        "The first imputation strategy that we will use is **mean substitution**: we will replace the missing values for each feature with the mean of the available values. In the next cell, use the `SimpleImputer` from `sklearn` to use mean imputation for the missing values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "TS1jmsZ2611M"
      },
      "outputs": [],
      "source": [
        "# Impute values using the mean\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "imputer.fit(X_train)\n",
        "X_train_mean_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
        "X_val_mean_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EuqizodB1T4K"
      },
      "source": [
        "<a name='ex-5'></a>\n",
        "### Exercise 5 - hyperparams\n",
        "Now perform a hyperparameter grid search to find the best-performing random forest model, and report results on the test set. \n",
        "\n",
        "Define the parameter ranges for the hyperparameter search in the next cell, and run the cell."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gd7hITAy1T4K"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>n_estimators: try values greater than 100</li>\n",
        "    <li>max_depth: try values in the range 1 to 100</li>\n",
        "    <li>min_samples_leaf: try float values below .5 and/or int values greater than 2</li>\n",
        "</ul>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evslwlUy1T4L"
      },
      "outputs": [],
      "source": [
        "# Define ranges for the random forest hyperparameter search \n",
        "hyperparams = {\n",
        "\n",
        "    # how many trees should be in the forest (int)\n",
        "    'n_estimators': [1],\n",
        "\n",
        "    # the maximum depth of trees in the forest (int)\n",
        "    'max_depth': [3, 4],\n",
        "\n",
        "    # the minimum number of samples in a leaf as a fraction\n",
        "    # of the total number of samples in the training set\n",
        "    # Can be int (in which case that is the minimum number)\n",
        "    # or float (in which case the minimum is that fraction of the\n",
        "    # number of training set samples)\n",
        "    'min_samples_leaf': [1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KYn3usw1T4L",
        "outputId": "85ec6977-36df-487f-f184-61b46813adbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/2] {'n_estimators': 1, 'max_depth': 3, 'min_samples_leaf': 1}\n",
            "Val C-Index: 0.7065655677369344\n",
            "\n",
            "[2/2] {'n_estimators': 1, 'max_depth': 4, 'min_samples_leaf': 1}\n",
            "Val C-Index: 0.6940421983805932\n",
            "\n",
            "Performance for best hyperparameters:\n",
            "- Train C-Index: 0.7229\n",
            "- Val C-Index: 0.7066\n",
            "- Test C-Index: 0.7168\n"
          ]
        }
      ],
      "source": [
        "\n",
        "rf = RandomForestClassifier\n",
        "\n",
        "rf_mean_imputed, best_hyperparams_mean_imputed = holdout_grid_search(rf, X_train_mean_imputed, y_train,\n",
        "                                                                     X_val_mean_imputed, y_val,\n",
        "                                                                     hyperparams, {'random_state': 10})\n",
        "\n",
        "print(\"Performance for best hyperparameters:\")\n",
        "\n",
        "y_train_best = rf_mean_imputed.predict_proba(X_train_mean_imputed)[:, 1]\n",
        "print(f\"- Train C-Index: {cindex(y_train, y_train_best):.4f}\")\n",
        "\n",
        "y_val_best = rf_mean_imputed.predict_proba(X_val_mean_imputed)[:, 1]\n",
        "print(f\"- Val C-Index: {cindex(y_val, y_val_best):.4f}\")\n",
        "\n",
        "y_test_imp = rf_mean_imputed.predict_proba(X_test)[:, 1]\n",
        "print(f\"- Test C-Index: {cindex(y_test, y_test_imp):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MC2drk4t1T4L"
      },
      "source": [
        "#### Expected output\n",
        "Note, your actual C-Index values will vary depending on the hyperparameters that you choose.\n",
        "\n",
        "```\n",
        "C-Index >= 0.74\n",
        "```\n",
        "\n",
        "- Try to get a good C-Index, similar these numbers below:\n",
        "\n",
        "```Python\n",
        "Performance for best hyperparameters:\n",
        "- Train C-Index: 0.8109\n",
        "- Val C-Index: 0.7495\n",
        "- Test C-Index: 0.7805\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8eMe7MY7UJk"
      },
      "source": [
        "Next, we will apply another imputation strategy, known as **multivariate feature imputation**, using scikit-learn's `IterativeImputer` class (see the [documentation](https://scikit-learn.org/stable/modules/impute.html#iterative-imputer)).\n",
        "\n",
        "With this strategy, for each feature that is missing values, a regression model is trained to predict observed values based on all of the other features, and the missing values are inferred using this model.\n",
        "As a single iteration across all features may not be enough to impute all missing values, several iterations may be performed, hence the name of the class `IterativeImputer`.\n",
        "\n",
        "In the next cell, use `IterativeImputer` to perform multivariate feature imputation.\n",
        "\n",
        "> Note that the first time the cell is run, `imputer.fit(X_train)` may fail with the message `LinAlgError: SVD did not converge`: simply re-run the cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gr3RW-B1T4M",
        "outputId": "530920bf-bfb8-4402-c7f6-6e1903ab6368"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[IterativeImputer] Early stopping criterion not reached.\n"
          ]
        }
      ],
      "source": [
        "# Impute using regression on other covariates\n",
        "imputer = IterativeImputer(random_state=0, sample_posterior=False, max_iter=1, min_value=0)\n",
        "imputer.fit(X_train)\n",
        "X_train_imputed = pd.DataFrame(imputer.transform(X_train), columns=X_train.columns)\n",
        "X_val_imputed = pd.DataFrame(imputer.transform(X_val), columns=X_val.columns)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vymeWRT51T4M"
      },
      "source": [
        "<a name='ex-6'></a>\n",
        "### Exercise 6 - hyperparams\n",
        "\n",
        "Perform a hyperparameter grid search to find the best-performing random forest model, and report results on the test set. Define the parameter ranges for the hyperparameter search in the next cell, and run the cell.\n",
        "\n",
        "#### Target performance\n",
        "\n",
        "Try to get a text c-index of at least 0.74 or higher."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r5cqEg0O1T4N"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>n_estimators: try values greater than 100</li>\n",
        "    <li>max_depth: try values in the range 1 to 100</li>\n",
        "    <li>min_samples_leaf: try float values below .5 and/or int values greater than 2</li>\n",
        "</ul>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rdxb_5CZ1T4N"
      },
      "outputs": [],
      "source": [
        "# Define ranges for the random forest hyperparameter search \n",
        "hyperparams = {\n",
        "\n",
        "    # how many trees should be in the forest (int)\n",
        "    'n_estimators': [1],\n",
        "\n",
        "    # the maximum depth of trees in the forest (int)\n",
        "    'max_depth': [3, 4],\n",
        "\n",
        "    # the minimum number of samples in a leaf as a fraction\n",
        "    # of the total number of samples in the training set\n",
        "    # Can be int (in which case that is the minimum number)\n",
        "    # or float (in which case the minimum is that fraction of the\n",
        "    # number of training set samples)\n",
        "    'min_samples_leaf': [1],\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eh2GKJ3p1T4N",
        "outputId": "a9a2a4d2-33e8-45c0-a129-6a3a56ab9f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1/2] {'n_estimators': 1, 'max_depth': 3, 'min_samples_leaf': 1}\n",
            "Val C-Index: 0.7081332959857906\n",
            "\n",
            "[2/2] {'n_estimators': 1, 'max_depth': 4, 'min_samples_leaf': 1}\n",
            "Val C-Index: 0.6958227207684908\n",
            "\n",
            "Performance for best hyperparameters:\n",
            "- Train C-Index: 0.7239\n",
            "- Val C-Index: 0.7081\n",
            "- Test C-Index: 0.7357\n"
          ]
        }
      ],
      "source": [
        "rf = RandomForestClassifier\n",
        "\n",
        "rf_imputed, best_hyperparams_imputed = holdout_grid_search(rf, X_train_imputed, y_train,\n",
        "                                                           X_val_imputed, y_val,\n",
        "                                                           hyperparams, {'random_state': 10})\n",
        "\n",
        "print(\"Performance for best hyperparameters:\")\n",
        "\n",
        "y_train_best = rf_imputed.predict_proba(X_train_imputed)[:, 1]\n",
        "print(f\"- Train C-Index: {cindex(y_train, y_train_best):.4f}\")\n",
        "\n",
        "y_val_best = rf_imputed.predict_proba(X_val_imputed)[:, 1]\n",
        "print(f\"- Val C-Index: {cindex(y_val, y_val_best):.4f}\")\n",
        "\n",
        "y_test_imp = rf_imputed.predict_proba(X_test)[:, 1]\n",
        "print(f\"- Test C-Index: {cindex(y_test, y_test_imp):.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EY_CdXFK1T4O"
      },
      "source": [
        "#### Expected Output\n",
        "Note, your actual C-Index values will vary depending on the hyperparameters that you choose.\n",
        "\n",
        "```\n",
        "C-Index >= 0.74\n",
        "```\n",
        "\n",
        "- Try to get a good C-Index, similar these numbers below:\n",
        "\n",
        "```Python\n",
        "Performance for best hyperparameters:\n",
        "- Train C-Index: 0.8131\n",
        "- Val C-Index: 0.7454\n",
        "- Test C-Index: 0.7797\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IhZVEMnnmTe"
      },
      "source": [
        "<a name='6'></a>\n",
        "## 6. Comparison\n",
        "\n",
        "For good measure, retest on the subgroup from before to see if your new models do better."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pxO1Mev31T4O",
        "outputId": "cb9c8f26-45cb-42c3-cfc7-e8cb2e5ffac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "C-Index (no imputation): 0.5032160963244613\n",
            "C-Index (mean imputation): 0.5648922686945501\n",
            "C-Index (multivariate feature imputation): 0.5613434727503168\n"
          ]
        }
      ],
      "source": [
        "performance, subgroup_size = bad_subset(best_rf, X_test, y_test)\n",
        "print(f\"C-Index (no imputation): {performance}\")\n",
        "\n",
        "performance, subgroup_size = bad_subset(rf_mean_imputed, X_test, y_test)\n",
        "print(f\"C-Index (mean imputation): {performance}\")\n",
        "\n",
        "performance, subgroup_size = bad_subset(rf_imputed, X_test, y_test)\n",
        "print(f\"C-Index (multivariate feature imputation): {performance}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8fvmd2o76yma"
      },
      "source": [
        "We should see that avoiding complete case analysis (i.e. analysis only on observations for which there is no missing data) allows our model to generalize a bit better. Remember to examine your missing cases to judge whether they are missing at random or not!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFM27SfS1QSD"
      },
      "source": [
        "<a name='7'></a>\n",
        "## 7. Explanations: SHAP\n",
        "\n",
        "Using a random forest has improved results, but we've lost some of the natural interpretability of trees. In this section we'll try to explain the predictions using slightly more sophisticated techniques. \n",
        "\n",
        "You choose to apply **SHAP (SHapley Additive exPlanations)**, a cutting edge method that explains predictions made by black-box machine learning models (i.e. models which are too complex to be understandable by humans as is).\n",
        "\n",
        "> Given a prediction made by a machine learning model, SHAP values explain the prediction by quantifying the additive importance of each feature to the prediction. SHAP values have their roots in cooperative game theory, where Shapley values are used to quantify the contribution of each player to the game.\n",
        "> \n",
        "> Although it is computationally expensive to compute SHAP values for general black-box models, in the case of trees and forests there exists a fast polynomial-time algorithm. For more details, see the [TreeShap paper](https://arxiv.org/pdf/1802.03888.pdf).\n",
        "\n",
        "We'll use the [shap library](https://github.com/slundberg/shap) to do this for our random forest model. Run the next cell to output the most at risk individuals in the test set according to our model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "emlK-wlyJEel"
      },
      "outputs": [],
      "source": [
        "X_test_risk = X_test.copy(deep=True)\n",
        "X_test_risk.loc[:, 'risk'] = rf_imputed.predict_proba(X_test_risk)[:, 1]\n",
        "X_test_risk = X_test_risk.sort_values(by='risk', ascending=False)\n",
        "X_test_risk.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aefDv0PDKrfv"
      },
      "source": [
        "We can use SHAP values to try and understand the model output on specific individuals using force plots. Run the cell below to see a force plot on the riskiest individual. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "elJX1FqWKzYm"
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(rf_imputed)\n",
        "i = 0\n",
        "shap_value = explainer.shap_values(X_test.loc[X_test_risk.index[i], :])[1]\n",
        "shap.force_plot(explainer.expected_value[1], shap_value, feature_names=X_test.columns, matplotlib=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kak4kR4yQ8Tk"
      },
      "source": [
        "How to read this chart:\n",
        "- The red sections on the left are features which push the model towards the final prediction in the positive direction (i.e. a higher Age increases the predicted risk).\n",
        "- The blue sections on the right are features that push the model towards the final prediction in the negative direction (if an increase in a feature leads to a lower risk, it will be shown in blue).\n",
        "- Note that the exact output of your chart will differ depending on the hyper-parameters that you choose for your model.\n",
        "\n",
        "We can also use SHAP values to understand the model output in aggregate. Run the next cell to initialize the SHAP values (this may take a few minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "Q9pwTohdRlFB"
      },
      "outputs": [],
      "source": [
        "shap_values = shap.TreeExplainer(rf_imputed).shap_values(X_test)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NpathrHHH3q"
      },
      "source": [
        "Run the next cell to see a summary plot of the SHAP values for each feature on each of the test examples. The colors indicate the value of the feature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsqthyxCDfY1"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Z1oed01T4R"
      },
      "source": [
        "Clearly we see that being a woman (`sex = 2.0`, as opposed to men for which `sex = 1.0`) has a negative SHAP value, meaning that it reduces the risk of dying within 10 years. High age and high systolic blood pressure have positive SHAP values, and are therefore related to increased mortality. \n",
        "\n",
        "You can see how features interact using dependence plots. These plot the SHAP value for a given feature for each data point, and color the points in using the value for another feature. This lets us begin to explain the variation in SHAP value for a single value of the main feature.\n",
        "\n",
        "Run the next cell to see the interaction between Age and Sex."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RA3YOaJhEkDZ"
      },
      "outputs": [],
      "source": [
        "shap.dependence_plot('Age', shap_values, X_test, interaction_index='Sex')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81YW8Mi91T4R"
      },
      "source": [
        "We see that while Age > 50 is generally bad (positive SHAP value), being a woman generally reduces the impact of age. This makes sense since we know that women generally live longer than men.\n",
        "\n",
        "Let's now look at poverty index and age."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXcUiJ_ZFtcl"
      },
      "outputs": [],
      "source": [
        "shap.dependence_plot('Poverty index', shap_values, X_test, interaction_index='Age')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J0lr2uBl1T4S"
      },
      "source": [
        "We see that the impact of poverty index drops off quickly, and for higher income individuals age begins to explain much of variation in the impact of poverty index.\n",
        "\n",
        "Try some other pairs and see what other interesting relationships you can find!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9hbgZTZSAIL"
      },
      "source": [
        "<a name='8'></a>\n",
        "## 7. Feature Importance - Permutations and shapley values in more detail"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vgBsltXSLnL"
      },
      "source": [
        "When developing predictive models and risk measures, it's often helpful to know which features are making the most difference. This is easy to determine in simpler models such as linear models and decision trees. However as we move to more complex models to achieve high performance, we usually sacrifice some interpretability. In this assignment we'll try to regain some of that interpretability using Shapley values, a technique which has gained popularity in recent years, but which is based on classic results in cooperative game theory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j92O1aBISQAz",
        "outputId": "96dff5fc-68c3-49c8-bcbb-efda6b6aa73e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model C-index on test: 0.7168262942491878\n"
          ]
        }
      ],
      "source": [
        "#@title let's test our model\n",
        "\n",
        "def cindex(y_true, scores):\n",
        "    return lifelines.utils.concordance_index(y_true, scores)\n",
        "\n",
        "### loading model if saved vs just use our rf_mean_imputed from above to test it\n",
        "## rf = pickle.load(open('./whatever_model_we have', 'rb'))\n",
        "\n",
        "test_df = pd.read_csv('./nhanest_test.csv')\n",
        "test_df = test_df.drop(test_df.columns[0], axis=1)\n",
        "X_test = test_df.drop('y', axis=1)\n",
        "y_test = test_df.loc[:, 'y']\n",
        "cindex_test = cindex(y_test, rf_mean_imputed.predict_proba(X_test)[:, 1])\n",
        "\n",
        "print(\"Model C-index on test: {}\".format(cindex_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qa3c0ZwNTgUh"
      },
      "outputs": [],
      "source": [
        "## Run the next cell to print out the riskiest individuals according to our model\n",
        "X_test_risky = X_test.copy(deep=True)\n",
        "X_test_risky.loc[:, 'risk'] = rf_mean_imputed.predict_proba(X_test)[:, 1] # Predicting our risk.\n",
        "X_test_risky = X_test_risky.sort_values(by='risk', ascending=False) # Sorting by risk value.\n",
        "X_test_risky.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BqVN_rJET7ng"
      },
      "outputs": [],
      "source": [
        "# Permuation Method for Feature Importance\n",
        "# First we'll try to determine feature importance using the permutation method. \n",
        "#In the permutation method, the importance of feature i would be the regular performance \n",
        "#of the model minus the performance with the values for feature i permuted in the dataset. \n",
        "#This way we can assess how well a model without that feature would do without having to train a new model for each feature.\n",
        "# Implementing Permutation - permute_feature\n",
        "# Complete the implementation of the function below, which given a feature name returns a \n",
        "# dataset with those feature values randomly permuted.\n",
        "\n",
        "def permute_feature(df, feature):\n",
        "    \"\"\"\n",
        "    Given dataset, returns version with the values of\n",
        "    the given feature randomly permuted. \n",
        "\n",
        "    Args:\n",
        "        df (dataframe): The dataset, shape (num subjects, num features)\n",
        "        feature (string): Name of feature to permute\n",
        "    Returns:\n",
        "        permuted_df (dataframe): Exactly the same as df except the values\n",
        "                                of the given feature are randomly permuted.\n",
        "    \"\"\"\n",
        "    permuted_df = df.copy(deep=True) # Make copy so we don't change original df\n",
        "\n",
        "    # Permute the values of the column 'feature'\n",
        "    permuted_features = np.random.permutation(permuted_df[feature])\n",
        "    \n",
        "    # Set the column 'feature' to its permuted values.\n",
        "    permuted_df[feature] = permuted_features\n",
        "\n",
        "    return permuted_df\n",
        "\n",
        "\n",
        "def permutation_importance(X, y, model, metric, num_samples = 100):\n",
        "    \"\"\"\n",
        "    Compute permutation importance for each feature.\n",
        "\n",
        "    Args:\n",
        "        X (dataframe): Dataframe for test data, shape (num subject, num features)\n",
        "        y (np.array): Labels for each row of X, shape (num subjects,)\n",
        "        model (object): Model to compute importances for, guaranteed to have\n",
        "                        a 'predict_proba' method to compute probabilistic \n",
        "                        predictions given input\n",
        "        metric (function): Metric to be used for feature importance. Takes in ground\n",
        "                           truth and predictions as the only two arguments\n",
        "        num_samples (int): Number of samples to average over when computing change in\n",
        "                           performance for each feature\n",
        "    Returns:\n",
        "        importances (dataframe): Dataframe containing feature importance for each\n",
        "                                 column of df with shape (1, num_features)\n",
        "    \"\"\"\n",
        "\n",
        "    importances = pd.DataFrame(index = ['importance'], columns = X.columns)\n",
        "    \n",
        "    # Get baseline performance (note, you'll use this metric function again later)\n",
        "    baseline_performance = metric(y, model.predict_proba(X)[:, 1])\n",
        "\n",
        "    # Iterate over features (the columns in the importances dataframe)\n",
        "    for feature in importances.columns: # complete this line\n",
        "        \n",
        "        # Compute 'num_sample' performances by permutating that feature\n",
        "        \n",
        "        # You'll see how the model performs when the feature is permuted\n",
        "        # You'll do this num_samples number of times, and save the performance each time\n",
        "        # To store the feature performance,\n",
        "        # create a numpy array of size num_samples, initialized to all zeros\n",
        "        feature_performance_arr = np.zeros(num_samples)\n",
        "        \n",
        "        # Loop through each sample\n",
        "        for i in range(num_samples): # complete this line\n",
        "            \n",
        "            # permute the column of dataframe X\n",
        "            perm_X = permute_feature(X,feature)\n",
        "            \n",
        "            # calculate the performance with the permuted data\n",
        "            # Use the same metric function that was used earlier\n",
        "            feature_performance_arr[i] = metric(y, model.predict_proba(perm_X)[:, 1])\n",
        "    \n",
        "        # Compute importance: absolute difference between \n",
        "        # the baseline performance and the average across the feature performance\n",
        "        importances[feature]['importance'] = baseline_performance - np.mean(feature_performance_arr)\n",
        "\n",
        "    return importances\n",
        "\n",
        "importances = permutation_importance(X_test, y_test, rf_mean_imputed, cindex, num_samples=100)\n",
        "importances"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoHEwlTRVXw2"
      },
      "outputs": [],
      "source": [
        "# let's plot for better understanding\n",
        "importances.T.plot.bar()\n",
        "plt.ylabel(\"Importance\")\n",
        "l = plt.legend()\n",
        "l.remove()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wH9R9gIVtMO"
      },
      "source": [
        "We see age as by far the best prediction of near term mortality, as one might expect. Next is sex, followed by diastolic blood pressure. Interestingly, the poverty index also has a large impact, despite the fact that it is not directly related to an individual's health. This alludes to the importance of social determinants of health in our model.\n",
        "\n",
        "\n",
        "**Closer look on Shapley Values for Random Forests**\n",
        "\n",
        "We'll contrast the permutation method with a more recent technique known as Shapley values (actually, Shapley values date back to the mid 20th century, but have only been applied to machine learning very recently).\n",
        "\n",
        "\n",
        "Visualizing Feature Importance on Specific Individuals\n",
        "We can use Shapley values to try and understand the model output on specific individuals. In general Shapley values take exponential time to compute, but luckily there are faster approximations for forests in particular that run in polynomial time. Run the next cell to display a 'force plot' showing how each feature influences the output for the first person in our dataset. If you want more information about 'force plots' and other decision plots, please take a look at GitHub repo by the shap library creators."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AShEFonRVetN"
      },
      "outputs": [],
      "source": [
        "explainer = shap.TreeExplainer(rf_mean_imputed)\n",
        "i = 0 # Picking an individual\n",
        "shap_value = explainer.shap_values(X_test.loc[X_test_risky.index[i], :])[1]\n",
        "shap.force_plot(explainer.expected_value[1], shap_value, feature_names=X_test.columns, matplotlib=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cj79xzTrWXcV"
      },
      "source": [
        "For this individual, their age, pulse pressure, and sex were the biggest contributors to their high risk prediction. Note how shapley values give us greater granularity in our interpretations.\n",
        "\n",
        "Feel free to change the i value above to explore the feature influences for different individuals.\n",
        "\n",
        "**Visualizing Feature Importance on Aggregate**\n",
        "\n",
        "Just like with the permutation method, we might also want to understand model output in aggregate. Shapley values allow us to do this as well. Run the next cell to initialize the shapley values for each example in the test set (this may also take a few minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "IzYK8ktzWdsd"
      },
      "outputs": [],
      "source": [
        "shap_values = shap.TreeExplainer(rf_mean_imputed).shap_values(X_test)[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAJ9DLoxWxdc"
      },
      "source": [
        "Run the next cell to see a summary plot of the shapley values for each feature on each of the test examples. The colors indicate the value of the feature. The features are listed in terms of decreasing absolute average shapley value over all the individuals in the dataset.\n",
        "\n",
        "In the plot, you might be able to notice a high concentration of points on specific SHAP value ranges. This means that a high proportion of our test set lies on those ranges.\n",
        "\n",
        "As with the permutation method, age, sex, poverty index, and diastolic BP seem to be the most important features. Being older has a negative impact on mortality, and being a woman (sex=2.0) has a positive effect."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diaLahuQW0NM"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x7Oi3xc7XKar"
      },
      "source": [
        "**Visualizing Interactions between Features**\n",
        "\n",
        "The shap library also lets you visualize interactions between features using dependence plots. These plot the Shapley value for a given feature for each data point, and color the points in using the value for another feature. This lets us begin to explain the variation in shapley value for a single value of the main feature.\n",
        "\n",
        "Run the next cell to see the interaction between Age and Sex.\n",
        "\n",
        "shap.dependence_plot('Age', shap_values, X_test, interaction_index = 'Sex')\n",
        "We see that while Age > 50 is generally bad (positive Shapley value), being a woman (red points) generally reduces the impact of age. This makes sense since we know that women generally live longer than men."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNMfzDh0XPbj"
      },
      "outputs": [],
      "source": [
        "shap.dependence_plot('Age', shap_values, X_test, interaction_index = 'Sex')\n",
        "shap.dependence_plot('Poverty index', shap_values, X_test, interaction_index='Age')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Q2KuaRamHfr"
      },
      "source": [
        "# **B.** Survival Estimates that Vary with Time\n",
        "\n",
        "Welcome to the third assignment of Course 2. In this assignment, we'll use Python to build some of the statistical models we learned this past week to analyze surivival estimates for a dataset of lymphoma patients. We'll also evaluate these models and interpret their outputs. Along the way, you will be learning about the following: \n",
        "\n",
        "- Censored Data\n",
        "- Kaplan-Meier Estimates\n",
        "- Subgroup Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nFhaFQbh-g7r"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [1. Import Packages](#1)\n",
        "- [2. Load the Dataset](#2)\n",
        "- [3. Censored Data](#3)\n",
        "    - [Exercise 1 - frac_censored](#ex-1)\n",
        "- [4. Survival Estimates](#4)\n",
        "    - [Exercise 2 - naive_estimator](#ex-2)\n",
        "    - [Exercise 3 - HomemadeKM](#ex-3)\n",
        "- [5. Subgroup Analysis](#5)\n",
        "    - [5.1 Bonus: Log Rank Test](#5-1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UopnLTeLkViX"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1. Import Packages\n",
        "\n",
        "We'll first import all the packages that we need for this assignment. \n",
        "\n",
        "- `lifelines` is an open-source library for data analysis.\n",
        "- `numpy` is the fundamental package for scientific computing in python.\n",
        "- `pandas` is what we'll use to manipulate our data.\n",
        "- `matplotlib` is a plotting library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qSiMZY6t_Lio"
      },
      "outputs": [],
      "source": [
        "!pip install -q lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TZyXoADQmYlt"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "from IPython.display import display\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import lifelines\n",
        "from lifelines import KaplanMeierFitter as KM\n",
        "from lifelines.statistics import logrank_test\n",
        "from lifelines.datasets import load_lymphoma"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "h41_6cyVBMxL"
      },
      "outputs": [],
      "source": [
        "#@title tests\n",
        "\n",
        "### data tests\n",
        "np.random.seed(3)\n",
        "\n",
        "def datatype_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += datatype_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}. Got {} but expected type {}\".format(error,\n",
        "                                                                          key, type(target_output[key]), type(expected_output[key])))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += datatype_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}, Got {}  but expected type {}\".format(error,\n",
        "                                                                          i, type(target_output[i]), type(expected_output[i])))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        assert isinstance(target_output, type(expected_output))\n",
        "        return 1\n",
        "            \n",
        "def equation_output_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += equation_output_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(expected_output[key], \n",
        "                                         target_output[key])\n",
        "                print(\"Error: {} for variable {}.\".format(error,\n",
        "                                                                          key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += equation_output_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable in position {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            np.testing.assert_array_almost_equal(target_output, expected_output)\n",
        "        else:\n",
        "            assert target_output == expected_output\n",
        "        return 1\n",
        "    \n",
        "def shape_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += shape_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += shape_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            assert target_output.shape == expected_output.shape\n",
        "        return 1\n",
        "                \n",
        "def multiple_test(test_cases, target):\n",
        "    success = 0\n",
        "    for test_case in test_cases:\n",
        "        try:\n",
        "            target_answer = target(*test_case['input'])\n",
        "            if test_case['name'] == \"datatype_check\":\n",
        "                success += datatype_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"equation_output_check\":\n",
        "                success += equation_output_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"shape_check\":\n",
        "                success += shape_check(test_case['expected'], target_answer, test_case['error'])\n",
        "        except:\n",
        "            print(\"Error: \" + test_case['error'])\n",
        "            \n",
        "    if success == len(test_cases):\n",
        "        print(\"\\033[92m All tests passed.\")\n",
        "    else:\n",
        "        print('\\033[92m', success,\" Tests passed\")\n",
        "        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n",
        "        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n",
        "\n",
        "\n",
        "### general tests\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "### ex1\n",
        "def frac_censored_test(target, data):\n",
        "    data = data\n",
        "    print(\"Observations which were censored: \", target(data))\n",
        "    expected_output = 0.325\n",
        "    \n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [data],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Data-type mismatch.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [data],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong shape.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [data],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong output.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, target)\n",
        "    \n",
        "\n",
        "##############################################        \n",
        "### ex2\n",
        "def naive_estimator_test_case():\n",
        "    sample_df_1 = pd.DataFrame(columns = [\"Time\", \"Event\"])\n",
        "    sample_df_1.Time = [5, 10, 15]\n",
        "    sample_df_1.Event = [0, 1, 0]\n",
        "    \n",
        "    sample_df_2 = pd.DataFrame({'Time': [5,5,10],\n",
        "                                'Event': [0,1,0]\n",
        "                               })\n",
        "    \n",
        "    return sample_df_1, sample_df_2\n",
        "\n",
        "def naive_estimator_test(target):\n",
        "    sample_df_1, sample_df_2 = naive_estimator_test_case()\n",
        "    \n",
        "    print(\"Sample 1 dataframe for testing code:\\n\")\n",
        "    print(sample_df_1)\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    print(\"Test Case 1: S(3)\")\n",
        "    print(\"Output: \", target(3, sample_df_1))\n",
        "\n",
        "    print(\"\\nTest Case 2: S(12)\")\n",
        "    print(\"Output: \", target(12, sample_df_1))\n",
        "\n",
        "    print(\"\\nTest Case 3: S(20)\")\n",
        "    print(\"Output: \", target(20, sample_df_1))\n",
        "    \n",
        "    print(\"\\nSample 2 dataframe for testing code:\\n\")\n",
        "    print(\"\\n\", sample_df_2, \"\\n\")\n",
        "\n",
        "    print(\"Test case 4: S(5)\")\n",
        "    print(\"Output: \", target(5, sample_df_2), \"\\n\")\n",
        "    \n",
        "    expected_output_1 = 1.0\n",
        "    expected_output_2 = 0.5\n",
        "    expected_output_3 = 0.0\n",
        "    expected_output_4 = 0.5\n",
        "    \n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [3, sample_df_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Data-type mismatch for Test Case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [3, sample_df_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Wrong shape for Test Case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [3, sample_df_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Wrong output for Test Case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [12, sample_df_1],\n",
        "            \"expected\": expected_output_2,\n",
        "            \"error\": \"Wrong output for Test Case 2.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [20, sample_df_1],\n",
        "            \"expected\": expected_output_3,\n",
        "            \"error\": \"Wrong output for Test Case 3.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [5, sample_df_2],\n",
        "            \"expected\": expected_output_4,\n",
        "            \"error\": \"Wrong output for Test Case 4.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, target)\n",
        "    \n",
        "\n",
        "\n",
        "##############################################        \n",
        "### ex3\n",
        "def HomemadeKM_test_case():\n",
        "    sample_df_1 = pd.DataFrame(columns = [\"Time\", \"Event\"])\n",
        "    sample_df_1.Time = [5, 10, 15]\n",
        "    sample_df_1.Event = [0, 1, 0]\n",
        "    \n",
        "    sample_df_2 = pd.DataFrame(columns = [\"Time\", \"Event\"])\n",
        "    sample_df_2.loc[:, \"Time\"] = [2, 15, 12, 10, 20]\n",
        "    sample_df_2.loc[:, \"Event\"] = [0, 0, 1, 1, 1]\n",
        "    \n",
        "    return sample_df_1, sample_df_2\n",
        "\n",
        "def HomemadeKM_test(target):\n",
        "    \n",
        "    sample_df_1, sample_df_2 = HomemadeKM_test_case()\n",
        "    \n",
        "    print(\"Test Case 1\\n\")\n",
        "    print(sample_df_1.head(), \"\\n\")\n",
        "    x, y = target(sample_df_1)\n",
        "    print(\"Test Case 1 Event times: {}, Survival Probabilities: {}\".format(x, y))\n",
        "    \n",
        "    print(\"\\nTest Case 2\\n\")\n",
        "    print(sample_df_2.head(), \"\\n\")\n",
        "    x, y = target(sample_df_2)\n",
        "    print(\"Test Case 2 Event times: {}, Survival Probabilities: {}\".format(x, y), \"\\n\")\n",
        "    \n",
        "    expected_output_1 = (np.array([0, 5, 10, 15]), np.array([1.0, 1.0, 0.5, 0.5]))\n",
        "    expected_output_2 = (np.array([0, 2, 10, 12, 15, 20]), np.array([1.0, 1.0, 0.75, 0.5, 0.5, 0.0]))\n",
        "    \n",
        "    test_cases = [\n",
        "        \n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [sample_df_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Wrong shape for Test Case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [sample_df_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Wrong output for Test Case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [sample_df_2],\n",
        "            \"expected\": expected_output_2,\n",
        "            \"error\": \"Wrong output for Test Case 2.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, target)\n",
        "    \n",
        "    \n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5rp2TD1qnGmp"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2. Load the Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEbu3MtrVsnU"
      },
      "source": [
        "Run the next cell to load the lymphoma data set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3wHdLrEnSNa"
      },
      "outputs": [],
      "source": [
        "def load_data():\n",
        "    df = load_lymphoma()\n",
        "    df.loc[:, 'Event'] = df.Censor\n",
        "    df = df.drop(['Censor'], axis=1)\n",
        "    return df\n",
        "\n",
        "data = load_data()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hrHa0dPqU08"
      },
      "source": [
        "As always, you first look over your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEd504pKqWuc"
      },
      "outputs": [],
      "source": [
        "print(\"data shape: {}\".format(data.shape))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dblUOLQS4UU0"
      },
      "source": [
        "The column `Time` states how long the patient lived before they died or were censored.\n",
        "\n",
        "The column `Event` says whether a death was observed or not. `Event` is 1 if the event is observed (i.e. the patient died) and 0 if data was censored.\n",
        "\n",
        "Censorship here means that the observation has ended without any observed event.\n",
        "For example, let a patient be in a hospital for 100 days at most. If a patient dies after only 44 days, their event will be recorded as `Time` = 44 and `Event` = 1. If a patient walks out after 100 days and dies 3 days later (103 days total), this event is not observed in our process and the corresponding row has `Time` = 100 and `Event` = 0. If a patient survives for 25 years after being admitted, their data for are still `Time` = 100 and `Event` = 0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L0d2s2wtn2Pf"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3. Censored Data\n",
        "\n",
        "We can plot a histogram of the survival times to see in general how long cases survived before censorship or events."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cFrvXrODZklx"
      },
      "outputs": [],
      "source": [
        "data.Time.hist();\n",
        "plt.xlabel(\"Observation time before death or censorship (days)\");\n",
        "plt.ylabel(\"Frequency (number of patients)\");\n",
        "# Note that the semicolon at the end of the plotting line\n",
        "# silences unnecessary textual output - try removing it\n",
        "# to observe its effect"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohXd70ZBaRWJ"
      },
      "source": [
        "<a name='ex-1'></a>\n",
        "### Exercise 1 - frac_censored\n",
        "\n",
        "In the next cell, write a function to compute the fraction ($\\in [0, 1]$) of observations which were censored. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8Z67ku7-g71"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>Summing up the <code>'Event'</code> column will give you the number of observations where censorship has NOT occurred.</li>\n",
        "    \n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fkHnfJ6bD0f"
      },
      "outputs": [],
      "source": [
        "\n",
        "def frac_censored(df):\n",
        "    \"\"\"\n",
        "    Return percent of observations which were censored.\n",
        "    \n",
        "    Args:\n",
        "        df (dataframe): dataframe which contains column 'Event' which is \n",
        "                        1 if an event occurred (death)\n",
        "                        0 if the event did not occur (censored)\n",
        "    Returns:\n",
        "        frac_censored (float): fraction of cases which were censored. \n",
        "    \"\"\"\n",
        "    result = 0.0\n",
        "    \n",
        "    censored_count = sum(df['Event'] == 0)\n",
        "    result = censored_count/len(df)\n",
        "    \n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9M9k1dvU-g73",
        "outputId": "93b48521-98bc-4fbb-b10b-9ae3f5926a89"
      },
      "outputs": [],
      "source": [
        "frac_censored_test(frac_censored, data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8z8Sap1-g73"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "Observations which were censored:  0.325\n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpzYWXUpbk6x"
      },
      "source": [
        "Run the next cell to see the distributions of survival times for censored and uncensored examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1k3qlTQLbulW"
      },
      "outputs": [],
      "source": [
        "df_censored = data[data.Event == 0]\n",
        "df_uncensored = data[data.Event == 1]\n",
        "\n",
        "df_censored.Time.hist()\n",
        "plt.title(\"Censored\")\n",
        "plt.xlabel(\"Time (days)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()\n",
        "\n",
        "df_uncensored.Time.hist()\n",
        "plt.title(\"Uncensored\")\n",
        "plt.xlabel(\"Time (days)\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmFDrzYrn-JA"
      },
      "source": [
        "<a name='4'></a>\n",
        "## 4. Survival Estimates\n",
        "\n",
        "We'll now try to estimate the survival function:\n",
        "\n",
        "$$\n",
        "S(t) = P(T > t)\n",
        "$$\n",
        "\n",
        "To illustrate the strengths of Kaplan Meier, we'll start with a naive estimator of the above survival function. To estimate this quantity, we'll divide the number of people who we know lived past time $t$ by the number of people who were not censored before $t$.\n",
        "\n",
        "Formally, let $i$ = 1, ..., $n$ be the cases, and let $T_i$ be the time when $i$ was censored or an event happened. Let $e_i= 1$ if an event was observed for $i$ and 0 otherwise. Then let $X_t = \\{i : T_i > t\\}$, and let $M_t = \\{i : e_i = 1 \\text{ or } T_i > t\\}$. The estimator you will compute will be:\n",
        "\n",
        "$$\n",
        "\\hat{S}(t) = \\frac{|X_t|}{|M_t|}\n",
        "$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4_2RYQPy-g75"
      },
      "source": [
        "<a name='ex-2'></a>\n",
        "### Exercise 2 - naive_estimator\n",
        "Write a function to compute this estimate for arbitrary $t$ in the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUoKpBHJjZM-"
      },
      "outputs": [],
      "source": [
        "def naive_estimator(t, df):\n",
        "    \"\"\"\n",
        "    Return naive estimate for S(t), the probability\n",
        "    of surviving past time t. Given by number\n",
        "    of cases who survived past time t divided by the\n",
        "    number of cases who weren't censored before time t.\n",
        "    \n",
        "    Args:\n",
        "        t (int): query time\n",
        "        df (dataframe): survival data. Has a Time column,\n",
        "                        which says how long until that case\n",
        "                        experienced an event or was censored,\n",
        "                        and an Event column, which is 1 if an event\n",
        "                        was observed and 0 otherwise.\n",
        "    Returns:\n",
        "        S_t (float): estimator for survival function evaluated at t.\n",
        "    \"\"\"\n",
        "    S_t = 0.0\n",
        "    X = sum(df['Time'] > t)\n",
        "    M = sum( (df['Time'] > t) | (df['Event'] == 1) )\n",
        "    S_t = X / M\n",
        "    \n",
        "    return S_t"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HSUrodL5-g76"
      },
      "outputs": [],
      "source": [
        "\n",
        "naive_estimator_test(naive_estimator)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VD-yaw1N-g76"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "Test Case 1: S(3)\n",
        "Output:  1.0\n",
        "\n",
        "Test Case 2: S(12)\n",
        "Output:  0.5\n",
        "\n",
        "Test Case 3: S(20)\n",
        "Output:  0.0\n",
        "\n",
        "Test case 4: S(5)\n",
        "Output:  0.5 \n",
        "\n",
        " All tests passed.\n",
        "\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKMsSOzfmGwD"
      },
      "source": [
        "In the next cell, we will plot the naive estimator using the real data up to the maximum time in the dataset. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nauOrVd9mNDs"
      },
      "outputs": [],
      "source": [
        "max_time = data.Time.max()\n",
        "x = range(0, max_time+1)\n",
        "y = np.zeros(len(x))\n",
        "for i, t in enumerate(x):\n",
        "    y[i] = naive_estimator(t, data)\n",
        "    \n",
        "plt.plot(x, y)\n",
        "plt.title(\"Naive Survival Estimate\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Estimated cumulative survival rate\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jg4VTizxqgKM"
      },
      "source": [
        "<a name='ex-3'></a>\n",
        "### Exercise 3 - HomemadeKM\n",
        "\n",
        "Next let's compare this with the Kaplan Meier estimate. In the cell below, write a function that computes the Kaplan Meier estimate of $S(t)$ at every distinct time in the dataset. \n",
        "\n",
        "Recall the Kaplan-Meier estimate:\n",
        "\n",
        "$$\n",
        "S(t) = \\prod_{t_i \\leq t} (1 - \\frac{d_i}{n_i})\n",
        "$$\n",
        "\n",
        "where $t_i$ are the events observed in the dataset and $d_i$ is the number of deaths at time $t_i$ and $n_i$ is the number of people who we know have survived up to time $t_i$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVz64UqC-g77"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>Try sorting by Time.</li>\n",
        "    <li>Use <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.unique.html\">pandas.Series.unique<a> </li>\n",
        "    <li>If you get a division by zero error, please double-check how you calculated `n_t`</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnwysrz7CzNG"
      },
      "outputs": [],
      "source": [
        "\n",
        "def HomemadeKM(df):\n",
        "    \"\"\"\n",
        "    Return KM estimate evaluated at every distinct\n",
        "    time (event or censored) recorded in the dataset.\n",
        "    Event times and probabilities should begin with\n",
        "    time 0 and probability 1.\n",
        "    \n",
        "    Example:\n",
        "    \n",
        "    input: \n",
        "    \n",
        "         Time  Censor\n",
        "    0     5       0\n",
        "    1    10       1\n",
        "    2    15       0\n",
        "    \n",
        "    correct output: \n",
        "    \n",
        "    event_times: [0, 5, 10, 15]\n",
        "    S: [1.0, 1.0, 0.5, 0.5]\n",
        "    \n",
        "    Args:\n",
        "        df (dataframe): dataframe which has columns for Time\n",
        "                          and Event, defined as usual.\n",
        "                          \n",
        "    Returns:\n",
        "        event_times (list of ints): array of unique event times\n",
        "                                      (begins with 0).\n",
        "        S (list of floats): array of survival probabilites, so that\n",
        "                            S[i] = P(T > event_times[i]). This \n",
        "                            begins with 1.0 (since no one dies at time\n",
        "                            0).\n",
        "    \"\"\"\n",
        "    # individuals are considered to have survival probability 1\n",
        "    # at time 0\n",
        "    event_times = [0]\n",
        "    p = 1.0\n",
        "    S = [p]\n",
        "    \n",
        "    # get collection of unique observed event times\n",
        "    observed_event_times = df.Time.unique()\n",
        "  \n",
        "    # sort event times\n",
        "    observed_event_times = sorted(observed_event_times)\n",
        "    \n",
        "    # iterate through event times\n",
        "    for t in observed_event_times:\n",
        "  \n",
        "        # compute n_t, number of people who survive to time t\n",
        "        n_t = len(df[df.Time >= t])\n",
        "  \n",
        "        # compute d_t, number of people who die at time t\n",
        "        d_t = len(df[(df.Time == t) & (df.Event == 1)])\n",
        "        \n",
        "        # update p\n",
        "        p = p*(1 - float(d_t)/n_t)\n",
        "  \n",
        "        # update S and event_times (ADD code below)\n",
        "        # hint: use append\n",
        "        event_times.append(t)\n",
        "        S.append(p)\n",
        "  \n",
        "    return event_times, S"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a9cS2Nnr-g78"
      },
      "outputs": [],
      "source": [
        "HomemadeKM_test(HomemadeKM)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b-2tHEcp-g79"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "Test Case 1 Event times: [0, 5, 10, 15], Survival Probabilities: [1.0, 1.0, 0.5, 0.5]\n",
        "Test Case 2 Event times: [0, 2, 10, 12, 15, 20], Survival Probabilities: [1.0, 1.0, 0.75, 0.5, 0.5, 0.0] \n",
        "\n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G7OAiWjS7hLA"
      },
      "source": [
        "Now let's plot the two against each other on the data to see the difference."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbPlC5717gM_"
      },
      "outputs": [],
      "source": [
        "max_time = data.Time.max()\n",
        "x = range(0, max_time+1)\n",
        "y = np.zeros(len(x))\n",
        "for i, t in enumerate(x):\n",
        "    y[i] = naive_estimator(t, data)\n",
        "    \n",
        "plt.plot(x, y, label=\"Naive\")\n",
        "\n",
        "x, y = HomemadeKM(data)\n",
        "plt.step(x, y, label=\"Kaplan-Meier\")\n",
        "plt.xlabel(\"Time\")\n",
        "plt.ylabel(\"Survival probability estimate\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY__6ufG3sDk"
      },
      "source": [
        "### Question\n",
        "\n",
        "What differences do you observe between the naive estimator and Kaplan-Meier estimator? Do any of our earlier explorations of the dataset help to explain these differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i7tElIKVoQ4R"
      },
      "source": [
        "<a name='5'></a>\n",
        "## 5. Subgroup Analysis\n",
        "\n",
        "We see that along with Time and Censor, we have a column called `Stage_group`. \n",
        "- A value of 1 in this column denotes a patient with stage III cancer\n",
        "- A value of 2 denotes stage IV. \n",
        "\n",
        "We want to compare the survival functions of these two groups.\n",
        "\n",
        "This time we'll use the `KaplanMeierFitter` class from `lifelines`. Run the next cell to fit and plot the Kaplan Meier curves for each group. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ge6P3fgVrZLS"
      },
      "outputs": [],
      "source": [
        "S1 = data[data.Stage_group == 1]\n",
        "km1 = KM()\n",
        "km1.fit(S1.loc[:, 'Time'], event_observed = S1.loc[:, 'Event'], label = 'Stage III')\n",
        "\n",
        "S2 = data[data.Stage_group == 2]\n",
        "km2 = KM()\n",
        "km2.fit(S2.loc[:, \"Time\"], event_observed = S2.loc[:, 'Event'], label = 'Stage IV')\n",
        "\n",
        "ax = km1.plot(ci_show=False)\n",
        "km2.plot(ax = ax, ci_show=False)\n",
        "plt.xlabel('time')\n",
        "plt.ylabel('Survival probability estimate')\n",
        "plt.savefig('two_km_curves', dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4DwaOVEs19Q"
      },
      "source": [
        "Let's compare the survival functions at 90, 180, 270, and 360 days"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11dhdsUOtEqe"
      },
      "outputs": [],
      "source": [
        "survivals = pd.DataFrame([90, 180, 270, 360], columns = ['time'])\n",
        "survivals.loc[:, 'Group 1'] = km1.survival_function_at_times(survivals['time']).values\n",
        "survivals.loc[:, 'Group 2'] = km2.survival_function_at_times(survivals['time']).values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zRlM1SAtYdl"
      },
      "outputs": [],
      "source": [
        "survivals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RA3amMk__J6e"
      },
      "source": [
        "This makes clear the difference in survival between the Stage III and IV cancer groups in the dataset. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VoOQREQoXny"
      },
      "source": [
        "<a name='5-1'></a>\n",
        "## 5.1 Bonus: Log-Rank Test\n",
        "\n",
        "To say whether there is a statistical difference between the survival curves we can run the log-rank test. This test tells us the probability that we could observe this data if the two curves were the same. The derivation of the log-rank test is somewhat complicated, but luckily `lifelines` has a simple function to compute it. \n",
        "\n",
        "Run the next cell to compute a p-value using `lifelines.statistics.logrank_test`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7-QIy8ovsgC",
        "outputId": "d83eb412-41eb-47a2-eab2-62dde76b615c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.009588929834755544"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def logrank_p_value(group_1_data, group_2_data):\n",
        "    result = logrank_test(group_1_data.Time, group_2_data.Time,\n",
        "                          group_1_data.Event, group_2_data.Event)\n",
        "    return result.p_value\n",
        "\n",
        "logrank_p_value(S1, S2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUbv_csdJRSw"
      },
      "source": [
        "If everything is correct, you should see a p value of less than 0.05, which indicates that the difference in the curves is indeed statistically significant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZqu9a_ChWYv"
      },
      "source": [
        "# **C.** Cox Proportional Hazards (linear) and Random Survival Forests (non-linear)\n",
        "\n",
        "Welcome to the final assignment in Course 2! In this assignment you'll develop risk models using survival data and a combination of linear and non-linear techniques. We'll be using a dataset with survival data of patients with Primary Biliary Cirrhosis (pbc). PBC is a progressive disease of the liver caused by a buildup of bile within the liver (cholestasis) that results in damage to the small bile ducts that drain bile from the liver. Our goal will be to understand the effects of different factors on the survival times of the patients. Along the way you'll learn about the following topics: \n",
        "\n",
        "- Cox Proportional Hazards\n",
        "  - Data Preprocessing for Cox Models.\n",
        "- Random Survival Forests\n",
        "  - Permutation Methods for Interpretation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifbMt2cJFLFG"
      },
      "source": [
        "## Table of Contents\n",
        "\n",
        "- [1. Import Packages](#1)\n",
        "- [2. Load the Dataset](#2)\n",
        "- [3. Explore the Dataset](#3)\n",
        "- [4. Cox Proportional Hazards](#4)\n",
        "    - [Exercise 1 - to_one_hot](#ex-1)\n",
        "- [5. Fitting and Interpreting a Cox Model](#5)\n",
        "- [6. Hazard ratio](#3)\n",
        "    - [Exercise 2 - hazard_ratio](#ex-2)\n",
        "- [7. Harrell's C-Index](#7)\n",
        "    - [Exercise 3 - harrell_c](#ex-3)\n",
        "- [8. Random Survival Forests](#8)\n",
        "- [9. Permutation Method for Interpretation](#9)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH0ukiNS3zG-"
      },
      "source": [
        "<a name='1'></a>\n",
        "## 1. Import Packages\n",
        "\n",
        "We'll first import all the packages that we need for this assignment. \n",
        "\n",
        "- `sklearn` is one of the most popular machine learning libraries.\n",
        "- `numpy` is the fundamental package for scientific computing in python.\n",
        "- `pandas` is what we'll use to manipulate our data.\n",
        "- `matplotlib` is a plotting library.\n",
        "- `lifelines` is an open-source survival analysis library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dn8zUW9lWZez"
      },
      "outputs": [],
      "source": [
        "!pip install -q lifelines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0JHzRJaQi_nU"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "from IPython.display import display\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from lifelines import CoxPHFitter\n",
        "from lifelines.utils import concordance_index as cindex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WzMty4liW0ex"
      },
      "outputs": [],
      "source": [
        "#@title tests\n",
        "\n",
        "### tests for data\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "def datatype_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += datatype_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}. Got {} but expected type {}\".format(error,\n",
        "                                                                          key, type(target_output[key]), type(expected_output[key])))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += datatype_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} in variable {}, Got {}  but expected type {}\".format(error,\n",
        "                                                                          i, type(target_output[i]), type(expected_output[i])))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        assert isinstance(target_output, type(expected_output))\n",
        "        return 1\n",
        "            \n",
        "def equation_output_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += equation_output_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(expected_output[key], \n",
        "                                         target_output[key])\n",
        "                print(\"Error: {} for variable {}.\".format(error,\n",
        "                                                                          key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += equation_output_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable in position {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            np.testing.assert_array_almost_equal(target_output, expected_output)\n",
        "        else:\n",
        "            assert target_output == expected_output\n",
        "        return 1\n",
        "    \n",
        "def shape_check(expected_output, target_output, error):\n",
        "    success = 0\n",
        "    if isinstance(target_output, dict):\n",
        "        for key in target_output.keys():\n",
        "            try:\n",
        "                success += shape_check(expected_output[key], \n",
        "                                         target_output[key], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, key))\n",
        "        if success == len(target_output.keys()):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "    elif isinstance(target_output, tuple) or isinstance(target_output, list):\n",
        "        for i in range(len(target_output)):\n",
        "            try: \n",
        "                success += shape_check(expected_output[i], \n",
        "                                         target_output[i], error)\n",
        "            except:\n",
        "                print(\"Error: {} for variable {}.\".format(error, i))\n",
        "        if success == len(target_output):\n",
        "            return 1\n",
        "        else:\n",
        "            return 0\n",
        "                \n",
        "    else:\n",
        "        if hasattr(target_output, 'shape'):\n",
        "            assert target_output.shape == expected_output.shape\n",
        "        return 1\n",
        "                \n",
        "def multiple_test(test_cases, target):\n",
        "    success = 0\n",
        "    for test_case in test_cases:\n",
        "        try:\n",
        "            target_answer = target(*test_case['input'])\n",
        "            if test_case['name'] == \"datatype_check\":\n",
        "                success += datatype_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"equation_output_check\":\n",
        "                success += equation_output_check(test_case['expected'], target_answer, test_case['error'])\n",
        "            if test_case['name'] == \"shape_check\":\n",
        "                success += shape_check(test_case['expected'], target_answer, test_case['error'])\n",
        "        except:\n",
        "            print(\"Error: \" + test_case['error'])\n",
        "            \n",
        "    if success == len(test_cases):\n",
        "        print(\"\\033[92m All tests passed.\")\n",
        "    else:\n",
        "        print('\\033[92m', success,\" Tests passed\")\n",
        "        print('\\033[91m', len(test_cases) - success, \" Tests failed\")\n",
        "        raise AssertionError(\"Not all tests were passed for {}. Check your equations and avoid using global variables inside the function.\".format(target.__name__))\n",
        "\n",
        "### general tests\n",
        "\n",
        "np.random.seed(3)\n",
        "\n",
        "### ex1\n",
        "def to_one_hot_test(target_to_one_hot, df_train, df_val, df_test):\n",
        "    to_encode = ['spiders', 'stage']\n",
        "    \n",
        "    def to_list(target_to_one_hot, to_encode, df_train, df_val, df_test):\n",
        "        one_hot_train = target_to_one_hot(df_train, to_encode)\n",
        "        one_hot_val = target_to_one_hot(df_val, to_encode)\n",
        "        one_hot_test = target_to_one_hot(df_test, to_encode)\n",
        "        \n",
        "        return one_hot_train.columns.tolist(), one_hot_val.columns.tolist(), one_hot_test.columns.tolist()\n",
        "    \n",
        "    one_hot_train_to_list, one_hot_val_to_list, one_hot_test_to_list = to_list(target_to_one_hot, to_encode, df_train, df_val, df_test)\n",
        "    \n",
        "    print(\"One hot val columns:\\n\\n\", one_hot_val_to_list, \"\\n\")\n",
        "    print(\"There are\", len(one_hot_val_to_list), \"columns\\n\")\n",
        "    \n",
        "    expected_output = (['time', 'status', 'trt', 'age', 'sex', 'ascites', 'hepato', 'edema', 'bili', \n",
        "                        'chol', 'albumin', 'copper', 'alk.phos', 'ast', 'trig', 'platelet', 'protime', 'spiders_1.0',\n",
        "                        'stage_2.0', 'stage_3.0', 'stage_4.0'], \n",
        "                       ['time', 'status', 'trt', 'age', 'sex', 'ascites', 'hepato', 'edema', 'bili', 'chol', 'albumin', \n",
        "                        'copper', 'alk.phos', 'ast', 'trig', 'platelet', 'protime', 'spiders_1.0', 'stage_2.0', 'stage_3.0',\n",
        "                        'stage_4.0'], \n",
        "                       ['time', 'status', 'trt', 'age', 'sex', 'ascites', 'hepato', 'edema', 'bili', 'chol', 'albumin', 'copper',\n",
        "                        'alk.phos', 'ast', 'trig', 'platelet', 'protime', 'spiders_1.0', 'stage_2.0', 'stage_3.0', 'stage_4.0'])\n",
        "        \n",
        "        \n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [target_to_one_hot, to_encode, df_train, df_val, df_test],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Data-type mismatch.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [target_to_one_hot, to_encode, df_train, df_val, df_test],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong shape.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [target_to_one_hot, to_encode, df_train, df_val, df_test],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong output.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, to_list)\n",
        "    \n",
        "\n",
        "\n",
        "##############################################        \n",
        "### ex2\n",
        "def hazard_ratio_test_case(i, j, one_hot_train):\n",
        "    case_1 = one_hot_train.iloc[i, :].drop(['time', 'status'])\n",
        "    case_2 = one_hot_train.iloc[j, :].drop(['time', 'status'])\n",
        "    \n",
        "    return case_1, case_2\n",
        "\n",
        "\n",
        "def hazard_ratio_test(target, i, j, one_hot_train, cph):\n",
        "    case_1, case_2 = hazard_ratio_test_case(i, j, one_hot_train)\n",
        "    \n",
        "    print(target(case_1.values, case_2.values, cph.params_.values), \"\\n\")\n",
        "    \n",
        "    expected_output = np.float64(15.029022704011822)  #np.float64(15.029017732492221)\n",
        "    \n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [case_1.values, case_2.values, cph.params_.values],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Data-type mismatch.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [case_1.values, case_2.values, cph.params_.values],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong shape.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [case_1.values, case_2.values, cph.params_.values],\n",
        "            \"expected\": expected_output,\n",
        "            \"error\": \"Wrong output. One possible solution: make sure i = 1 and j = 5\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, target)\n",
        "    \n",
        "\n",
        "\n",
        "##############################################        \n",
        "### ex3\n",
        "def harrell_c_test_case():\n",
        "    y_true_1 = [30, 12, 84, 9]\n",
        "    \n",
        "    event_1 = [1, 1, 1, 1]\n",
        "    scores_1 = [0.5, 0.9, 0.1, 1.0]\n",
        "    \n",
        "    scores_2 = [0.9, 0.5, 1.0, 0.1]\n",
        "    \n",
        "    event_3 = [1, 0, 1, 1]\n",
        "    scores_3 = [0.5, 0.9, 0.1, 1.0]\n",
        "    \n",
        "    y_true_4 = [30, 30, 20, 20]\n",
        "    event_4 = [1, 0, 1, 0]\n",
        "    scores_4 = [10, 5, 15, 20]\n",
        "    \n",
        "    y_true_5 = list(reversed([30, 30, 30, 20, 20]))\n",
        "    event_5 = [0, 1, 0, 1, 0]\n",
        "    scores_5 = list(reversed([15, 10, 5, 15, 20]))\n",
        "    \n",
        "    y_true_6 = [10,10]\n",
        "    event_6 = [0,1]\n",
        "    scores_6 = [4,5]\n",
        "    \n",
        "    return y_true_1, event_1, scores_1, scores_2, event_3, scores_3, y_true_4, event_4, scores_4, y_true_5, event_5, scores_5, y_true_6, event_6, scores_6\n",
        "\n",
        "\n",
        "def harrell_c_test(target):\n",
        "    \n",
        "    y_true_1, event_1, scores_1, scores_2, event_3, scores_3, y_true_4, event_4, scores_4, y_true_5, event_5, scores_5, y_true_6, event_6, scores_6 = harrell_c_test_case()\n",
        "    \n",
        "    print(\"Test Case 1\\n\")\n",
        "    print(\"y_true: \", y_true_1)\n",
        "    print(\"scores: \", scores_1)\n",
        "    print(\"event:  \", event_1)\n",
        "    print(\"Output: \", target(y_true_1, scores_1, event_1))\n",
        "    expected_output_1 = 1.0\n",
        "    \n",
        "    print(\"\\nTest Case 2\\n\")\n",
        "    print(\"y_true: \", y_true_1)\n",
        "    print(\"scores: \", scores_2)\n",
        "    print(\"event:  \", event_1)\n",
        "    print(\"Output: \", target(y_true_1, scores_2, event_1))\n",
        "    expected_output_2 = 0.0\n",
        "    \n",
        "    print(\"\\nTest Case 3\\n\")\n",
        "    print(\"y_true: \", y_true_1)\n",
        "    print(\"scores: \", scores_3)\n",
        "    print(\"event:  \", event_3)\n",
        "    print(\"Output: \", target(y_true_1, scores_3, event_3))\n",
        "    expected_output_3 = 1.0\n",
        "    \n",
        "    print(\"\\nTest Case 4\\n\")\n",
        "    print(\"y_true: \", y_true_4)\n",
        "    print(\"scores: \", scores_4)\n",
        "    print(\"event:  \", event_4)\n",
        "    print(\"Output: \", target(y_true_4, scores_4, event_4))\n",
        "    expected_output_4 = 0.75\n",
        "    \n",
        "    print(\"\\nTest Case 5\\n\")\n",
        "    print(\"y_true: \", y_true_5)\n",
        "    print(\"scores: \", scores_5)\n",
        "    print(\"event:  \", event_5)\n",
        "    print(\"Output: \", target(y_true_5, scores_5, event_5))\n",
        "    expected_output_5 = 0.5833333333333334\n",
        "    \n",
        "    print(\"\\nTes Case 6\\n\")\n",
        "    print(\"y_true: \", y_true_6)\n",
        "    print(\"scores: \", scores_6)\n",
        "    print(\"event:  \", event_6)\n",
        "    print(\"Output: \", target(y_true_6, scores_6, event_6), \"\\n\")\n",
        "    expected_output_6 = 1.0\n",
        "    \n",
        "    test_cases = [\n",
        "        {\n",
        "            \"name\":\"datatype_check\",\n",
        "            \"input\": [y_true_1, scores_1, event_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Data-type mismatch for Test Case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"shape_check\",\n",
        "            \"input\": [y_true_1, scores_1, event_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Wrong shape for Test Case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true_1, scores_1, event_1],\n",
        "            \"expected\": expected_output_1,\n",
        "            \"error\": \"Wrong output for Test Case 1.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true_1, scores_2, event_1],\n",
        "            \"expected\": expected_output_2,\n",
        "            \"error\": \"Wrong output for Test Case 2.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true_1, scores_3, event_3],\n",
        "            \"expected\": expected_output_3,\n",
        "            \"error\": \"Wrong output for Test Case 3.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true_4, scores_4, event_4],\n",
        "            \"expected\": expected_output_4,\n",
        "            \"error\": \"Wrong output for Test Case 4.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true_5, scores_5, event_5],\n",
        "            \"expected\": expected_output_5,\n",
        "            \"error\": \"Wrong output for Test Case 5.\"\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"equation_output_check\",\n",
        "            \"input\": [y_true_6, scores_6, event_6],\n",
        "            \"expected\": expected_output_6,\n",
        "            \"error\": \"Wrong output for Test Case 6.\"\n",
        "        }\n",
        "    ]\n",
        "    \n",
        "    multiple_test(test_cases, target)\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZMwq0VfW5TW"
      },
      "source": [
        "<a name='2'></a>\n",
        "## 2. Load the Dataset\n",
        "\n",
        "Run the next cell to load the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gZmpv0ZtFLFL"
      },
      "outputs": [],
      "source": [
        "def load_data(data):\n",
        "    df = pd.read_csv(data)\n",
        "    df = df.drop('id', axis=1)\n",
        "    df = df[df.status != 1]\n",
        "    df.loc[:, 'status'] = df.status / 2.0\n",
        "    df.loc[:, 'time'] = df.time / 365.0\n",
        "    df.loc[:, 'trt'] = df.trt - 1\n",
        "    df.loc[:, 'sex'] = df.sex.map({'f':0.0, 'm':1.0})\n",
        "    df = df.dropna(axis=0)\n",
        "\n",
        "    return df\n",
        "\n",
        "df = load_data('./pbc.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMOzDJ7qFLFM"
      },
      "source": [
        "<a name='3'></a>\n",
        "## 3. Explore the Dataset\n",
        "\n",
        "In the lecture videos `time` was in months, however in this assignment, `time` will be converted into years. Also notice that we have assigned a numeric value to `sex`, where `female = 0` and `male = 1`.\n",
        "\n",
        "Next, familiarize yourself with the data and the shape of it. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1a_aHGmXT_C"
      },
      "outputs": [],
      "source": [
        "print(df.shape)\n",
        "\n",
        "# df.head() only outputs the top few rows\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy5BmjCV-Uo2"
      },
      "source": [
        "Take a minute to examine particular cases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "01I3ChzL-T-f"
      },
      "outputs": [],
      "source": [
        "i = 20\n",
        "df.iloc[i, :]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYZKl_9Tk2vS"
      },
      "source": [
        "Now, split your dataset into train, validation and test set using 60/20/20 split. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4HJSZaMk1xG"
      },
      "outputs": [],
      "source": [
        "np.random.seed(0)\n",
        "df_dev, df_test = train_test_split(df, test_size = 0.2)\n",
        "df_train, df_val = train_test_split(df_dev, test_size = 0.25)\n",
        "\n",
        "print(\"Total number of patients:\", df.shape[0])\n",
        "print(\"Total number of patients in training set:\", df_train.shape[0])\n",
        "print(\"Total number of patients in validation set:\", df_val.shape[0])\n",
        "print(\"Total number of patients in test set:\", df_test.shape[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i2di-Zn0FLFP"
      },
      "source": [
        "Before proceeding to modeling, let's normalize the continuous covariates to make sure they're on the same scale. Again, we should normalize the test data using statistics from the train data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhJjd8neFLFQ"
      },
      "outputs": [],
      "source": [
        "continuous_columns = ['age', 'bili', 'chol', 'albumin', 'copper', 'alk.phos', 'ast', 'trig', 'platelet', 'protime']\n",
        "mean = df_train.loc[:, continuous_columns].mean()\n",
        "std = df_train.loc[:, continuous_columns].std()\n",
        "df_train.loc[:, continuous_columns] = (df_train.loc[:, continuous_columns] - mean) / std\n",
        "df_val.loc[:, continuous_columns] = (df_val.loc[:, continuous_columns] - mean) / std\n",
        "df_test.loc[:, continuous_columns] = (df_test.loc[:, continuous_columns] - mean) / std"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmhUwaxqFLFQ"
      },
      "source": [
        "Let's check the summary statistics on our training dataset to make sure it's standardized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zb5OWawjFLFR"
      },
      "outputs": [],
      "source": [
        "df_train.loc[:, continuous_columns].describe()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "BX3woHz-jit1"
      },
      "source": [
        "<a name='4'></a>\n",
        "## 4. Cox Proportional Hazards\n",
        "\n",
        "Our goal is to build a risk score using the survival data that we have. We'll begin by fitting a Cox Proportional Hazards model to your data.\n",
        "\n",
        "Recall that the Cox Proportional Hazards model describes the hazard for an individual $i$ at time $t$ as \n",
        "\n",
        "$$\n",
        "\\lambda(t, x) = \\lambda_0(t)e^{\\theta^T X_i}\n",
        "$$\n",
        "\n",
        "The $\\lambda_0$ term is a baseline hazard and incorporates the risk over time, and the other term incorporates the risk due to the individual's covariates. After fitting the model, we can rank individuals using the person-dependent risk term $e^{\\theta^T X_i}$. \n",
        "\n",
        "Categorical variables cannot be used in a regression model as they are. In order to use them, conversion to a series of variables is required.\n",
        "\n",
        "Since our data has a mix of categorical (`stage`) and continuous (`wblc`) variables, before we proceed further we need to do some data engineering. To tackle the issue at hand we'll be using the `Dummy Coding` technique. In order to use Cox Proportional Hazards, we will have to turn the categorical data into one hot features so that we can fit our Cox model. Luckily, Pandas has a built-in function called `get_dummies` that will make it easier for us to implement our function. It turns categorical features into multiple binary features.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0EQP7iY9FLFS"
      },
      "source": [
        "<a name='ex-1'></a>\n",
        "### Exercise 1 - to_one_hot\n",
        "In the cell below, implement the `to_one_hot(...)` function."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K1D-YpDaFLFS"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>Remember to drop the first dummy for each each category to avoid convergence issues when fitting the proportional hazards model.</li>\n",
        "    <li> Check out the <a href=\"https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html\" > get_dummies() </a>  documentation. </li>\n",
        "    <li>Use <code>dtype=np.float64</code>.</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VMzvx0xF_C3I"
      },
      "outputs": [],
      "source": [
        "\n",
        "def to_one_hot(dataframe, columns):\n",
        "    '''\n",
        "    Convert columns in dataframe to one-hot encoding.\n",
        "    Args:\n",
        "        dataframe (dataframe): pandas dataframe containing covariates\n",
        "        columns (list of strings): list categorical column names to one hot encode\n",
        "    Returns:\n",
        "        one_hot_df (dataframe): dataframe with categorical columns encoded\n",
        "                            as binary variables\n",
        "    '''\n",
        "    \n",
        "    one_hot_df = pd.get_dummies(dataframe, columns = columns, drop_first = True, dtype=np.float64)\n",
        "    \n",
        "    return one_hot_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGZfLeup_fUL"
      },
      "outputs": [],
      "source": [
        "# test cell ex1 - do not modify this test cell\n",
        "to_one_hot_test(to_one_hot, df_train, df_val, df_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIktMuEgFLFT"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "One hot val columns:\n",
        "\n",
        " ['time', 'status', 'trt', 'age', 'sex', 'ascites', 'hepato', 'edema', 'bili', 'chol', 'albumin', 'copper', 'alk.phos', 'ast', 'trig', 'platelet', 'protime', 'spiders_1.0', 'stage_2.0', 'stage_3.0', 'stage_4.0'] \n",
        "\n",
        "There are 21 columns\n",
        "\n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "APPrSp1OFLFT"
      },
      "source": [
        "Now you'll use the function you coded to transform the training, validation, and test sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fdDmpOBFLFU"
      },
      "outputs": [],
      "source": [
        "to_encode = ['edema', 'stage']\n",
        "\n",
        "one_hot_train = to_one_hot(df_train, to_encode)\n",
        "one_hot_val = to_one_hot(df_val, to_encode)\n",
        "one_hot_test = to_one_hot(df_test, to_encode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qlU-LS26FLFU"
      },
      "source": [
        "### Look for new features\n",
        "Now, let's take a peek at one of the transformed data sets. Do you notice any new features?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w8EG8A9gXcpu"
      },
      "outputs": [],
      "source": [
        "print(one_hot_train.shape)\n",
        "one_hot_train.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNxuymLwyjqM"
      },
      "source": [
        "<a name='5'></a>\n",
        "## 5. Fitting and Interpreting a Cox Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygiFcUKcAFQk"
      },
      "source": [
        "Run the following cell to fit your Cox Proportional Hazards model using the `lifelines` package."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dDCS7p3xjbXB",
        "outputId": "df376cae-f7a5-4334-af8a-bceaf0b4d863"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<lifelines.CoxPHFitter: fitted with 154 total observations, 90 right-censored observations>"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cph = CoxPHFitter()\n",
        "cph.fit(one_hot_train, duration_col = 'time', event_col = 'status', fit_options = {'step_size':0.1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MUITR0QANDH"
      },
      "source": [
        "You can use `cph.print_summary()` to view the coefficients associated with each covariate as well as confidence intervals. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fH5AZs8vjcEv"
      },
      "outputs": [],
      "source": [
        "cph.print_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCNgwgCzFLFW"
      },
      "source": [
        "**Question:**\n",
        "\n",
        "- According to the model, was treatment `trt` beneficial? \n",
        "- What was its associated hazard ratio? \n",
        "    - Note that the hazard ratio is how much an incremental increase in the feature variable changes the hazard."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClZ9BYyVFLFW"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Check your answer!</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "<ul>\n",
        "    <li>You should see that the treatment (trt) was beneficial because it has a negative impact on the hazard (the coefficient is negative, and exp(coef) is less than 1).</li>\n",
        "    <li>The associated hazard ratio is ~0.8, because this is the exp(coef) of treatment.</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2J0Mn_cYFLFX"
      },
      "source": [
        "We can compare the predicted survival curves for treatment variables. Run the next cell to plot survival curves using the `plot_covariate_groups()` function. \n",
        "- The y-axis is th survival rate\n",
        "- The x-axis is time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "Uxl0icyBS4Dr",
        "outputId": "bf2778d0-6d1d-4ecc-d253-709c2159ff50"
      },
      "outputs": [],
      "source": [
        "cph.plot_covariate_groups('trt', values=[0, 1]);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "drt4Mz11FLFX"
      },
      "source": [
        "Notice how the group without treatment has a lower survival rate at all times (the x-axis is time) compared to the treatment group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lL_ku4btFLFX"
      },
      "source": [
        "<a name='6'></a>\n",
        "## 6. Hazard Ratio\n",
        "\n",
        "Recall from the lecture videos that the Hazard Ratio between two patients was the likelihood of one patient (e.g smoker) being more at risk than the other (e.g non-smoker).\n",
        "$$\n",
        "\\frac{\\lambda_{smoker}(t)}{\\lambda_{nonsmoker}(t)} = e^{\\theta (X_{smoker} - X_{nonsmoker})^T}\n",
        "$$\n",
        "\n",
        "Where\n",
        "\n",
        "$$\n",
        "\\lambda_{smoker}(t) = \\lambda_0(t)e^{\\theta X_{smoker}^T}\n",
        "$$\n",
        "and\n",
        "$$\n",
        "\\lambda_{nonsmoker}(t) = \\lambda_0(t)e^{\\theta X_{nonsmoker}^T} \\\\\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHophtsFLFY"
      },
      "source": [
        "<a name='ex-2'></a>\n",
        "### Exercise 2 - hazard_ratio\n",
        "In the cell below, write a function to compute the hazard ratio between two individuals given the cox model's coefficients."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qmk0y7G1FLFZ"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>use numpy.dot</li>\n",
        "    <li>use nump.exp</li>\n",
        "</ul>\n",
        "</p>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WbBmxbeDA3k1"
      },
      "outputs": [],
      "source": [
        "def hazard_ratio(case_1, case_2, cox_params):\n",
        "    '''\n",
        "    Return the hazard ratio of case_1 : case_2 using\n",
        "    the coefficients of the cox model.\n",
        "    \n",
        "    Args:\n",
        "        case_1 (np.array): (1 x d) array of covariates\n",
        "        case_2 (np.array): (1 x d) array of covariates\n",
        "        model (np.array): (1 x d) array of cox model coefficients\n",
        "    Returns:\n",
        "        hazard_ratio (float): hazard ratio of case_1 : case_2\n",
        "    '''\n",
        "    \n",
        "    hr = np.exp(cox_params.dot((case_1 - case_2).T))\n",
        "    \n",
        "    return hr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbDQUxE6CcA3"
      },
      "source": [
        "Now, evaluate it on the following pair of indivduals: `i = 1` and `j = 5`. Given your implementation of `hazard_ratio` is correct, you will **only** pass the test when `i = 1` and `j = 5`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7flsvTRXCgqO"
      },
      "outputs": [],
      "source": [
        "# test cell ex2\n",
        "\n",
        "# Set i = 1 and j = 5 to pass the test\n",
        "i = 1\n",
        "j = 5\n",
        "\n",
        "hazard_ratio_test(hazard_ratio, i, j, one_hot_train, cph)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCu4xsq1FLFa"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "15.029017732492221 \n",
        "\n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tgUqxr1SFLFa"
      },
      "source": [
        "**Question:** \n",
        "\n",
        "Is `case_1` or `case_2` at greater risk? "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44fyTTG4FLFa"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Check your answer!</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "<ul>\n",
        "    Important! The following answer only applies if you picked i = 1 and j = 5\n",
        "    <li>You should see that `case_1` is at higher risk.</li>\n",
        "    <li>The hazard ratio of case 1 / case 2 is greater than 1, so case 1 had a higher hazard relative to case 2</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "psI5U1BdFLFb"
      },
      "source": [
        "Inspect different pairs, and see if you can figure out which patient is more at risk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2PZ3sGvCs0K"
      },
      "outputs": [],
      "source": [
        "i = 4\n",
        "case_1 = one_hot_train.iloc[i, :].drop(['time', 'status'])\n",
        "\n",
        "j = 7\n",
        "case_2 = one_hot_train.iloc[j, :].drop(['time', 'status'])\n",
        "\n",
        "print(\"Case 1\\n\\n\", case_1, \"\\n\")\n",
        "print(\"Case 2\\n\\n\", case_2, \"\\n\")\n",
        "print(\"Hazard Ratio:\", hazard_ratio(case_1.values, case_2.values, cph.params_.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kH_H3KTcFLFb"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Check your answer!</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "<ul>\n",
        "    Important! The following answer only applies if you picked i = 4 and j = 7\n",
        "    <li>You should see that `case_2` is at higher risk.</li>\n",
        "    <li>The hazard ratio of case 1 / case 2 is less than 1, so case 2 had a higher hazard relative to case 1</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUa6r-KOyySp"
      },
      "source": [
        "<a name='7'></a>\n",
        "## 7. Harrell's C-index"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "woQAtSmRXrgr"
      },
      "source": [
        "To evaluate how good our model is performing, we will write our own version of the C-index. Similar to the week 1 case, C-index in the survival context is the probability that, given a randomly selected pair of individuals, the one who died sooner has a higher risk score. \n",
        "\n",
        "However, we need to take into account censoring. Imagine a pair of patients, $A$ and $B$. \n",
        "\n",
        "#### Scenario 1\n",
        "- A was censored at time $t_A$ \n",
        "- B died at $t_B$\n",
        "- $t_A < t_B$. \n",
        "\n",
        "Because of censoring, we can't say whether $A$ or $B$ should have a higher risk score. \n",
        "\n",
        "#### Scenario 2\n",
        "Now imagine that $t_A > t_B$.\n",
        "\n",
        "- A was censored at time $t_A$ \n",
        "- B died at $t_B$\n",
        "- $t_A > t_B$\n",
        "\n",
        "Now we can definitively say that $B$ should have a higher risk score than $A$, since we know for a fact that $A$ lived longer. \n",
        "\n",
        "Therefore, when we compute our C-index\n",
        "- We should only consider pairs where at most one person is censored\n",
        "- If they are censored, then their censored time should occur *after* the other person's time of death. \n",
        "\n",
        "The metric we get if we use this rule is called **Harrel's C-index**.\n",
        "\n",
        "Note that in this case, being censored at time $t$ means that the true death time was some time AFTER time $t$ and not at $t$. \n",
        "- Therefore if $t_A = t_B$ and A was censored:\n",
        "    - Then $A$ actually lived longer than $B$. \n",
        "    - This will effect how you deal with ties in the exercise below!\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nyn7rZGQFLFc"
      },
      "source": [
        "<a name='ex-3'></a>\n",
        "### Exercise 3 - harrell_c\n",
        "Fill in the function below to compute Harrel's C-index."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nQkINzfkFLFc"
      },
      "source": [
        "<details>    \n",
        "<summary>\n",
        "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
        "</summary>\n",
        "<p>\n",
        "<ul>\n",
        "    <li>If you get a division by zero error, consider checking how you count when a pair is permissible (in the case where one patient is censored and the other is not censored).</li>\n",
        "</ul>\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UYsAf0SZFLFd"
      },
      "outputs": [],
      "source": [
        "\n",
        "def harrell_c(y_true, scores, event):\n",
        "    '''\n",
        "    Compute Harrel C-index given true event/censoring times,\n",
        "    model output, and event indicators.\n",
        "    \n",
        "    Args:\n",
        "        y_true (array): array of true event times\n",
        "        scores (array): model risk scores\n",
        "        event (array): indicator, 1 if event occurred at that index, 0 for censorship\n",
        "    Returns:\n",
        "        result (float): C-index metric\n",
        "    '''\n",
        "    \n",
        "    n = len(y_true)\n",
        "    assert (len(scores) == n and len(event) == n)\n",
        "    \n",
        "    concordant = 0.0\n",
        "    permissible = 0.0\n",
        "    ties = 0.0\n",
        "    \n",
        "    result = 0.0\n",
        "    \n",
        "    # use double for loop to go through cases\n",
        "    for i in range(n):\n",
        "        # set lower bound on j to avoid double counting\n",
        "        for j in range(i+1, n):\n",
        "            \n",
        "            # check if at most one is censored\n",
        "            if event[i] == 1 or event[j] == 1:\n",
        "            \n",
        "                # check if neither are censored\n",
        "                if event[i] == 1 and event[j] == 1:\n",
        "                    \n",
        "                    permissible += 1.0\n",
        "                    \n",
        "                    # check if scores are tied\n",
        "                    if scores[i] == scores[j]:\n",
        "                        ties += 1.0\n",
        "                    \n",
        "                    # check for concordant\n",
        "                    elif y_true[i] < y_true[j] and scores[i] > scores[j]:\n",
        "                        concordant += 1.0\n",
        "                    elif y_true[i] > y_true[j] and scores[i] < scores[j]:\n",
        "                        concordant += 1.0\n",
        "                \n",
        "                # check if one is censored\n",
        "                elif event[i] != event[j]:\n",
        "                    \n",
        "                    # get censored index\n",
        "                    censored = j\n",
        "                    uncensored = i\n",
        "                    \n",
        "                    if event[i] == 0:\n",
        "                        censored = i\n",
        "                        uncensored = j\n",
        "                        \n",
        "                    # check if permissible\n",
        "                    # Note: in this case, we are assuming that censored at a time\n",
        "                    # means that you did NOT die at that time. That is, if you\n",
        "                    # live until time 30 and have event = 0, then you lived THROUGH\n",
        "                    # time 30.\n",
        "                    if y_true[uncensored] <= y_true[censored]:\n",
        "                        permissible += 1.0\n",
        "                        \n",
        "                        # check if scores are tied\n",
        "                        if scores[uncensored] == scores[censored]:\n",
        "                            # update ties \n",
        "                            ties += 1.0\n",
        "                            \n",
        "                        # check if scores are concordant \n",
        "                        if scores[uncensored] > scores[censored]:\n",
        "                            concordant += 1.0\n",
        "    \n",
        "    # set result to c-index computed from number of concordant pairs,\n",
        "    # number of ties, and number of permissible pairs (REPLACE 0 with your code)  \n",
        "    result = (concordant + 0.5*ties) / permissible\n",
        "    \n",
        "    return result   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJxmvYvUFLFd"
      },
      "outputs": [],
      "source": [
        "# test cell ex1 - do not modify this test cell\n",
        "harrell_c_test(harrell_c)    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhxoHjMIFLFe"
      },
      "source": [
        "#### Expected Output:\n",
        "```\n",
        "Test Case 1\n",
        "Output:  1.0\n",
        "\n",
        "Test Case 2\n",
        "Output:  0.0\n",
        "\n",
        "Test Case 3\n",
        "Output:  1.0\n",
        "\n",
        "Test Case 4\n",
        "Output:  0.75\n",
        "\n",
        "Test Case 5\n",
        "Output:  0.5833333333333334\n",
        "\n",
        "Tes Case 6\n",
        "Output:  1.0 \n",
        "\n",
        " All tests passed.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CtQVe4pAn8ic"
      },
      "source": [
        "Now use the Harrell's C-index function to evaluate the cox model on our data sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8nzHc_Qbn7dM"
      },
      "outputs": [],
      "source": [
        "# Train\n",
        "scores = cph.predict_partial_hazard(one_hot_train)\n",
        "cox_train_scores = harrell_c(one_hot_train['time'].values, scores.values, one_hot_train['status'].values)\n",
        "# Validation\n",
        "scores = cph.predict_partial_hazard(one_hot_val)\n",
        "cox_val_scores = harrell_c(one_hot_val['time'].values, scores.values, one_hot_val['status'].values)\n",
        "# Test\n",
        "scores = cph.predict_partial_hazard(one_hot_test)\n",
        "cox_test_scores = harrell_c(one_hot_test['time'].values, scores.values, one_hot_test['status'].values)\n",
        "\n",
        "print(\"Train:\", cox_train_scores)\n",
        "print(\"Val:\", cox_val_scores)\n",
        "print(\"Test:\", cox_test_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rA4hvCG6FLFf"
      },
      "source": [
        "What do these values tell us ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AuNjR_wNkpWz"
      },
      "source": [
        "<a name='8'></a>\n",
        "## 8. Random Survival Forests\n",
        "\n",
        "This performed well, but you have a hunch you can squeeze out better performance by using a machine learning approach. You decide to use a Random Survival Forest. To do this, you can use the `RandomForestSRC` package in R. To call R function from Python, we'll use the `r2py` package. Run the following cell to import the necessary requirements. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M6ODLAFRa3Yi"
      },
      "outputs": [],
      "source": [
        "#!pip install rpy2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgSy-Dj6kquK"
      },
      "outputs": [],
      "source": [
        "%load_ext rpy2.ipython\n",
        "%R require(ggplot2)\n",
        "\n",
        "# from rpy2.robjects.packages import importr\n",
        "# # import R's \"base\" package\n",
        "# base = importr('base')\n",
        "\n",
        "# # import R's \"utils\" package\n",
        "# utils = importr('utils')\n",
        "\n",
        "# # import rpy2's package module\n",
        "# import rpy2.robjects.packages as rpackages\n",
        "\n",
        "# ## forest = rpackages.importr('randomForestSRC', lib_loc='R')\n",
        "# forest = rpackages.importr('randomForestSRC') \n",
        "\n",
        "# from rpy2 import robjects as ro\n",
        "# R = ro.r\n",
        "\n",
        "# from rpy2.robjects import pandas2ri\n",
        "# pandas2ri.activate()\n",
        "\n",
        "#-------------------------------------------\n",
        "\n",
        "# import rpy2's package module\n",
        "import rpy2.robjects.packages as rpackages\n",
        "\n",
        "# import R's utility package\n",
        "utils = rpackages.importr('utils')\n",
        "\n",
        "# select a mirror for R packages\n",
        "utils.chooseCRANmirror(ind=1) # select the first mirror in the list\n",
        "\n",
        "# R package names\n",
        "packnames = ('ggplot2', 'randomForestSRC')\n",
        "\n",
        "# R vector of strings\n",
        "from rpy2.robjects.vectors import StrVector\n",
        "\n",
        "# Selectively install what needs to be install.\n",
        "# We are fancy, just because we can.\n",
        "names_to_install = [x for x in packnames if not rpackages.isinstalled(x)]\n",
        "if len(names_to_install) > 0:\n",
        "    utils.install_packages(StrVector(names_to_install))\n",
        "\n",
        "\n",
        "\n",
        "forest = rpackages.importr('randomForestSRC') \n",
        "\n",
        "from rpy2 import robjects as ro\n",
        "R = ro.r\n",
        "\n",
        "from rpy2.robjects import pandas2ri\n",
        "pandas2ri.activate()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LXBgqQBfuMA5"
      },
      "source": [
        "Instead of encoding our categories as binary features, we can use the original dataframe since trees deal well with raw categorical data (can you think why this might be?).\n",
        "\n",
        "Run the code cell below to build your forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B-pio4o4mdVJ"
      },
      "outputs": [],
      "source": [
        "model = forest.rfsrc(ro.Formula('Surv(time, status) ~ .'), data=df_train, ntree=300, nodedepth=5, seed=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZfcUvJ3nL04"
      },
      "outputs": [],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Mwzm55H-QKV"
      },
      "source": [
        "Finally, let's evaluate on our validation and test sets, and compare it with our Cox model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vfl4LbGfpbKp",
        "outputId": "a3237dc1-4c30-47da-d726-b22839d8a054"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cox Model Validation Score: 0.8544776119402985\n",
            "Survival Forest Validation Score: 0.8296019900497512\n"
          ]
        }
      ],
      "source": [
        "result = R.predict(model, newdata=df_val)\n",
        "scores = np.array(result.rx('predicted')[0])\n",
        "\n",
        "print(\"Cox Model Validation Score:\", cox_val_scores)\n",
        "print(\"Survival Forest Validation Score:\", harrell_c(df_val['time'].values, scores, df_val['status'].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uhqSQJhrplSG",
        "outputId": "6db0d808-055d-46af-9780-111b564df693"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cox Model Test Score: 0.8478543563068921\n",
            "Survival Forest Validation Score: 0.8621586475942783\n"
          ]
        }
      ],
      "source": [
        "result = R.predict(model, newdata=df_test)\n",
        "scores = np.array(result.rx('predicted')[0])\n",
        "\n",
        "print(\"Cox Model Test Score:\", cox_test_scores)\n",
        "print(\"Survival Forest Validation Score:\", harrell_c(df_test['time'].values, scores, df_test['status'].values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gp_SgUXreAWn"
      },
      "source": [
        "Your random forest model should be outperforming the Cox model slightly. Let's dig deeper to see how they differ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZtPMPaSli8GB"
      },
      "source": [
        "<a name='9'></a>\n",
        "## 9. Permutation Method for Interpretation\n",
        "\n",
        "We'll dig a bit deeper into interpretation methods for forests a bit later, but for now just know that random surival forests come with their own built in variable importance feature. The method is referred to as VIMP, and for the purpose of this section you should just know that higher absolute value of the VIMP means that the variable generally has a larger effect on the model outcome.\n",
        "\n",
        "Run the next cell to compute and plot VIMP for the random survival forest."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u7M4_N_d-YJu"
      },
      "outputs": [],
      "source": [
        "vimps = np.array(forest.vimp(model).rx('importance')[0])\n",
        "\n",
        "y = np.arange(len(vimps))\n",
        "plt.barh(y, np.abs(vimps))\n",
        "plt.yticks(y, df_train.drop(['time', 'status'], axis=1).columns)\n",
        "plt.title(\"VIMP (absolute value)\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "6NzLKfypU5KJ",
        "IMWP1Iq01T3q",
        "h9hbgZTZSAIL",
        "3Q2KuaRamHfr",
        "EZqu9a_ChWYv"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
