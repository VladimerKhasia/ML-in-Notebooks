{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DSWwLBrZeMe_"
      },
      "source": [
        "Data is available here: https://drive.google.com/file/d/17q8hIFttHLQAGdfzVZ3vost2TqOFLCPR/view?usp=sharing \n",
        "\n",
        "Data comes from: [Decathlon 10 Challenge](https://decathlon-10.grand-challenge.org). \n",
        "\n",
        "Format: [NifTI-1 format](https://nifti.nimh.nih.gov/nifti-1/) \n",
        "Library: [NiBabel library](https://nipy.org/nibabel/nibabel_images.html)\n",
        "\n",
        "other possibility:\n",
        "Format: DICOM format\n",
        "Library: [pydicom](https://pydicom.github.io/)  library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:11.197002Z",
          "start_time": "2020-03-08T01:28:16.130730Z"
        },
        "id": "sJz-IbUycEhT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import h5py\n",
        "import imageio\n",
        "import sys\n",
        "import json\n",
        "import nibabel as nib\n",
        "from IPython.display import Image, display\n",
        "\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import backend\n",
        "from keras import backend as K\n",
        "from keras import Input, Model\n",
        "from keras.layers import Activation, Conv3D, MaxPooling3D, UpSampling3D, Conv3DTranspose\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.compat.v1.logging import INFO, set_verbosity\n",
        "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
        "tf.compat.v1.disable_eager_execution()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DIVnzKJL_qtB"
      },
      "outputs": [],
      "source": [
        "#@title U-net model and other helpers\n",
        "\n",
        "set_verbosity(INFO)\n",
        "\n",
        "K.set_image_data_format(\"channels_first\")\n",
        "\n",
        "\n",
        "def plot_image_grid(image):\n",
        "    data_all = []\n",
        "\n",
        "    data_all.append(image)\n",
        "\n",
        "    fig, ax = plt.subplots(3, 6, figsize=[16, 9])\n",
        "\n",
        "    # coronal plane\n",
        "    coronal = np.transpose(data_all, [1, 3, 2, 4, 0])\n",
        "    coronal = np.rot90(coronal, 1)\n",
        "\n",
        "    # transversal plane\n",
        "    transversal = np.transpose(data_all, [2, 1, 3, 4, 0])\n",
        "    transversal = np.rot90(transversal, 2)\n",
        "\n",
        "    # sagittal plane\n",
        "    sagittal = np.transpose(data_all, [2, 3, 1, 4, 0])\n",
        "    sagittal = np.rot90(sagittal, 1)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(coronal.shape[2])\n",
        "        ax[0][i].imshow(np.squeeze(coronal[:, :, n, :]))\n",
        "        ax[0][i].set_xticks([])\n",
        "        ax[0][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[0][i].set_ylabel('Coronal', fontsize=15)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(transversal.shape[2])\n",
        "        ax[1][i].imshow(np.squeeze(transversal[:, :, n, :]))\n",
        "        ax[1][i].set_xticks([])\n",
        "        ax[1][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[1][i].set_ylabel('Transversal', fontsize=15)\n",
        "\n",
        "    for i in range(6):\n",
        "        n = np.random.randint(sagittal.shape[2])\n",
        "        ax[2][i].imshow(np.squeeze(sagittal[:, :, n, :]))\n",
        "        ax[2][i].set_xticks([])\n",
        "        ax[2][i].set_yticks([])\n",
        "        if i == 0:\n",
        "            ax[2][i].set_ylabel('Sagittal', fontsize=15)\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "\n",
        "def visualize_data_gif(data_):\n",
        "    images = []\n",
        "    for i in range(data_.shape[0]):\n",
        "        x = data_[min(i, data_.shape[0] - 1), :, :]\n",
        "        y = data_[:, min(i, data_.shape[1] - 1), :]\n",
        "        z = data_[:, :, min(i, data_.shape[2] - 1)]\n",
        "        img = np.concatenate((x, y, z), axis=1)\n",
        "        images.append(img)\n",
        "    imageio.mimsave(\"/tmp/gif.gif\", images, duration=0.01)\n",
        "    return Image(filename=\"/tmp/gif.gif\", format='png')\n",
        "\n",
        "\n",
        "# Some code was borrowed from:\n",
        "# https://github.com/ellisdg/3DUnetCNN/blob/master/unet3d/\n",
        "\n",
        "\n",
        "def create_convolution_block(input_layer, n_filters, batch_normalization=False,\n",
        "                             kernel=(3, 3, 3), activation=None,\n",
        "                             padding='same', strides=(1, 1, 1),\n",
        "                             instance_normalization=False):\n",
        "    \"\"\"\n",
        "    :param strides:\n",
        "    :param input_layer:\n",
        "    :param n_filters:\n",
        "    :param batch_normalization:\n",
        "    :param kernel:\n",
        "    :param activation: Keras activation layer to use. (default is 'relu')\n",
        "    :param padding:\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    layer = Conv3D(n_filters, kernel, padding=padding, strides=strides)(\n",
        "        input_layer)\n",
        "    if activation is None:\n",
        "        return Activation('relu')(layer)\n",
        "    else:\n",
        "        return activation()(layer)\n",
        "\n",
        "\n",
        "def get_up_convolution(n_filters, pool_size, kernel_size=(2, 2, 2),\n",
        "                       strides=(2, 2, 2),\n",
        "                       deconvolution=False):\n",
        "    if deconvolution:\n",
        "        return Conv3DTranspose(filters=n_filters, kernel_size=kernel_size,\n",
        "                               strides=strides)\n",
        "    else:\n",
        "        return UpSampling3D(size=pool_size)\n",
        "\n",
        "\n",
        "def unet_model_3d(loss_function, input_shape=(4, 160, 160, 16),\n",
        "                  pool_size=(2, 2, 2), n_labels=3,\n",
        "                  initial_learning_rate=0.00001,\n",
        "                  deconvolution=False, depth=4, n_base_filters=32,\n",
        "                  include_label_wise_dice_coefficients=False, metrics=[],\n",
        "                  batch_normalization=False, activation_name=\"sigmoid\"):\n",
        "    \"\"\"\n",
        "    Builds the 3D UNet Keras model.f\n",
        "    :param metrics: List metrics to be calculated during model training (default is dice coefficient).\n",
        "    :param include_label_wise_dice_coefficients: If True and n_labels is greater than 1, model will report the dice\n",
        "    coefficient for each label as metric.\n",
        "    :param n_base_filters: The number of filters that the first layer in the convolution network will have. Following\n",
        "    layers will contain a multiple of this number. Lowering this number will likely reduce the amount of memory required\n",
        "    to train the model.\n",
        "    :param depth: indicates the depth of the U-shape for the model. The greater the depth, the more max pooling\n",
        "    layers will be added to the model. Lowering the depth may reduce the amount of memory required for training.\n",
        "    :param input_shape: Shape of the input data (n_chanels, x_size, y_size, z_size). The x, y, and z sizes must be\n",
        "    divisible by the pool size to the power of the depth of the UNet, that is pool_size^depth.\n",
        "    :param pool_size: Pool size for the max pooling operations.\n",
        "    :param n_labels: Number of binary labels that the model is learning.\n",
        "    :param initial_learning_rate: Initial learning rate for the model. This will be decayed during training.\n",
        "    :param deconvolution: If set to True, will use transpose convolution(deconvolution) instead of up-sampling. This\n",
        "    increases the amount memory required during training.\n",
        "    :return: Untrained 3D UNet Model\n",
        "    \"\"\"\n",
        "    inputs = Input(input_shape)\n",
        "    current_layer = inputs\n",
        "    levels = list()\n",
        "\n",
        "    # add levels with max pooling\n",
        "    for layer_depth in range(depth):\n",
        "        layer1 = create_convolution_block(input_layer=current_layer,\n",
        "                                          n_filters=n_base_filters * (\n",
        "                                                  2 ** layer_depth),\n",
        "                                          batch_normalization=batch_normalization)\n",
        "        layer2 = create_convolution_block(input_layer=layer1,\n",
        "                                          n_filters=n_base_filters * (\n",
        "                                                  2 ** layer_depth) * 2,\n",
        "                                          batch_normalization=batch_normalization)\n",
        "        if layer_depth < depth - 1:\n",
        "            current_layer = MaxPooling3D(pool_size=pool_size)(layer2)\n",
        "            levels.append([layer1, layer2, current_layer])\n",
        "        else:\n",
        "            current_layer = layer2\n",
        "            levels.append([layer1, layer2])\n",
        "\n",
        "    # add levels with up-convolution or up-sampling\n",
        "    for layer_depth in range(depth - 2, -1, -1):\n",
        "        up_convolution = get_up_convolution(pool_size=pool_size,\n",
        "                                            deconvolution=deconvolution,\n",
        "                                            n_filters=\n",
        "                                            current_layer.shape[1])(     ## or ._keras_shape\n",
        "            current_layer)\n",
        "        concat = concatenate([up_convolution, levels[layer_depth][1]], axis=1)\n",
        "        current_layer = create_convolution_block(\n",
        "            n_filters=levels[layer_depth][1].shape[1],                   ## or ._keras_shape\n",
        "            input_layer=concat, batch_normalization=batch_normalization)\n",
        "        current_layer = create_convolution_block(\n",
        "            n_filters=levels[layer_depth][1].shape[1],                   ## or ._keras_shape\n",
        "            input_layer=current_layer,\n",
        "            batch_normalization=batch_normalization)\n",
        "\n",
        "    final_convolution = Conv3D(n_labels, (1, 1, 1))(current_layer)\n",
        "    act = Activation(activation_name)(final_convolution)\n",
        "    model = Model(inputs=inputs, outputs=act)\n",
        "\n",
        "    if not isinstance(metrics, list):\n",
        "        metrics = [metrics]\n",
        "\n",
        "    model.compile(optimizer=Adam(lr=initial_learning_rate), loss=loss_function,\n",
        "                  metrics=metrics)\n",
        "    return model\n",
        "\n",
        "\n",
        "def visualize_patch(X, y):\n",
        "    fig, ax = plt.subplots(1, 2, figsize=[10, 5], squeeze=False)\n",
        "\n",
        "    ax[0][0].imshow(X[:, :, 0], cmap='Greys_r')\n",
        "    ax[0][0].set_yticks([])\n",
        "    ax[0][0].set_xticks([])\n",
        "    ax[0][1].imshow(y[:, :, 0], cmap='Greys_r')\n",
        "    ax[0][1].set_xticks([])\n",
        "    ax[0][1].set_yticks([])\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=0)\n",
        "\n",
        "\n",
        "class VolumeDataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self,\n",
        "                 sample_list,\n",
        "                 base_dir,\n",
        "                 batch_size=1,\n",
        "                 shuffle=True,\n",
        "                 dim=(160, 160, 16),\n",
        "                 num_channels=4,\n",
        "                 num_classes=3,\n",
        "                 verbose=1):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.base_dir = base_dir\n",
        "        self.dim = dim\n",
        "        self.num_channels = num_channels\n",
        "        self.num_classes = num_classes\n",
        "        self.verbose = verbose\n",
        "        self.sample_list = sample_list\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.sample_list))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.sample_list) / self.batch_size))\n",
        "\n",
        "    def __data_generation(self, list_IDs_temp):\n",
        "        'Generates data containing batch_size samples'\n",
        "\n",
        "        # Initialization\n",
        "        X = np.zeros((self.batch_size, self.num_channels, *self.dim),\n",
        "                     dtype=np.float64)\n",
        "        y = np.zeros((self.batch_size, self.num_classes, *self.dim),\n",
        "                     dtype=np.float64)\n",
        "\n",
        "        # Generate data\n",
        "        for i, ID in enumerate(list_IDs_temp):\n",
        "            # Store sample\n",
        "            if self.verbose == 1:\n",
        "                print(\"Training on: %s\" % self.base_dir + ID)\n",
        "            with h5py.File(self.base_dir + ID, 'r') as f:\n",
        "                X[i] = np.array(f.get(\"x\"))\n",
        "                # remove the background class\n",
        "                y[i] = np.moveaxis(np.array(f.get(\"y\")), 3, 0)[1:]\n",
        "        return X, y\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[\n",
        "                  index * self.batch_size: (index + 1) * self.batch_size]\n",
        "        # Find list of IDs\n",
        "        sample_list_temp = [self.sample_list[k] for k in indexes]\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(sample_list_temp)\n",
        "\n",
        "        return X, y\n",
        "\n",
        "\n",
        "def get_labeled_image(image, label, is_categorical=False):\n",
        "    if not is_categorical:\n",
        "        label = to_categorical(label, num_classes=4).astype(np.uint8)\n",
        "\n",
        "    image = cv2.normalize(image[:, :, :, 0], None, alpha=0, beta=255,\n",
        "                          norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F).astype(\n",
        "        np.uint8)\n",
        "\n",
        "    labeled_image = np.zeros_like(label[:, :, :, 1:])\n",
        "\n",
        "    # remove tumor part from image\n",
        "    labeled_image[:, :, :, 0] = image * (label[:, :, :, 0])\n",
        "    labeled_image[:, :, :, 1] = image * (label[:, :, :, 0])\n",
        "    labeled_image[:, :, :, 2] = image * (label[:, :, :, 0])\n",
        "\n",
        "    # color labels\n",
        "    labeled_image += label[:, :, :, 1:] * 255\n",
        "    return labeled_image\n",
        "\n",
        "\n",
        "def predict_and_viz(image, label, model, threshold, loc=(100, 100, 50)):\n",
        "    image_labeled = get_labeled_image(image.copy(), label.copy())\n",
        "\n",
        "    model_label = np.zeros([3, 320, 320, 160])\n",
        "\n",
        "    for x in range(0, image.shape[0], 160):\n",
        "        for y in range(0, image.shape[1], 160):\n",
        "            for z in range(0, image.shape[2], 16):\n",
        "                patch = np.zeros([4, 160, 160, 16])\n",
        "                p = np.moveaxis(image[x: x + 160, y: y + 160, z:z + 16], 3, 0)\n",
        "                patch[:, 0:p.shape[1], 0:p.shape[2], 0:p.shape[3]] = p\n",
        "                pred = model.predict(np.expand_dims(patch, 0))\n",
        "                model_label[:, x:x + p.shape[1],\n",
        "                y:y + p.shape[2],\n",
        "                z: z + p.shape[3]] += pred[0][:, :p.shape[1], :p.shape[2],\n",
        "                                      :p.shape[3]]\n",
        "\n",
        "    model_label = np.moveaxis(model_label[:, 0:240, 0:240, 0:155], 0, 3)\n",
        "    model_label_reformatted = np.zeros((240, 240, 155, 4))\n",
        "\n",
        "    model_label_reformatted = to_categorical(label, num_classes=4).astype(\n",
        "        np.uint8)\n",
        "\n",
        "    model_label_reformatted[:, :, :, 1:4] = model_label\n",
        "\n",
        "    model_labeled_image = get_labeled_image(image, model_label_reformatted,\n",
        "                                            is_categorical=True)\n",
        "\n",
        "    fig, ax = plt.subplots(2, 3, figsize=[10, 7])\n",
        "\n",
        "    # plane values\n",
        "    x, y, z = loc\n",
        "\n",
        "    ax[0][0].imshow(np.rot90(image_labeled[x, :, :, :]))\n",
        "    ax[0][0].set_ylabel('Ground Truth', fontsize=15)\n",
        "    ax[0][0].set_xlabel('Sagital', fontsize=15)\n",
        "\n",
        "    ax[0][1].imshow(np.rot90(image_labeled[:, y, :, :]))\n",
        "    ax[0][1].set_xlabel('Coronal', fontsize=15)\n",
        "\n",
        "    ax[0][2].imshow(np.squeeze(image_labeled[:, :, z, :]))\n",
        "    ax[0][2].set_xlabel('Transversal', fontsize=15)\n",
        "\n",
        "    ax[1][0].imshow(np.rot90(model_labeled_image[x, :, :, :]))\n",
        "    ax[1][0].set_ylabel('Prediction', fontsize=15)\n",
        "\n",
        "    ax[1][1].imshow(np.rot90(model_labeled_image[:, y, :, :]))\n",
        "    ax[1][2].imshow(model_labeled_image[:, :, z, :])\n",
        "\n",
        "    fig.subplots_adjust(wspace=0, hspace=.12)\n",
        "\n",
        "    for i in range(2):\n",
        "        for j in range(3):\n",
        "            ax[i][j].set_xticks([])\n",
        "            ax[i][j].set_yticks([])\n",
        "\n",
        "    return model_label_reformatted\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:36.462907Z",
          "start_time": "2020-03-08T01:29:36.458910Z"
        },
        "id": "AoW-WFWNW0cN"
      },
      "outputs": [],
      "source": [
        "# set home directory and data directory\n",
        "HOME_DIR = \"./\"\n",
        "DATA_DIR = HOME_DIR\n",
        "\n",
        "def load_case(image_nifty_file, label_nifty_file):\n",
        "    # load the image and label file, get the image content and return a numpy array for each\n",
        "    image = np.array(nib.load(image_nifty_file).get_fdata())\n",
        "    label = np.array(nib.load(label_nifty_file).get_fdata())\n",
        "    \n",
        "    return image, label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:41.377380Z",
          "start_time": "2020-03-08T01:29:38.869873Z"
        },
        "id": "ihLR2ZD-W0cU"
      },
      "outputs": [],
      "source": [
        "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
        "image = get_labeled_image(image, label)\n",
        "\n",
        "plot_image_grid(image)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:46.121069Z",
          "start_time": "2020-03-08T01:29:42.475071Z"
        },
        "id": "TJubVx44W0cf"
      },
      "outputs": [],
      "source": [
        "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
        "visualize_data_gif(get_labeled_image(image, label))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dulCuzOnW0ch"
      },
      "source": [
        "### using 3d-sub-volumes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:46.222114Z",
          "start_time": "2020-03-08T01:29:46.138071Z"
        },
        "id": "Fd3ThBwlPIiH"
      },
      "outputs": [],
      "source": [
        "def get_sub_volume(image, label, \n",
        "                   orig_x = 240, orig_y = 240, orig_z = 155, \n",
        "                   output_x = 160, output_y = 160, output_z = 16,\n",
        "                   num_classes = 4, max_tries = 1000, \n",
        "                   background_threshold=0.95):\n",
        "    \"\"\"\n",
        "    Extract random sub-volume from original images.\n",
        "\n",
        "    Args:s\n",
        "        image (np.array): original image, \n",
        "            of shape (orig_x, orig_y, orig_z, num_channels)\n",
        "        label (np.array): original label. \n",
        "            labels coded using discrete values rather than\n",
        "            a separate dimension, \n",
        "            so this is of shape (orig_x, orig_y, orig_z)\n",
        "        orig_x (int): x_dim of input image\n",
        "        orig_y (int): y_dim of input image\n",
        "        orig_z (int): z_dim of input image\n",
        "        output_x (int): desired x_dim of output\n",
        "        output_y (int): desired y_dim of output\n",
        "        output_z (int): desired z_dim of output\n",
        "        num_classes (int): number of class labels\n",
        "        max_tries (int): maximum trials to do when sampling\n",
        "        background_threshold (float): limit on the fraction \n",
        "            of the sample which can be the background\n",
        "\n",
        "    returns:\n",
        "        X (np.array): sample of original image of dimension \n",
        "            (num_channels, output_x, output_y, output_z)\n",
        "        y (np.array): labels which correspond to X, of dimension \n",
        "            (num_classes, output_x, output_y, output_z)\n",
        "    \"\"\"\n",
        "    # Initialize features and labels with `None`\n",
        "    X = None\n",
        "    y = None\n",
        "\n",
        "    tries = 0\n",
        "    \n",
        "    while tries < max_tries:\n",
        "        # randomly sample sub-volume by sampling the corner voxel\n",
        "        # hint: make sure to leave enough room for the output dimensions!\n",
        "        start_x = np.random.randint(0 , orig_x - output_x + 1)\n",
        "        start_y = np.random.randint(0 , orig_y - output_y + 1)\n",
        "        start_z = np.random.randint(0 , orig_z - output_z + 1)\n",
        "\n",
        "        # extract relevant area of label\n",
        "        y = label[start_x: start_x + output_x,\n",
        "                  start_y: start_y + output_y,\n",
        "                  start_z: start_z + output_z]\n",
        "        \n",
        "        # One-hot encode the categories.\n",
        "        # This adds a 4th dimension, 'num_classes'\n",
        "        # (output_x, output_y, output_z, num_classes)\n",
        "        y = keras.utils.to_categorical(y, num_classes = num_classes)\n",
        "\n",
        "        # compute the background ratio\n",
        "        bgrd_ratio = np.sum(y[:,:,:,0]) / (output_x * output_y * output_z)\n",
        "\n",
        "        # increment tries counter\n",
        "        tries += 1\n",
        "\n",
        "        # if background ratio is below the desired threshold,\n",
        "        # use that sub-volume.\n",
        "        # otherwise continue the loop and try another random sub-volume\n",
        "        if bgrd_ratio < background_threshold:\n",
        "\n",
        "            # make copy of the sub-volume\n",
        "            X = np.copy(image[start_x: start_x + output_x,\n",
        "                              start_y: start_y + output_y,\n",
        "                              start_z: start_z + output_z, :])\n",
        "            \n",
        "            # change dimension of X\n",
        "            # from (x_dim, y_dim, z_dim, num_channels)\n",
        "            # to (num_channels, x_dim, y_dim, z_dim)\n",
        "            X = np.moveaxis(X,3,0)\n",
        "\n",
        "            # change dimension of y\n",
        "            # from (x_dim, y_dim, z_dim, num_classes)\n",
        "            # to (num_classes, x_dim, y_dim, z_dim)\n",
        "            y = np.moveaxis(y,3,0)\n",
        "\n",
        "            ### END CODE HERE ###\n",
        "            \n",
        "            # take a subset of y that excludes the background class\n",
        "            # in the 'num_classes' dimension\n",
        "            y = y[1:, :, :, :]\n",
        "    \n",
        "            return X, y\n",
        "\n",
        "    # if we've tried max_tries number of samples\n",
        "    # Give up in order to avoid looping forever.\n",
        "    print(f\"Tried {tries} times to find a sub-volume. Giving up...\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:49.157586Z",
          "start_time": "2020-03-08T01:29:47.726586Z"
        },
        "id": "otA9p2lRW0cu"
      },
      "outputs": [],
      "source": [
        "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_001.nii.gz\", DATA_DIR + \"labelsTr/BRATS_001.nii.gz\")\n",
        "X, y = get_sub_volume(image, label)\n",
        "# enhancing tumor is channel 2 in the class label\n",
        "# you can change indexer for y to look at different classes\n",
        "visualize_patch(X[0, :, :, :], y[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:49.276586Z",
          "start_time": "2020-03-08T01:29:49.245584Z"
        },
        "id": "u1T5NzNe9Cnp"
      },
      "outputs": [],
      "source": [
        "def standardize(image):\n",
        "    \"\"\"\n",
        "    Standardize mean and standard deviation \n",
        "        of each channel and z_dimension.\n",
        "\n",
        "    Args:\n",
        "        image (np.array): input image, \n",
        "            shape (num_channels, dim_x, dim_y, dim_z)\n",
        "\n",
        "    Returns:\n",
        "        standardized_image (np.array): standardized version of input image\n",
        "    \"\"\"\n",
        "  \n",
        "    # initialize to array of zeros, with same shape as the image\n",
        "    standardized_image = np.zeros(image.shape)\n",
        "\n",
        "    # iterate over channels\n",
        "    for c in range(image.shape[0]):\n",
        "        # iterate over the `z` dimension\n",
        "        for z in range(image.shape[3]):\n",
        "            # get a slice of the image \n",
        "            # at channel c and z-th dimension `z`\n",
        "            image_slice = image[c,:,:,z]\n",
        "\n",
        "            # subtract the mean from image_slice\n",
        "            centered = image_slice - np.mean(image_slice)\n",
        "            \n",
        "            # divide by the standard deviation (only if it is different from zero)\n",
        "            centered_scaled = centered / np.std(centered)\n",
        "\n",
        "            # update  the slice of standardized image\n",
        "            # with the scaled centered and scaled image\n",
        "            standardized_image[c, :, :, z] = centered_scaled\n",
        "\n",
        "    return standardized_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:53.531889Z",
          "start_time": "2020-03-08T01:29:53.340902Z"
        },
        "id": "XcMiq-3FOYHe"
      },
      "outputs": [],
      "source": [
        "X_norm = standardize(X)\n",
        "visualize_patch(X_norm[0, :, :, :], y[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:29:58.610988Z",
          "start_time": "2020-03-08T01:29:58.605988Z"
        },
        "id": "09NNAst0BZJE"
      },
      "outputs": [],
      "source": [
        "def single_class_dice_coefficient(y_true, y_pred, axis=(0, 1, 2), \n",
        "                                  epsilon=0.00001):\n",
        "    \"\"\"\n",
        "    Compute dice coefficient for single class.\n",
        "\n",
        "    Args:\n",
        "        y_true (Tensorflow tensor): tensor of ground truth values for single class.\n",
        "                                    shape: (x_dim, y_dim, z_dim)\n",
        "        y_pred (Tensorflow tensor): tensor of predictions for single class.\n",
        "                                    shape: (x_dim, y_dim, z_dim)\n",
        "        axis (tuple): spatial axes to sum over when computing numerator and\n",
        "                      denominator of dice coefficient.\n",
        "                      Hint: pass this as the 'axis' argument to the K.sum function.\n",
        "        epsilon (float): small constant added to numerator and denominator to\n",
        "                        avoid divide by 0 errors.\n",
        "    Returns:\n",
        "        dice_coefficient (float): computed value of dice coefficient.     \n",
        "    \"\"\"\n",
        "    dice_numerator = 2 * np.sum(y_true * y_pred, axis = axis) + epsilon\n",
        "    dice_denominator = K.sum(y_true,axis= axis) + K.sum(y_pred, axis= axis) + epsilon\n",
        "    dice_coefficient = dice_numerator / dice_denominator\n",
        "\n",
        "    return dice_coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:30:03.312564Z",
          "start_time": "2020-03-08T01:30:03.307566Z"
        },
        "id": "AAmG3BP0EJFk"
      },
      "outputs": [],
      "source": [
        "def dice_coefficient(y_true, y_pred, axis=(1, 2, 3), \n",
        "                     epsilon=0.00001):\n",
        "    \"\"\"\n",
        "    Compute mean dice coefficient over all abnormality classes.\n",
        "\n",
        "    Args:\n",
        "        y_true (Tensorflow tensor): tensor of ground truth values for all classes.\n",
        "                                    shape: (num_classes, x_dim, y_dim, z_dim)\n",
        "        y_pred (Tensorflow tensor): tensor of predictions for all classes.\n",
        "                                    shape: (num_classes, x_dim, y_dim, z_dim)\n",
        "        axis (tuple): spatial axes to sum over when computing numerator and\n",
        "                      denominator of dice coefficient.\n",
        "                      Hint: pass this as the 'axis' argument to the K.sum function.\n",
        "        epsilon (float): small constant add to numerator and denominator to\n",
        "                        avoid divide by 0 errors.\n",
        "    Returns:\n",
        "        dice_coefficient (float): computed value of dice coefficient.     \n",
        "    \"\"\"\n",
        "    dice_numerator = 2 * K.sum(y_true * y_pred , axis = axis) + epsilon\n",
        "    dice_denominator = K.sum(y_true, axis = axis ) + K.sum(y_pred, axis = axis) + epsilon\n",
        "    dice_coefficient = K.mean(dice_numerator/dice_denominator)\n",
        "\n",
        "    return dice_coefficient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:30:07.734304Z",
          "start_time": "2020-03-08T01:30:07.728305Z"
        },
        "id": "KjtevmR185vb"
      },
      "outputs": [],
      "source": [
        "def soft_dice_loss(y_true, y_pred, axis=(1, 2, 3), \n",
        "                   epsilon=0.00001):\n",
        "    \"\"\"\n",
        "    Compute mean soft dice loss over all abnormality classes.\n",
        "\n",
        "    Args:\n",
        "        y_true (Tensorflow tensor): tensor of ground truth values for all classes.\n",
        "                                    shape: (num_classes, x_dim, y_dim, z_dim)\n",
        "        y_pred (Tensorflow tensor): tensor of soft predictions for all classes.\n",
        "                                    shape: (num_classes, x_dim, y_dim, z_dim)\n",
        "        axis (tuple): spatial axes to sum over when computing numerator and\n",
        "                      denominator in formula for dice loss.\n",
        "                      Hint: pass this as the 'axis' argument to the K.sum function.\n",
        "        epsilon (float): small constant added to numerator and denominator to\n",
        "                        avoid divide by 0 errors.\n",
        "    Returns:\n",
        "        dice_loss (float): computed value of dice loss.     \n",
        "    \"\"\"\n",
        "    dice_numerator = 2 * K.sum(y_true * y_pred , axis= axis) + epsilon\n",
        "    dice_denominator = K.sum(y_true ** 2, axis= axis) + K.sum(y_pred ** 2 , axis = axis) + epsilon\n",
        "    dice_loss = 1 - K.mean(dice_numerator / dice_denominator)\n",
        "\n",
        "    return dice_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkSoXp6o8Q2r",
        "outputId": "14001652-472b-40d8-ca07-dba3df883490"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = unet_model_3d(loss_function=soft_dice_loss, metrics=[dice_coefficient])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcBeF80jf54b",
        "outputId": "f19d6b23-05df-4077-b966-7b56000d80d2"
      },
      "outputs": [],
      "source": [
        "base_dir = HOME_DIR + \"processed/\"\n",
        "\n",
        "with open(base_dir + \"config.json\") as json_file:\n",
        "    config = json.load(json_file)\n",
        "\n",
        "# Get generators for training and validation sets\n",
        "train_generator = VolumeDataGenerator(config[\"train\"], base_dir + \"train/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
        "valid_generator = VolumeDataGenerator(config[\"valid\"], base_dir + \"valid/\", batch_size=3, dim=(160, 160, 16), verbose=0)\n",
        "\n",
        "steps_per_epoch = 20\n",
        "n_epochs=10\n",
        "validation_steps = 20\n",
        "\n",
        "model.fit_generator(generator=train_generator,\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "        epochs=n_epochs,\n",
        "        use_multiprocessing=True,\n",
        "        validation_data=valid_generator,\n",
        "        validation_steps=validation_steps)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7bABYtr8Q2t",
        "outputId": "e15e2500-4b1b-421c-8fa8-d126a042001b",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D3Zx9gSiAhEC"
      },
      "outputs": [],
      "source": [
        "visualize_patch(X_norm[0, :, :, :], y[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GKVqDNbjUIF"
      },
      "outputs": [],
      "source": [
        "X_norm_with_batch_dimension = np.expand_dims(X_norm, axis=0)\n",
        "patch_pred = model.predict(X_norm_with_batch_dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCsVNiKJBvcC"
      },
      "outputs": [],
      "source": [
        "# set threshold.\n",
        "threshold = 0.5\n",
        "\n",
        "# use threshold to get hard predictions\n",
        "patch_pred[patch_pred > threshold] = 1.0\n",
        "patch_pred[patch_pred <= threshold] = 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vf6N-lzLjov4"
      },
      "outputs": [],
      "source": [
        "print(\"Patch and ground truth\")\n",
        "visualize_patch(X_norm[0, :, :, :], y[2])\n",
        "plt.show()\n",
        "print(\"Patch and prediction\")\n",
        "visualize_patch(X_norm[0, :, :, :], patch_pred[0, 2, :, :, :])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qnc9IWfcX1YJ"
      },
      "outputs": [],
      "source": [
        "def compute_class_sens_spec(pred, label, class_num):\n",
        "    \"\"\"\n",
        "    Compute sensitivity and specificity for a particular example\n",
        "    for a given class.\n",
        "\n",
        "    Args:\n",
        "        pred (np.array): binary arrary of predictions, shape is\n",
        "                         (num classes, height, width, depth).\n",
        "        label (np.array): binary array of labels, shape is\n",
        "                          (num classes, height, width, depth).\n",
        "        class_num (int): number between 0 - (num_classes -1) which says\n",
        "                         which prediction class to compute statistics\n",
        "                         for.\n",
        "\n",
        "    Returns:\n",
        "        sensitivity (float): for a given class_num.\n",
        "        specificity (float): for a given class_num.\n",
        "    \"\"\"\n",
        "\n",
        "    # extract sub-array for specified class\n",
        "    class_pred = pred[class_num]\n",
        "    class_label = label[class_num]\n",
        "\n",
        "    # true positives\n",
        "    tp = np.sum( (class_pred == 1) * (class_label == 1))\n",
        "\n",
        "    # true negatives\n",
        "    tn = np.sum( (class_pred == 0) * (class_label == 0))\n",
        "    \n",
        "    #false positives\n",
        "    fp = np.sum( (class_pred == 1) * (class_label == 0))\n",
        "    \n",
        "    # false negatives\n",
        "    fn = np.sum( (class_pred == 0) * (class_label == 1))\n",
        "\n",
        "    # compute sensitivity and specificity\n",
        "    sensitivity = tp / (tp + fn)\n",
        "    specificity = tn / (tn + fp)\n",
        "\n",
        "    return sensitivity, specificity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mcTtD1JdYnGj",
        "outputId": "c02f5bf2-e18b-4117-ac82-aa6bd7d76077"
      },
      "outputs": [],
      "source": [
        "### test cell ex6 - do not modify this test cell    \n",
        "compute_class_sens_spec_test(compute_class_sens_spec)    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kp4SJDWmc0L5",
        "outputId": "095eae33-9396-4fbf-9a62-0c1bc43dae0c"
      },
      "outputs": [],
      "source": [
        "sensitivity, specificity = compute_class_sens_spec(patch_pred[0], y, 2)\n",
        "\n",
        "print(f\"Sensitivity: {sensitivity:.4f}\")\n",
        "print(f\"Specificity: {specificity:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LuVZHUKnp4t"
      },
      "outputs": [],
      "source": [
        "def get_sens_spec_df(pred, label):\n",
        "    patch_metrics = pd.DataFrame(\n",
        "        columns = ['Edema', \n",
        "                   'Non-Enhancing Tumor', \n",
        "                   'Enhancing Tumor'], \n",
        "        index = ['Sensitivity',\n",
        "                 'Specificity'])\n",
        "    \n",
        "    for i, class_name in enumerate(patch_metrics.columns):\n",
        "        sens, spec = compute_class_sens_spec(pred, label, i)\n",
        "        patch_metrics.loc['Sensitivity', class_name] = round(sens,4)\n",
        "        patch_metrics.loc['Specificity', class_name] = round(spec,4)\n",
        "\n",
        "    return patch_metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lBPqWFmspQHj",
        "outputId": "0a99e5a0-5bfa-4ca0-c694-5c18abd832d4"
      },
      "outputs": [],
      "source": [
        "df = get_sens_spec_df(patch_pred[0], y)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18m8pkA9W0dt"
      },
      "outputs": [],
      "source": [
        "image, label = load_case(DATA_DIR + \"imagesTr/BRATS_003.nii.gz\", DATA_DIR + \"labelsTr/BRATS_003.nii.gz\")\n",
        "pred = predict_and_viz(image, label, model, .5, loc=(130, 130, 77))                "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-03-08T01:50:20.141287Z",
          "start_time": "2020-03-08T01:50:20.138316Z"
        },
        "id": "H7pB-ZgPsl2N"
      },
      "outputs": [],
      "source": [
        "whole_scan_label = keras.utils.to_categorical(label, num_classes = 4)\n",
        "whole_scan_pred = pred\n",
        "\n",
        "# move axis to match shape expected in functions\n",
        "whole_scan_label = np.moveaxis(whole_scan_label, 3 ,0)[1:4]\n",
        "whole_scan_pred = np.moveaxis(whole_scan_pred, 3, 0)[1:4]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpljPNBJ6k0k",
        "outputId": "8f5890c4-ca6d-4f19-8e13-3c9f4225ff88"
      },
      "outputs": [],
      "source": [
        "whole_scan_df = get_sens_spec_df(whole_scan_pred, whole_scan_label)\n",
        "\n",
        "print(whole_scan_df)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
