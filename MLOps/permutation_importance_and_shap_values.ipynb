{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "tUUVrx70Z5KL"
      },
      "source": [
        "# Permutation Feature Importance\n",
        "dataset: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html#sklearn.datasets.load_wine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UsGnA3r9DQkw"
      },
      "outputs": [],
      "source": [
        "!pip install -U scikit-learn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DCRACaLFC-1N"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_wine\n",
        "\n",
        "# as_frame param requires scikit-learn >= 0.23\n",
        "data = load_wine(as_frame=True)\n",
        "\n",
        "# Print first rows of the data\n",
        "data.frame.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Aaszrn9CEsIf"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Train / Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, random_state=42)\n",
        "\n",
        "# Instantiate StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit it to the train data\n",
        "scaler.fit(X_train)\n",
        "\n",
        "# Use it to transform the train and test data\n",
        "X_train = scaler.transform(X_train)\n",
        "\n",
        "# Notice that the scaler is trained on the train data to avoid data leakage from the test set\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NK5Dxa70Ir3N"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Fit the classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=10, random_state=42).fit(X_train, y_train)\n",
        "\n",
        "# Print the mean accuracy achieved by the classifier on the test set\n",
        "rf_clf.score(X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nAvDl_2rJsTA"
      },
      "outputs": [],
      "source": [
        "from sklearn.inspection import permutation_importance\n",
        "\n",
        "def feature_importance(clf, X, y, top_limit=None):\n",
        "\n",
        "  # Retrieve the Bunch object after 50 repeats\n",
        "  # n_repeats is the number of times that each feature was permuted to compute the final score\n",
        "  bunch = permutation_importance(clf, X, y,\n",
        "                                 n_repeats=50, random_state=42)\n",
        "\n",
        "  # Average feature importance\n",
        "  imp_means = bunch.importances_mean\n",
        "\n",
        "  # List that contains the index of each feature in descending order of importance\n",
        "  ordered_imp_means_args = np.argsort(imp_means)[::-1]\n",
        "\n",
        "  # If no limit print all features\n",
        "  if top_limit is None:\n",
        "    top_limit = len(ordered_imp_means_args)\n",
        "\n",
        "  # Print relevant information\n",
        "  for i, _ in zip(ordered_imp_means_args, range(top_limit)):\n",
        "    name = data.feature_names[i]\n",
        "    imp_score = imp_means[i]\n",
        "    imp_std = bunch.importances_std[i]\n",
        "    print(f\"Feature {name} with index {i} has an average importance score of {imp_score:.3f} +/- {imp_std:.3f}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wuB6EyTuHT7S"
      },
      "outputs": [],
      "source": [
        "feature_importance(rf_clf, X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iDjYLTDBzfXT"
      },
      "outputs": [],
      "source": [
        "feature_importance(rf_clf, X_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "daZkt0PE1oxc"
      },
      "outputs": [],
      "source": [
        "print(\"On TRAIN split:\\n\")\n",
        "feature_importance(rf_clf, X_train, y_train, top_limit=3)\n",
        "\n",
        "print(\"\\nOn TEST split:\\n\")\n",
        "feature_importance(rf_clf, X_test, y_test, top_limit=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VOZyil7eqH5-"
      },
      "outputs": [],
      "source": [
        "# Preserve only the top 3 features\n",
        "X_train_top_features = X_train[:,[6, 9, 12]]\n",
        "X_test_top_features = X_test[:,[6, 9, 12]]\n",
        "\n",
        "# Re-train with only these features\n",
        "rf_clf_top = RandomForestClassifier(n_estimators=10, random_state=42).fit(X_train_top_features, y_train)\n",
        "\n",
        "# Compute mean accuracy achieved\n",
        "rf_clf_top.score(X_test_top_features, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b72FJLpj9Aly"
      },
      "outputs": [],
      "source": [
        "# Preserve only the top 3 features\n",
        "X_train_top_features = X_train[:,[0, 6, 9, 12]]\n",
        "X_test_top_features = X_test[:,[0, 6, 9, 12]]\n",
        "\n",
        "# Re-train with only these features\n",
        "rf_clf_top = RandomForestClassifier(n_estimators=10, random_state=42).fit(X_train_top_features, y_train)\n",
        "\n",
        "# Compute mean accuracy achieved\n",
        "rf_clf_top.score(X_test_top_features, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hv6oXNMUrzmR"
      },
      "outputs": [],
      "source": [
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import Lasso, Ridge\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Select 4 new classifiers\n",
        "clfs = {\"Laso\": Lasso(alpha=0.05), \n",
        "        \"Ridge\": Ridge(), \n",
        "        \"Decision Tree\": DecisionTreeClassifier(), \n",
        "        \"Support Vector\": SVC()}\n",
        "\n",
        "\n",
        "# Compute feature importance on the test set given a classifier\n",
        "def fit_compute_importance(clf):\n",
        "  clf.fit(X_train, y_train)\n",
        "  print(f\"üìè Mean accuracy score on the test set: {clf.score(X_test, y_test)*100:.2f}%\\n\")\n",
        "  print(\"üîù Top 4 features when using the test set:\\n\")\n",
        "  feature_importance(clf, X_test, y_test, top_limit=4)\n",
        "\n",
        "\n",
        "# Print results\n",
        "for name, clf in clfs.items():\n",
        "  print(\"=====\"*20)\n",
        "  print(f\"‚û°Ô∏è {name} classifier\\n\")\n",
        "  fit_compute_importance(clf)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "EixH_3T4RN9u"
      },
      "source": [
        "# Shapley Values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7Fzf05Amwpx"
      },
      "outputs": [],
      "source": [
        "!pip install shap\n",
        "!pip install tensorflow==2.4.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5BRI5W3mf5q"
      },
      "outputs": [],
      "source": [
        "import shap\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6ap5dqFQmsDC"
      },
      "outputs": [],
      "source": [
        "# Download the dataset\n",
        "(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# Reshape and normalize data\n",
        "x_train = x_train.reshape(60000, 28, 28, 1).astype(\"float32\") / 255\n",
        "x_test = x_test.reshape(10000, 28, 28, 1).astype(\"float32\") / 255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SH7gEwiksWDE"
      },
      "outputs": [],
      "source": [
        "# Define the model architecture using the functional API\n",
        "inputs = keras.Input(shape=(28, 28, 1))\n",
        "x = keras.layers.Conv2D(32, (3, 3), activation='relu')(inputs)\n",
        "x = keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = keras.layers.Flatten()(x)\n",
        "x = keras.layers.Dense(256, activation='relu')(x)\n",
        "outputs = keras.layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "# Create the model with the corresponding inputs and outputs\n",
        "model = keras.Model(inputs=inputs, outputs=outputs, name=\"CNN\")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "      optimizer=keras.optimizers.Adam(),\n",
        "      metrics=[tf.keras.metrics.SparseCategoricalAccuracy()]\n",
        "  )\n",
        "\n",
        "# Train it!\n",
        "model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hSqcehYVxSZY"
      },
      "outputs": [],
      "source": [
        "# Name each one of the classes\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# Save an example for each category in a dict\n",
        "images_dict = dict()\n",
        "for i, l in enumerate(y_train):\n",
        "  if len(images_dict)==10:\n",
        "    break\n",
        "  if l not in images_dict.keys():\n",
        "    images_dict[l] = x_train[i].reshape((28, 28))\n",
        "\n",
        "# Function to plot images\n",
        "def plot_categories(images):\n",
        "  fig, axes = plt.subplots(1, 11, figsize=(16, 15))\n",
        "  axes = axes.flatten()\n",
        "  \n",
        "  # Plot an empty canvas\n",
        "  ax = axes[0]\n",
        "  dummy_array = np.array([[[0, 0, 0, 0]]], dtype='uint8')\n",
        "  ax.set_title(\"reference\")\n",
        "  ax.set_axis_off()\n",
        "  ax.imshow(dummy_array, interpolation='nearest')\n",
        "\n",
        "  # Plot an image for every category\n",
        "  for k,v in images.items():\n",
        "    ax = axes[k+1]\n",
        "    ax.imshow(v, cmap=plt.cm.binary)\n",
        "    ax.set_title(f\"{class_names[k]}\")\n",
        "    ax.set_axis_off()\n",
        "\n",
        "  plt.tight_layout()\n",
        "  plt.show()\n",
        "\n",
        "\n",
        "# Use the function to plot\n",
        "plot_categories(images_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-fZZQnMWvjc6"
      },
      "outputs": [],
      "source": [
        "# Take a random sample of 5000 training images\n",
        "background = x_train[np.random.choice(x_train.shape[0], 5000, replace=False)]\n",
        "\n",
        "# Use DeepExplainer to explain predictions of the model\n",
        "e = shap.DeepExplainer(model, background)\n",
        "\n",
        "# Compute shap values\n",
        "# shap_values = e.shap_values(x_test[1:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5InnVMMzvCwl"
      },
      "outputs": [],
      "source": [
        "# Save an example of each class from the test set\n",
        "x_test_dict = dict()\n",
        "for i, l in enumerate(y_test):\n",
        "  if len(x_test_dict)==10:\n",
        "    break\n",
        "  if l not in x_test_dict.keys():\n",
        "    x_test_dict[l] = x_test[i]\n",
        "\n",
        "# Convert to list preserving order of classes\n",
        "x_test_each_class = [x_test_dict[i] for i in sorted(x_test_dict)]\n",
        "\n",
        "# Convert to tensor\n",
        "x_test_each_class = np.asarray(x_test_each_class)\n",
        "\n",
        "# Print shape of tensor\n",
        "print(f\"x_test_each_class tensor has shape: {x_test_each_class.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3gbdJQKcqN6y"
      },
      "outputs": [],
      "source": [
        "# Compute predictions\n",
        "predictions = model.predict(x_test_each_class)\n",
        "\n",
        "# Apply argmax to get predicted class\n",
        "np.argmax(predictions, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Cm_HjmFuQzF"
      },
      "outputs": [],
      "source": [
        "# Compute shap values using DeepExplainer instance\n",
        "shap_values = e.shap_values(x_test_each_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0t1dWh7rv0ya"
      },
      "outputs": [],
      "source": [
        "# Plot reference column\n",
        "plot_categories(images_dict)\n",
        "\n",
        "# Print an empty line to separate the two plots\n",
        "print()\n",
        "\n",
        "# Plot shap values\n",
        "shap.image_plot(shap_values, -x_test_each_class)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGorLRbV2qz7"
      },
      "outputs": [],
      "source": [
        "# Save the probability of belonging to each class for the fifth element of the set\n",
        "coat_probs = predictions[4]\n",
        "\n",
        "# Order the probabilities in ascending order\n",
        "coat_args = np.argsort(coat_probs)\n",
        "\n",
        "# Reverse the list and get the top 3 probabilities\n",
        "top_coat_args = coat_args[::-1][:3]\n",
        "\n",
        "# Print (ordered) top 3 classes\n",
        "for i in list(top_coat_args):\n",
        "  print(class_names[i])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "EixH_3T4RN9u",
        "jJv0LghcmX_P",
        "tUUVrx70Z5KL"
      ],
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
