{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A/B testing, traffic shifting and autoscaling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "In this lab you will create an endpoint with multiple variants, splitting the traffic between them. Then after testing and reviewing the endpoint performance metrics, you will shift the traffic to one variant and configure it to autoscale.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "- [1. Create an endpoint with multiple variants](#c3w2-1.)\n",
    "  - [1.1. Construct Docker Image URI](#c3w2-1.1.)\n",
    "\n",
    "  - [1.2. Create Amazon SageMaker Models](#c3w2-1.2.)\n",
    "\n",
    "  - [1.3. Set up Amazon SageMaker production variants](#c3w2-1.3.)\n",
    "\n",
    "  - [1.4. Configure and create endpoint](#c3w2-1.4.)\n",
    "\n",
    "- [2. Test model](#c3w2-2.)\n",
    "  - [2.1. Test the model on a few sample strings](#c3w2-2.1.)\n",
    "\n",
    "  - [2.2. Generate traffic and review the endpoint performance metrics](#c3w2-2.2.)\n",
    "- [3. Shift the traffic to one variant and review the endpoint performance metrics](#c3w2-3.)\n",
    "\n",
    "- [4. Configure one variant to autoscale](#c3w2-4.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's install and import the required modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please ignore warning messages during the installation\n",
    "!pip install --disable-pip-version-check -q sagemaker==2.35.0\n",
    "!conda install -q -y pytorch==1.6.0 -c pytorch\n",
    "!pip install --disable-pip-version-check -q transformers==3.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import botocore\n",
    "\n",
    "config = botocore.config.Config(user_agent_extra='dlai-pds/c3/w2')\n",
    "\n",
    "# low-level service client of the boto3 session\n",
    "sm = boto3.client(service_name='sagemaker', \n",
    "                  config=config)\n",
    "\n",
    "sm_runtime = boto3.client('sagemaker-runtime',\n",
    "                          config=config)\n",
    "\n",
    "sess = sagemaker.Session(sagemaker_client=sm,\n",
    "                         sagemaker_runtime_client=sm_runtime)\n",
    "\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = sess.boto_region_name\n",
    "\n",
    "cw = boto3.client(service_name='cloudwatch', \n",
    "                  config=config)\n",
    "\n",
    "autoscale = boto3.client(service_name=\"application-autoscaling\", \n",
    "                         config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w2-1.'></a>\n",
    "# 1. Create an endpoint with multiple variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two models trained to analyze customer feedback and classify the messages into positive (1), neutral (0), and negative (-1) sentiments are saved in the following S3 bucket paths. These `tar.gz` files contain the model artifacts, which result from model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_a_s3_uri = 's3://dlai-practical-data-science/models/ab/variant_a/model.tar.gz'\n",
    "model_b_s3_uri = 's3://dlai-practical-data-science/models/ab/variant_b/model.tar.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deploy an endpoint splitting the traffic between these two models 50/50 to perform A/B Testing. Instead of creating a PyTorch Model object and calling `model.deploy()` function, you will create an `Endpoint configuration` with multiple model variants. Here is the workflow you will follow to create an endpoint:\n",
    "\n",
    "<img src=\"images/endpoint-workflow.png\" width=\"60%\" align=\"center\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name='c3w2-1.1.'></a>\n",
    "### 1.1. Construct Docker Image URI\n",
    "\n",
    "<img src=\"images/endpoint-workflow-1-image.png\" width=\"60%\" align=\"center\">\n",
    "\n",
    "You will need to create the models in Amazon SageMaker, which retrieves the URI for the pre-built SageMaker Docker image stored in Amazon Elastic Container Re\n",
    "gistry (ECR). Let's construct the ECR URI which you will pass into the `create_model` function later.\n",
    "\n",
    "Set the instance type. For the purposes of this lab, you will use a relatively small instance. Please refer to [this link](https://aws.amazon.com/sagemaker/pricing/) for additional instance types that may work for your use cases outside of this lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = 'ml.m5.large'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Create an ECR URI using the `'PyTorch'` framework. Review other parameters of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_image_uri = sagemaker.image_uris.retrieve(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    framework='pytorch', # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    version='1.6.0',\n",
    "    instance_type=inference_instance_type,\n",
    "    region=region,\n",
    "    py_version='py3',\n",
    "    image_scope='inference'\n",
    ")\n",
    "print(inference_image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Create Amazon SageMaker Models\n",
    "\n",
    "\n",
    "Amazon SageMaker Model includes information such as the S3 location of the model, the container image that can be used for inference with that model, the execution role, and the model name. \n",
    "\n",
    "Let's construct the model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from pprint import pprint\n",
    "\n",
    "timestamp = int(time.time())\n",
    "\n",
    "model_name_a = '{}-{}'.format('a', timestamp)\n",
    "model_name_b = '{}-{}'.format('b', timestamp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will use the following function to check if the model already exists in Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_model_existence(model_name):\n",
    "    for model in sm.list_models()['Models']:\n",
    "        if model_name == model['ModelName']:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Amazon SageMaker Model based on the `model_a_s3_uri` data.\n",
    "\n",
    "**Instructions**: Use `sm.create_model` function, which requires the model name, Amazon SageMaker execution role and a primary container description (`PrimaryContainer` dictionary). The `PrimaryContainer` includes the S3 bucket location of the model artifacts (`ModelDataUrl` key) and ECR URI (`Image` key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_model_existence(model_name_a):\n",
    "    model_a = sm.create_model(\n",
    "        ModelName=model_name_a,\n",
    "        ExecutionRoleArn=role,\n",
    "        PrimaryContainer={\n",
    "            ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "            'ModelDataUrl': model_a_s3_uri, # Replace None\n",
    "            'Image': inference_image_uri # Replace None\n",
    "            ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "        }\n",
    "    )\n",
    "    pprint(model_a)\n",
    "else:\n",
    "    print(\"Model {} already exists\".format(model_name_a))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Amazon SageMaker Model based on the `model_b_s3_uri` data.\n",
    "\n",
    "**Instructions**: Use the example in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_model_existence(model_name_b):\n",
    "    model_b = sm.create_model(\n",
    "        ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "        ModelName=model_name_b, # Replace all None\n",
    "        ExecutionRoleArn=role, # Replace all None\n",
    "        ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "        PrimaryContainer={\n",
    "            'ModelDataUrl': model_b_s3_uri, \n",
    "            'Image': inference_image_uri\n",
    "        }\n",
    "    )\n",
    "    pprint(model_b)\n",
    "else:\n",
    "    print(\"Model {} already exists\".format(model_name_b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Set up Amazon SageMaker production variants\n",
    "\n",
    "A production variant is a packaged SageMaker Model combined with the configuration related to how that model will be hosted. \n",
    "\n",
    "You have constructed the model in the section above. The hosting resources configuration includes information on how you want that model to be hosted: the number and type of instances, a pointer to the SageMaker package model, as well as a variant name and variant weight. A single SageMaker Endpoint can actually include multiple production variants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Amazon SageMaker production variant for the SageMaker Model with the `model_name_a`.\n",
    "\n",
    "**Instructions**: Use the `production_variant` function passing the `model_name_a` and instance type defined above.\n",
    "\n",
    "```python\n",
    "variantA = production_variant(\n",
    "    model_name=..., # SageMaker Model name\n",
    "    instance_type=..., # instance type\n",
    "    initial_weight=50, # traffic distribution weight\n",
    "    initial_instance_count=1, # instance count\n",
    "    variant_name='VariantA', # production variant name\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.session import production_variant\n",
    "\n",
    "variantA = production_variant(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    model_name=model_name_a, # Replace None\n",
    "    instance_type=inference_instance_type, # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    initial_weight=50,\n",
    "    initial_instance_count=1,\n",
    "    variant_name='VariantA',\n",
    ")\n",
    "print(variantA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Amazon SageMaker production variant for the SageMaker Model with the `model_name_b`.\n",
    "\n",
    "**Instructions**: See the required arguments in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variantB = production_variant(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    model_name=model_name_b, # Replace all None\n",
    "    instance_type=inference_instance_type, # Replace all None\n",
    "    initial_weight=50, # Replace all None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    initial_instance_count=1,\n",
    "    variant_name='VariantB'\n",
    ")\n",
    "print(variantB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4. Configure and create the endpoint\n",
    "\n",
    "You will use the following functions to check if the endpoint configuration and endpoint itself already exist in Amazon SageMaker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_endpoint_config_existence(endpoint_config_name):\n",
    "    for endpoint_config in sm.list_endpoint_configs()['EndpointConfigs']:\n",
    "        if endpoint_config_name == endpoint_config['EndpointConfigName']:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_endpoint_existence(endpoint_name):\n",
    "    for endpoint in sm.list_endpoints()['Endpoints']:\n",
    "        if endpoint_name == endpoint['EndpointName']:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the endpoint configuration by specifying the name and pointing to the two production variants that you just configured that tell SageMaker how you want to host those models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_config_name = '{}-{}'.format('ab', timestamp)\n",
    "\n",
    "if not check_endpoint_config_existence(endpoint_config_name):\n",
    "    endpoint_config = sm.create_endpoint_config(\n",
    "        EndpointConfigName=endpoint_config_name, \n",
    "        ProductionVariants=[variantA, variantB]\n",
    "    )\n",
    "    pprint(endpoint_config)\n",
    "else:\n",
    "    print(\"Endpoint configuration {} already exists\".format(endpoint_config_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct the endpoint name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ab_endpoint_name = '{}-{}'.format('ab', timestamp)\n",
    "print('Endpoint name: {}'.format(model_ab_endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an endpoint with the endpoint name and configuration defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not check_endpoint_existence(model_ab_endpoint_name):\n",
    "    endpoint_response = sm.create_endpoint(\n",
    "        ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "        EndpointName=model_ab_endpoint_name, # Replace None\n",
    "        EndpointConfigName=endpoint_config_name # Replace None\n",
    "        ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    )\n",
    "    print('Creating endpoint {}'.format(model_ab_endpoint_name))\n",
    "    pprint(endpoint_response)\n",
    "else:\n",
    "    print(\"Endpoint {} already exists\".format(model_ab_endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the created endpoint configuration in the AWS console.\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "- open the link\n",
    "- notice that you are in the section Amazon SageMaker -> Endpoint configuration\n",
    "- check the name of the endpoint configuration, its Amazon Resource Name (ARN) and production variants\n",
    "- click on the production variants and check their container information: image and model data location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpointConfig/ab-1631799832\">REST Endpoint configuration</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(\n",
    "    HTML(\n",
    "        '<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpointConfig/{}\">REST Endpoint configuration</a></b>'.format(\n",
    "            region, endpoint_config_name\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the created endpoint in the AWS console.\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "- open the link\n",
    "- notice that you are in the section Amazon SageMaker -> Endpoints\n",
    "- check the name of the endpoint, its ARN and status\n",
    "- below you can review the monitoring metrics such as CPU, memory and disk utilization. Further down you can see the endpoint configuration settings with its production variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/ab-1631799832\">SageMaker REST endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST endpoint</a></b>'.format(region, model_ab_endpoint_name)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait for the endpoint to deploy.\n",
    "\n",
    "### _This cell will take approximately 5-10 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "waiter = sm.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Wait until the ^^ endpoint ^^ is deployed_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Test the model on a few sample strings\n",
    "\n",
    "Here, you will pass sample strings of text to the endpoint in order to see the sentiment. You are given one example of each, however, feel free to play around and change the strings yourself!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an Amazon SageMaker Predictor based on the deployed endpoint.\n",
    "\n",
    "**Instructions**: Use the `Predictor` object with the following parameters. Please pass JSON serializer and deserializer objects here, calling them with the functions `JSONLinesSerializer()` and `JSONLinesDeserializer()`, respectively. More information about the serializers can be found [here](https://sagemaker.readthedocs.io/en/stable/api/inference/serializers.html).\n",
    "\n",
    "```python\n",
    "predictor = Predictor(\n",
    "    endpoint_name=..., # endpoint name\n",
    "    serializer=..., # a serializer object, used to encode data for an inference endpoint\n",
    "    deserializer=..., # a deserializer object, used to decode data from an inference endpoint\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "\n",
    "inputs = [\n",
    "    {\"features\": [\"I love this product!\"]},\n",
    "    {\"features\": [\"OK, but not great.\"]},\n",
    "    {\"features\": [\"This is not the right product.\"]},\n",
    "]\n",
    "\n",
    "predictor = Predictor(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    endpoint_name=model_ab_endpoint_name, # Replace None\n",
    "    serializer=JSONLinesSerializer(), # Replace None\n",
    "    deserializer=JSONLinesDeserializer(), # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    sagemaker_session=sess\n",
    ")\n",
    "\n",
    "predicted_classes = predictor.predict(inputs)\n",
    "\n",
    "for predicted_class in predicted_classes:\n",
    "    print(\"Predicted class {} with probability {}\".format(predicted_class['predicted_label'], predicted_class['probability']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2. Generate traffic and review the endpoint performance metrics\n",
    "\n",
    "Now you will generate traffic. To analyze the endpoint performance you will review some of the metrics that Amazon SageMaker emits in CloudWatch: CPU Utilization, Latency and Invocations. Full list of namespaces and metrics can be found [here](https://docs.aws.amazon.com/sagemaker/latest/dg/monitoring-cloudwatch.html). CloudWatch `get_metric_statistics` documentation can be found [here](https://docs.aws.amazon.com/AmazonCloudWatch/latest/APIReference/API_GetMetricStatistics.html).\n",
    "\n",
    "But before that, let's create a function that will help to extract the results from CloudWatch and plot them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_endpoint_metrics_for_variants(endpoint_name, \n",
    "                                       namespace_name, \n",
    "                                       metric_name, \n",
    "                                       variant_names, \n",
    "                                       start_time, \n",
    "                                       end_time):\n",
    "    \n",
    "    try:\n",
    "        joint_variant_metrics = None\n",
    "\n",
    "        for variant_name in variant_names:\n",
    "            metrics = cw.get_metric_statistics( # extracts the results in a dictionary format\n",
    "                Namespace=namespace_name, # the namespace of the metric, e.g. \"AWS/SageMaker\"\n",
    "                MetricName=metric_name, # the name of the metric, e.g. \"CPUUtilization\"\n",
    "                StartTime=start_time, # the time stamp that determines the first data point to return\n",
    "                EndTime=end_time, # the time stamp that determines the last data point to return\n",
    "                Period=60, # the granularity, in seconds, of the returned data points\n",
    "                Statistics=[\"Sum\"], # the metric statistics\n",
    "                Dimensions=[ # dimensions, as CloudWatch treats each unique combination of dimensions as a separate metric\n",
    "                    {\"Name\": \"EndpointName\", \"Value\": endpoint_name}, \n",
    "                    {\"Name\": \"VariantName\", \"Value\": variant_name}\n",
    "                ],\n",
    "            )\n",
    "            \n",
    "            if metrics[\"Datapoints\"]: # access the results from the distionary using the key \"Datapoints\"\n",
    "                df_metrics = pd.DataFrame(metrics[\"Datapoints\"]) \\\n",
    "                    .sort_values(\"Timestamp\") \\\n",
    "                    .set_index(\"Timestamp\") \\\n",
    "                    .drop(\"Unit\", axis=1) \\\n",
    "                    .rename(columns={\"Sum\": variant_name}) # rename the column with the metric results as a variant_name\n",
    "                \n",
    "                if joint_variant_metrics is None:\n",
    "                    joint_variant_metrics = df_metrics\n",
    "                else:\n",
    "                    joint_variant_metrics = joint_variant_metrics.join(df_metrics, how=\"outer\")\n",
    "        \n",
    "        joint_variant_metrics.plot(title=metric_name)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Establish wide enough time bounds to show all the charts using the same timeframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "start_time = datetime.now() - timedelta(minutes=30)\n",
    "end_time = datetime.now() + timedelta(minutes=30)\n",
    "\n",
    "print('Start Time: {}'.format(start_time))\n",
    "print('End Time: {}'.format(end_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the list of the the variant names to analyze."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variant_names = [variantA[\"VariantName\"], variantB[\"VariantName\"]]\n",
    "\n",
    "print(variant_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run some predictions and view the metrics for each variant.\n",
    "\n",
    "### _This cell will take approximately 1-2 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Μake sure the predictions ^^ above ^^ ran successfully_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s query CloudWatch to get a few metrics that are split across variants. If you see `Metrics not yet available`, please be patient as metrics may take a few mins to appear in CloudWatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "time.sleep(30) # Sleep to accomodate a slight delay in metrics gathering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPUUtilization\n",
    "# The sum of each individual CPU core's utilization. \n",
    "# The CPU utilization of each core can range between 0 and 100. For example, if there are four CPUs, CPUUtilization can range from 0% to 400%.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, \n",
    "    namespace_name=\"/aws/sagemaker/Endpoints\", \n",
    "    metric_name=\"CPUUtilization\",\n",
    "    variant_names=variant_names,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invocations\n",
    "# The number of requests sent to a model endpoint.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, \n",
    "    namespace_name=\"AWS/SageMaker\", \n",
    "    metric_name=\"Invocations\",\n",
    "    variant_names=variant_names,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InvocationsPerInstance\n",
    "# The number of invocations sent to a model, normalized by InstanceCount in each production variant.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, \n",
    "    namespace_name=\"AWS/SageMaker\", \n",
    "    metric_name=\"InvocationsPerInstance\",\n",
    "    variant_names=variant_names,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelLatency\n",
    "# The interval of time taken by a model to respond as viewed from SageMaker (in microseconds).\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, \n",
    "    namespace_name=\"AWS/SageMaker\", \n",
    "    metric_name=\"ModelLatency\",\n",
    "    variant_names=variant_names,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Shift the traffic to one variant and review the endpoint performance metrics\n",
    "\n",
    "Generally, the winning model would need to be chosen. The decision would be made based on the endpoint performance metrics and some other business related evaluations. Here you can assume that the winning model is in the Variant B and shift all traffic to it. \n",
    "\n",
    "Construct a list with the updated endpoint weights.\n",
    "\n",
    "### _**No downtime** occurs during this traffic-shift activity._\n",
    "\n",
    "### _This may take a few minutes. Please be patient._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_endpoint_config = [\n",
    "    {\n",
    "        \"VariantName\": variantA[\"VariantName\"],\n",
    "        \"DesiredWeight\": 0,\n",
    "    },\n",
    "    {\n",
    "        \"VariantName\": variantB[\"VariantName\"],\n",
    "        \"DesiredWeight\": 100,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update variant weights in the configuration of the existing endpoint.\n",
    "\n",
    "**Instructions**: Use the `sm.update_endpoint_weights_and_capacities` function, passing the endpoint name and list of updated weights for each of the variants that you defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm.update_endpoint_weights_and_capacities(\n",
    "    ### BEGIN SOLUTION - DO NOT delete this comment for grading purposes\n",
    "    EndpointName=model_ab_endpoint_name, # Replace None\n",
    "    DesiredWeightsAndCapacities=updated_endpoint_config # Replace None\n",
    "    ### END SOLUTION - DO NOT delete this comment for grading purposes\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Wait for the ^^ endpoint update ^^ to complete above_\n",
    "\n",
    "This may take a few minutes.  Please be patient.\n",
    "\n",
    "### _There is **no downtime** while the update is applying._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While waiting for the update (or afterwards) you can review the endpoint in the AWS console.\n",
    "\n",
    "**Instructions**:\n",
    "\n",
    "- open the link\n",
    "- notice that you are in the section Amazon SageMaker -> Endpoints\n",
    "- check the name of the endpoint, its ARN and status (`Updating` or `InService`)\n",
    "- below you can see the endpoint runtime settings with the updated weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/ab-1631799832\">SageMaker REST endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST endpoint</a></b>'.format(region, model_ab_endpoint_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run some more predictions and view the metrics for each variant.\n",
    "\n",
    "### _This cell will take approximately 1-2 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Μake sure the predictions ^^ above ^^ ran successfully_\n",
    "\n",
    "If you see `Metrics not yet available`, please be patient as metrics may take a few minutes to appear in CloudWatch. Compare the results with the plots above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CPUUtilization\n",
    "# The sum of each individual CPU core's utilization. \n",
    "# The CPU utilization of each core can range between 0 and 100. For example, if there are four CPUs, CPUUtilization can range from 0% to 400%.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, \n",
    "    namespace_name=\"/aws/sagemaker/Endpoints\",\n",
    "    metric_name=\"CPUUtilization\",\n",
    "    variant_names=variant_names,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invocations\n",
    "# The number of requests sent to a model endpoint.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, \n",
    "    namespace_name=\"AWS/SageMaker\", \n",
    "    metric_name=\"Invocations\",\n",
    "    variant_names=variant_names,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# InvocationsPerInstance\n",
    "# The number of invocations sent to a model, normalized by InstanceCount in each production variant.\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, \n",
    "    namespace_name=\"AWS/SageMaker\", \n",
    "    metric_name=\"InvocationsPerInstance\",\n",
    "    variant_names=variant_names,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModelLatency\n",
    "# The interval of time taken by a model to respond as viewed from SageMaker (in microseconds).\n",
    "plot_endpoint_metrics_for_variants(\n",
    "    endpoint_name=model_ab_endpoint_name, \n",
    "    namespace_name=\"AWS/SageMaker\", \n",
    "    metric_name=\"ModelLatency\",\n",
    "    variant_names=variant_names,\n",
    "    start_time=start_time,\n",
    "    end_time=end_time    \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Configure one variant to autoscale\n",
    "\n",
    "Let's configure Variant B to autoscale. You would not autoscale Variant A since no traffic is being passed to it at this time.\n",
    "\n",
    "First, you need to define a scalable target. It is an AWS resource and in this case you want to scale a `sagemaker` resource as indicated in the `ServiceNameSpace` parameter. Then the `ResourceId` is a SageMaker Endpoint. Because autoscaling is used by other AWS resources, you’ll see a few parameters that will remain static for scaling SageMaker Endpoints. Thus the `ScalableDimension` is a set value for SageMaker Endpoint scaling.\n",
    "\n",
    "You also need to specify a few key parameters that control the min and max behavior for your Machine Learning instances. The `MinCapacity` indicates the minimum number of instances you plan to scale in to. The `MaxCapacity` is the maximum number of instances you want to scale out to. So in this case you always want to have at least 1 instance running and a maximum of 2 during peak periods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscale.register_scalable_target(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=\"endpoint/\" + model_ab_endpoint_name + \"/variant/VariantB\",\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    MinCapacity=1,\n",
    "    MaxCapacity=2,\n",
    "    RoleARN=role,\n",
    "    SuspendedState={\n",
    "        \"DynamicScalingInSuspended\": False,\n",
    "        \"DynamicScalingOutSuspended\": False,\n",
    "        \"ScheduledScalingSuspended\": False,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the parameters from the function above are in the description of the scalable target:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscale.describe_scalable_targets(\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    MaxResults=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define and apply scaling policy using the `put_scaling_policy` function. The scaling policy provides additional information about the scaling behavior for your instance. `TargetTrackingScaling` refers to a specific autoscaling type supported by SageMaker, that uses a scaling metric and a target value as the indicator to scale.\n",
    "\n",
    "In the scaling policy configuration, you have the predefined metric `PredefinedMetricSpecification` which is the number of invocations on your instance and the `TargetValue` which indicates the number of invocations per ML instance you want to allow before triggering your scaling policy. A scale out cooldown of 60 seconds means that after autoscaling successfully scales out it starts to calculate the cooldown time. The scaling policy won’t increase the desired capacity again until the cooldown period ends.\n",
    "\n",
    "The scale in cooldown setting of 300 seconds means that SageMaker will not attempt to start another cooldown policy within 300 seconds of when the last one completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoscale.put_scaling_policy(\n",
    "    PolicyName=\"bert-reviews-autoscale-policy\",\n",
    "    ServiceNamespace=\"sagemaker\",\n",
    "    ResourceId=\"endpoint/\" + model_ab_endpoint_name + \"/variant/VariantB\",\n",
    "    ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "    PolicyType=\"TargetTrackingScaling\",\n",
    "    TargetTrackingScalingPolicyConfiguration={\n",
    "        \"TargetValue\": 2.0, # the number of invocations per ML instance you want to allow before triggering your scaling policy\n",
    "        \"PredefinedMetricSpecification\": {\n",
    "            \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\", # scaling metric\n",
    "        },\n",
    "        \"ScaleOutCooldown\": 60, # wait time, in seconds, before beginning another scale out activity after last one completes\n",
    "        \"ScaleInCooldown\": 300, # wait time, in seconds, before beginning another scale in activity after last one completes\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "waiter = sm.get_waiter(\"endpoint_in_service\")\n",
    "waiter.wait(EndpointName=model_ab_endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate traffic again and review the endpoint in the AWS console.\n",
    "\n",
    "### _This cell will take approximately 1-2 minutes to run._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i in range(0, 100):\n",
    "    predicted_classes = predictor.predict(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review the autoscaling:\n",
    "\n",
    "- open the link\n",
    "- notice that you are in the section Amazon SageMaker -> Endpoints\n",
    "- below you can see the endpoint runtime settings with the instance counts. You can run the predictions multiple times to observe the increase of the instance count to 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a target=\"blank\" href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">SageMaker REST endpoint</a></b>'.format(region, model_ab_endpoint_name)))\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
