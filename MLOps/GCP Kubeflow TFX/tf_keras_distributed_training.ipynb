{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bnYxvfLD-LW-"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import json\n",
        "import time\n",
        "\n",
        "# Log additional outputs from TF's C++ backend\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '0'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "685pbYEY3jGC"
      },
      "outputs": [],
      "source": [
        "# Disable GPUs\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "# Add current directory to path\n",
        "if '.' not in sys.path:\n",
        "  sys.path.insert(0, '.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vHNvttzV43sA"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "# Ignore warnings\n",
        "tf.get_logger().setLevel('ERROR')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dma_wUAxZqo2"
      },
      "outputs": [],
      "source": [
        "%%writefile mnist.py\n",
        "\n",
        "# import os\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "def mnist_dataset(batch_size):\n",
        "  # Load the data\n",
        "  (x_train, y_train), _ = tf.keras.datasets.mnist.load_data()\n",
        "  # Normalize pixel values for x_train and cast to float32\n",
        "  x_train = x_train / np.float32(255)\n",
        "  # Cast y_train to int64\n",
        "  y_train = y_train.astype(np.int64)\n",
        "  # Define repeated and shuffled dataset\n",
        "  train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(60000).repeat().batch(batch_size)\n",
        "  return train_dataset\n",
        "\n",
        "\n",
        "def build_and_compile_cnn_model():\n",
        "  # Define simple CNN model using Keras Sequential\n",
        "  model = tf.keras.Sequential([\n",
        "      tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
        "      tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
        "      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(128, activation='relu'),\n",
        "      tf.keras.layers.Dense(10)\n",
        "  ])\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(\n",
        "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "      optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
        "      metrics=['accuracy'])\n",
        "  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IxsnfpVurQ1g"
      },
      "outputs": [],
      "source": [
        "!ls *.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Qe6iAf5O8iJ"
      },
      "outputs": [],
      "source": [
        "# Import your mnist model\n",
        "import mnist\n",
        "\n",
        "# Set batch size\n",
        "batch_size = 64\n",
        "\n",
        "# Load the dataset\n",
        "single_worker_dataset = mnist.mnist_dataset(batch_size)\n",
        "\n",
        "# Load compiled CNN model\n",
        "single_worker_model = mnist.build_and_compile_cnn_model()\n",
        "\n",
        "# As training progresses, the loss should drop and the accuracy should increase.\n",
        "single_worker_model.fit(single_worker_dataset, epochs=3, steps_per_epoch=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XK1eTYvSZiX7"
      },
      "outputs": [],
      "source": [
        "tf_config = {\n",
        "    'cluster': {\n",
        "        'worker': ['localhost:12345', 'localhost:23456']\n",
        "    },\n",
        "    'task': {'type': 'worker', 'index': 0}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY-T0YDQZjbu"
      },
      "outputs": [],
      "source": [
        "json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uFSHCJXMrQ-"
      },
      "outputs": [],
      "source": [
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo6b9wX65glL"
      },
      "outputs": [],
      "source": [
        "# Implementing distributed strategy via a context manager\n",
        "with strategy.scope():\n",
        "  multi_worker_model = mnist.build_and_compile_cnn_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcsuBYrpgnlS"
      },
      "outputs": [],
      "source": [
        "%%writefile main.py\n",
        "\n",
        "import os\n",
        "import json\n",
        "\n",
        "import tensorflow as tf\n",
        "import mnist # Your module\n",
        "\n",
        "# Define batch size\n",
        "per_worker_batch_size = 64\n",
        "\n",
        "# Get TF_CONFIG from the env variables and save it as JSON\n",
        "tf_config = json.loads(os.environ['TF_CONFIG'])\n",
        "\n",
        "# Infer number of workers from tf_config\n",
        "num_workers = len(tf_config['cluster']['worker'])\n",
        "\n",
        "# Define strategy\n",
        "strategy = tf.distribute.MultiWorkerMirroredStrategy()\n",
        "\n",
        "# Define global batch size\n",
        "global_batch_size = per_worker_batch_size * num_workers\n",
        "\n",
        "# Load dataset\n",
        "multi_worker_dataset = mnist.mnist_dataset(global_batch_size)\n",
        "\n",
        "# Create and compile model following the distributed strategy\n",
        "with strategy.scope():\n",
        "  multi_worker_model = mnist.build_and_compile_cnn_model()\n",
        "\n",
        "# Train the model\n",
        "multi_worker_model.fit(multi_worker_dataset, epochs=3, steps_per_epoch=70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bi6x05Sr60O9"
      },
      "outputs": [],
      "source": [
        "!ls *.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uu3g7vV7Bbt"
      },
      "outputs": [],
      "source": [
        "# Set TF_CONFIG env variable\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "txMXaq8d8N_S"
      },
      "outputs": [],
      "source": [
        "# first kill any previous runs\n",
        "%killbgscripts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RdgqmTjCd6xY"
      },
      "outputs": [],
      "source": [
        "# This should not print anything at the moment\n",
        "!lsof -i :12345"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qnSma_Ck7r-r"
      },
      "outputs": [],
      "source": [
        "%%bash --bg\n",
        "python main.py &> job_0.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hm2yrULE9281"
      },
      "outputs": [],
      "source": [
        "# Wait for logs to be written to the file\n",
        "time.sleep(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OfKFSnuWd6xa"
      },
      "outputs": [],
      "source": [
        "!lsof -i :12345"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vZEOuVgQ9-hn"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lAiYkkPu_Jqd"
      },
      "outputs": [],
      "source": [
        "tf_config['task']['index'] = 1\n",
        "os.environ['TF_CONFIG'] = json.dumps(tf_config)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ESVtyQ9_xjx"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "python main.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rc6hw3yTBKXX"
      },
      "outputs": [],
      "source": [
        "%%bash\n",
        "cat job_0.log"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
