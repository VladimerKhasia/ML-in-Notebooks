{"cells":[{"cell_type":"markdown","id":"X2kr8RP-lgql","metadata":{"id":"X2kr8RP-lgql"},"source":["Subword vocabulary is available here: https://drive.google.com/file/d/1O-fvfZMkesttA3oEIWQgU3a9wKxPcqHp/view?usp=sharing"]},{"cell_type":"code","execution_count":154,"id":"_e_KcZzgRtku","metadata":{"executionInfo":{"elapsed":5479,"status":"ok","timestamp":1675435067019,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"_e_KcZzgRtku"},"outputs":[],"source":["!pip install -q trax"]},{"cell_type":"code","execution_count":155,"id":"aV4zpTnSVFIp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2138,"status":"ok","timestamp":1675435069150,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"aV4zpTnSVFIp","outputId":"5e9a3649-1c57-4b6f-e066-fb3e02afc377"},"outputs":[{"name":"stdout","output_type":"stream","text":["trax                          1.4.1\n"]}],"source":["import json\n","import random\n","import numpy as np\n","from termcolor import colored\n","\n","import trax   \n","from trax import layers as tl\n","from trax.supervised import training\n","\n","!pip list | grep trax"]},{"cell_type":"code","execution_count":157,"id":"_fTwVNsKN3bL","metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1675435069151,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"_fTwVNsKN3bL"},"outputs":[],"source":["# filename of the MultiWOZ dialogue dataset\n","DATA_FILE = 'data.json'\n","\n","# data directory\n","DATA_DIR = './data'\n","\n","# dictionary where we will load the dialogue dataset\n","DIALOGUE_DB = {}\n","\n","# vocabulary filename\n","VOCAB_FILE = 'en_32k.subword'\n","\n","# vocabulary file directory\n","VOCAB_DIR = './'"]},{"cell_type":"markdown","id":"-OVaQO9eN3bL","metadata":{"id":"-OVaQO9eN3bL"},"source":["Download MultiWOZ 2.1 dataset here:  https://github.com/budzianowski/multiwoz/blob/master/data/MultiWOZ_2.1.zip"]},{"cell_type":"code","execution_count":null,"id":"KJnwVUmCUxb2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":283582,"status":"ok","timestamp":1675435352721,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"KJnwVUmCUxb2","outputId":"35c85d98-e6ad-4664-faad-0dbbb9907d14"},"outputs":[],"source":["!unzip ./MultiWOZ_2.1.zip\n","\n","## this is to update data, following original instructions: https://github.com/budzianowski/multiwoz\n","!python convert_to_multiwoz_format.py --multiwoz21_data_dir=<multiwoz21_data_dir> --output_file=<output json file>\n","\n","## and just rename directory to something nice e.g. data\n","!mv ./MultiWOZ_2.1 ./data"]},{"cell_type":"code","execution_count":159,"id":"K58I5vFB7GlP","metadata":{"executionInfo":{"elapsed":15015,"status":"ok","timestamp":1675435367729,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"K58I5vFB7GlP"},"outputs":[],"source":["# help function to load a JSON file\n","def load_json(directory, file):\n","    with open(f'{directory}/{file}') as file: \n","        db = json.load(file)\n","    return db\n","\n","# load the dialogue data set into our dictionary\n","DIALOGUE_DB = load_json(DATA_DIR, DATA_FILE)"]},{"cell_type":"code","execution_count":null,"id":"VGBnUfEk8p9x","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":127,"status":"ok","timestamp":1675435367730,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"VGBnUfEk8p9x","outputId":"407dc940-3d24-409e-c739-d5778dfc90e3"},"outputs":[],"source":["print(f'The number of dialogues is: {len(DIALOGUE_DB)}')"]},{"cell_type":"code","execution_count":null,"id":"JIz7KZRAN3bO","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":112,"status":"ok","timestamp":1675435367731,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"JIz7KZRAN3bO","outputId":"ac311033-40d4-40bc-ec45-b4d6fd1ebce6"},"outputs":[],"source":["# print 7 keys from the dataset to see the filenames\n","print(list(DIALOGUE_DB.keys())[0:7]) "]},{"cell_type":"code","execution_count":null,"id":"5KYeQLnG8p96","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":102,"status":"ok","timestamp":1675435367732,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"5KYeQLnG8p96","outputId":"5184a1bc-2b3d-4525-96ea-61fbcd2cfdd9"},"outputs":[],"source":["# get keys of the fifth file in the list above\n","print(DIALOGUE_DB['SNG0073.json'].keys())"]},{"cell_type":"code","execution_count":null,"id":"PPPWwQ2s8p9_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":93,"status":"ok","timestamp":1675435367732,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"PPPWwQ2s8p9_","outputId":"402d6776-93e7-4129-bb95-5adbc2e22a2b"},"outputs":[],"source":["DIALOGUE_DB['SNG0073.json']['goal']"]},{"cell_type":"code","execution_count":null,"id":"9qClBkFzN3bQ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":86,"status":"ok","timestamp":1675435367733,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"9qClBkFzN3bQ","outputId":"f041ac24-bb3a-41da-f711-a5514aa12980"},"outputs":[],"source":["# get first element of the log list\n","DIALOGUE_DB['SNG0073.json']['log'][0]"]},{"cell_type":"code","execution_count":null,"id":"G_i07x92N3bR","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":79,"status":"ok","timestamp":1675435367733,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"G_i07x92N3bR","outputId":"e473ec3f-ef9e-4fc2-ac40-6554a9f6a226"},"outputs":[],"source":["print(' Person 1: ', DIALOGUE_DB['SNG0073.json']['log'][0]['text'])\n","print(' Person 2: ',DIALOGUE_DB['SNG0073.json']['log'][1]['text'])"]},{"cell_type":"code","execution_count":166,"id":"a7i6syQGN3bS","metadata":{"executionInfo":{"elapsed":76,"status":"ok","timestamp":1675435367734,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"a7i6syQGN3bS"},"outputs":[],"source":["def get_conversation(file, data_db):\n","    '''\n","    Args:\n","        file (string): filename of the dialogue file saved as json\n","        data_db (dict): dialogue database\n","    \n","    Returns:\n","        string: A string containing the 'text' fields of  data[file]['log'][x]\n","    '''\n","    \n","    # initialize empty string\n","    result = ''\n","    \n","    # get length of file's log list\n","    len_msg_log = len(data_db[file]['log'])\n","    \n","    # set the delimiter strings\n","    delimiter_1 = ' Person 1: '\n","    delimiter_2 = ' Person 2: '\n","    \n","    # loop over the file's log list\n","    for i in range(len_msg_log):\n","        \n","        # get i'th element of file log list\n","        cur_log = data_db[file]['log'][i]\n","        \n","        # check if i is even\n","        if i%2 == 0:                   \n","            # append the 1st delimiter string\n","            result += delimiter_1\n","        else: \n","            # append the 2nd delimiter string\n","            result += delimiter_2\n","        \n","        # append the message text from the log\n","        result += cur_log['text']\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"id":"Ugvx0noP8p-G","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":71,"status":"ok","timestamp":1675435367735,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Ugvx0noP8p-G","outputId":"2dd66796-7f4d-4eee-c126-d7909f05bf1c"},"outputs":[],"source":["file = 'SNG01856.json'\n","conversation = get_conversation(file, DIALOGUE_DB)\n","\n","# print raw output\n","print(conversation)"]},{"cell_type":"code","execution_count":null,"id":"wabtyqi8N3bU","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":68,"status":"ok","timestamp":1675435367736,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"wabtyqi8N3bU","outputId":"65588816-83d4-4d21-c00f-d87fe459bb2b"},"outputs":[],"source":["def print_conversation(conversation):\n","    \n","    delimiter_1 = 'Person 1: '\n","    delimiter_2 = 'Person 2: '\n","    \n","    split_list_d1 = conversation.split(delimiter_1)\n","    \n","    for sublist in split_list_d1[1:]:\n","        split_list_d2 = sublist.split(delimiter_2)\n","        print(colored(f'Person 1: {split_list_d2[0]}', 'red'))\n","        \n","        if len(split_list_d2) > 1:\n","            print(colored(f'Person 2: {split_list_d2[1]}', 'green'))\n","\n","            \n","print_conversation(conversation)"]},{"cell_type":"code","execution_count":null,"id":"Rs2R8q1d8p-K","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":63,"status":"ok","timestamp":1675435367736,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Rs2R8q1d8p-K","outputId":"c5fe9659-0033-49cd-f9f7-1c0f8a55abc4"},"outputs":[],"source":["DIALOGUE_DB['SNG01856.json']['log'][0]"]},{"cell_type":"code","execution_count":null,"id":"HQmYUcsi8p-O","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":59,"status":"ok","timestamp":1675435367737,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"HQmYUcsi8p-O","outputId":"ce805cbd-4e6a-41a4-f641-78faab5402ed"},"outputs":[],"source":["# this is an example of the attractions file\n","attraction_file = open('data/attraction_db.json')\n","attractions = json.load(attraction_file)\n","print(attractions[0])"]},{"cell_type":"code","execution_count":null,"id":"I5kTg4uX8p-R","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56,"status":"ok","timestamp":1675435367738,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"I5kTg4uX8p-R","outputId":"ecd2093c-a7b5-4b81-beb0-88f406ff7803"},"outputs":[],"source":["# this is an example of the hospital file\n","hospital_file = open('data/hospital_db.json')\n","hospitals = json.load(hospital_file)\n","print(hospitals[0]) # feel free to index into other indices"]},{"cell_type":"code","execution_count":null,"id":"B5knaAEc8p-U","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":51,"status":"ok","timestamp":1675435367738,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"B5knaAEc8p-U","outputId":"17de593e-8b83-4187-cd8a-f96ea17375a6"},"outputs":[],"source":["# this is an example of the hotel file\n","hotel_file = open('data/hotel_db.json')\n","hotels = json.load(hotel_file)\n","print(hotels[0]) # feel free to index into other indices"]},{"cell_type":"code","execution_count":null,"id":"t-Rk01Mv8p-a","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48,"status":"ok","timestamp":1675435367739,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"t-Rk01Mv8p-a","outputId":"4e15324f-917d-4cf8-cb8c-9a45aa38b907"},"outputs":[],"source":["# this is an example of the police file\n","police_file = open('data/police_db.json')\n","police = json.load(police_file)\n","print(police[0]) # feel free to index into other indices"]},{"cell_type":"code","execution_count":null,"id":"u-G9pD8g8p-d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1675435367739,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"u-G9pD8g8p-d","outputId":"aefb7bef-2b2e-4863-c396-015a284c92f3"},"outputs":[],"source":["# this is an example of a restaurant file\n","restaurant_file = open('data/restaurant_db.json')\n","restaurants = json.load(restaurant_file)\n","print(restaurants[0]) # feel free to index into other indices"]},{"cell_type":"markdown","id":"k9eAKw4R8p-g","metadata":{"id":"k9eAKw4R8p-g"},"source":["For more information about the multiwoz 2.1 data set, please run the cell below to read the `ReadMe.txt` file. Feel free to open any other file to explore it. "]},{"cell_type":"code","execution_count":null,"id":"2H8pB_yI8p-g","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1675435367740,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"2H8pB_yI8p-g","outputId":"dd3a755b-0f33-45b2-f4d4-6a75fb30977c"},"outputs":[],"source":["with open('data/README') as file:\n","    print(file.read())"]},{"cell_type":"code","execution_count":null,"id":"IrnQ9eNV8p-k","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":868,"status":"ok","timestamp":1675435368573,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"IrnQ9eNV8p-k","outputId":"6fea790e-14d0-4e71-d063-b57b782f21a7"},"outputs":[],"source":["# the keys are the file names\n","all_files = DIALOGUE_DB.keys()\n","\n","# initialize empty list\n","untokenized_data = []\n","\n","# loop over all files\n","for file in all_files:\n","    # this is the graded function you coded\n","    # returns a string delimited by Person 1 and Person 2\n","    result = get_conversation(file, DIALOGUE_DB)\n","    \n","    # append to the list\n","    untokenized_data.append(result)\n","\n","# print the first element to check if it's the same as the one we got before\n","print(untokenized_data[0])"]},{"cell_type":"code","execution_count":null,"id":"buE0b8bjx_p_","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1675435368574,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"buE0b8bjx_p_","outputId":"97329da4-8240-40c8-fbfc-c3577f4ddb85"},"outputs":[],"source":["# shuffle the list we generated above\n","random.shuffle(untokenized_data)\n","\n","# define a cutoff (5% of the total length for this assignment)\n","# convert to int because we will use it as a list index\n","cut_off = int(len(untokenized_data) * .05)\n","\n","# slice the list. the last elements after the cut_off value will be the eval set. the rest is for training. \n","train_data, eval_data = untokenized_data[:-cut_off], untokenized_data[-cut_off:]\n","\n","print(f'number of conversations in the data set: {len(untokenized_data)}')\n","print(f'number of conversations in train set: {len(train_data)}')\n","print(f'number of conversations in eval set: {len(eval_data)}')"]},{"cell_type":"code","execution_count":179,"id":"ir9YsBkFN3bZ","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1675435368575,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"ir9YsBkFN3bZ"},"outputs":[],"source":["def stream(data):\n","    # loop over the entire data\n","    while True:\n","        # get a random element\n","        d = random.choice(data)\n","        \n","        # yield a tuple pair of identical values \n","        # (i.e. our inputs to the model will also be our targets during training)\n","        yield (d, d)"]},{"cell_type":"code","execution_count":180,"id":"uZgK5FAAWwOu","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1675435368576,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"uZgK5FAAWwOu"},"outputs":[],"source":["# trax allows us to use combinators to generate our data pipeline\n","data_pipeline = trax.data.Serial(\n","    # randomize the stream\n","    trax.data.Shuffle(),\n","    \n","    # tokenize the data\n","    trax.data.Tokenize(vocab_dir=VOCAB_DIR,\n","                       vocab_file=VOCAB_FILE),\n","    \n","    # filter too long sequences\n","    trax.data.FilterByLength(2048),\n","    \n","    # bucket by length\n","    trax.data.BucketByLength(boundaries=[128, 256,  512, 1024],\n","                             batch_sizes=[16,    8,    4,   2, 1]),\n","    \n","    # add loss weights but do not add it to the padding tokens (i.e. 0)\n","    trax.data.AddLossWeights(id_to_mask=0)\n",")\n","\n","# apply the data pipeline to our train and eval sets\n","train_stream = data_pipeline(stream(train_data))\n","eval_stream = data_pipeline(stream(eval_data))"]},{"cell_type":"code","execution_count":null,"id":"9iBQEvhLYRot","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":959,"status":"ok","timestamp":1675435369527,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"9iBQEvhLYRot","outputId":"4068b0ac-5cdd-4944-f284-f799267d3de4"},"outputs":[],"source":["# the stream generators will yield (input, target, weights). let's just grab the input for inspection\n","inp, _, _ = next(train_stream)\n","\n","# print the shape. format is (batch size, token length)\n","print(\"input shape: \", inp.shape)\n","\n","# detokenize the first element\n","print(trax.data.detokenize(inp[0], vocab_dir=VOCAB_DIR, vocab_file=VOCAB_FILE))"]},{"cell_type":"code","execution_count":182,"id":"adX2eU762BkF","metadata":{"executionInfo":{"elapsed":547,"status":"ok","timestamp":1675435370064,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"adX2eU762BkF"},"outputs":[],"source":["def reversible_layer_forward(x, f, g):\n","    \"\"\"\n","    Args: \n","        x (np.array): an input vector or matrix\n","        f (function): a function which operates on a vector/matrix\n","        g (function): a function which operates on a vector/matrix\n","    Returns: \n","        y (np.array): an output vector or matrix whose form is determined by 'x', f and g\n","    \"\"\"\n","    # split the input vector into two (* along the last axis because it is the depth dimension)\n","    x1, x2 = np.split(x, 2, axis=-1) \n","    \n","    # get y1 using equation 3\n","    y1 = x1 + f(x2)\n","    \n","    # get y2 using equation 4\n","    y2 = x2 + g(y1)\n","    \n","    # concatenate y1 and y2 along the depth dimension. be sure output is of type np.ndarray\n","    y = np.concatenate([y1, y2], axis=-1)\n","     \n","    return y"]},{"cell_type":"code","execution_count":184,"id":"0xTCG9WlaiiO","metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1675435370065,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"0xTCG9WlaiiO"},"outputs":[],"source":["def reversible_layer_reverse(y, f, g):\n","    \"\"\"\n","    Args: \n","        y (np.array): an input vector or matrix\n","        f (function): a function which operates on a vector/matrix of the form of 'y'\n","        g (function): a function which operates on a vector/matrix of the form of 'y'\n","    Returns: \n","        y (np.array): an output vector or matrix whose form is determined by 'y', f and g\n","    \"\"\"\n","    \n","    # split the input vector into two (* along the last axis because it is the depth dimension)\n","    y1, y2 = np.split(y, 2, axis=-1)\n","    \n","    # compute x2 using equation 5\n","    x2 = y2 - g(y1)\n","    \n","    # compute x1 using equation 6\n","    x1 = y1 - f(x2)\n","    \n","    # concatenate x1 and x2 along the depth dimension\n","    x = np.concatenate([x1, x2], axis=-1)\n","    \n","    return x\n"]},{"cell_type":"code","execution_count":185,"id":"o66C0Nfoafjf","metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1675435370066,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"o66C0Nfoafjf"},"outputs":[],"source":["# UNIT TEST\n","f = lambda x: x + 2\n","g = lambda x: x * 3\n","input_vector = np.random.uniform(size=(32,))\n","\n","output_vector = reversible_layer_forward(input_vector, f, g)\n","reversed_vector = reversible_layer_reverse(output_vector, f, g)\n","\n","assert np.allclose(reversed_vector, input_vector)"]},{"cell_type":"code","execution_count":187,"id":"IjElqUtc2BYG","metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1675435370067,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"IjElqUtc2BYG"},"outputs":[],"source":["# Layers like dropout have noise, so let's simulate it here:\n","f = lambda x: x + np.random.uniform(size=x.shape)\n","\n","# See that the above doesn't work any more:\n","output_vector = reversible_layer_forward(input_vector, f, g)\n","reversed_vector = reversible_layer_reverse(output_vector, f, g)\n","\n","assert not np.allclose(reversed_vector, input_vector)  # Fails!!\n","\n","# It failed because the noise when reversing used a different random seed.\n","\n","random_seed = 27686\n","rng = trax.fastmath.random.get_prng(random_seed)\n","f = lambda x: x + trax.fastmath.random.uniform(key=rng, shape=x.shape)\n","\n","# See that it works now as the same rng is used on forward and reverse.\n","output_vector = reversible_layer_forward(input_vector, f, g)\n","reversed_vector = reversible_layer_reverse(output_vector, f, g)\n","\n","assert np.allclose(reversed_vector, input_vector,  atol=1e-07) "]},{"cell_type":"code","execution_count":188,"id":"RidbAcoR6duP","metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1675435370068,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"RidbAcoR6duP"},"outputs":[],"source":["def ReformerLM(vocab_size=33000, n_layers=2, mode='train', attention_type=tl.SelfAttention):\n","    \n","    # initialize an instance of Trax's ReformerLM class\n","    model = trax.models.reformer.ReformerLM( \n","        # set vocab size\n","        vocab_size=vocab_size,\n","        # set number of layers\n","        n_layers=n_layers,\n","        # set mode\n","        mode=mode,\n","        # set attention type\n","        attention_type=attention_type\n","    )\n","\n","    return tl.Serial(model, tl.LogSoftmax(),)  ## model"]},{"cell_type":"code","execution_count":null,"id":"cZTrXSBMN3be","metadata":{"id":"cZTrXSBMN3be"},"outputs":[],"source":["# display the model\n","temp_model = ReformerLM('train')\n","print(str(temp_model))\n","\n","# free memory\n","#del temp_model "]},{"cell_type":"code","execution_count":191,"id":"tQehGhoD4Psl","metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1675435370069,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"tQehGhoD4Psl"},"outputs":[],"source":["def training_loop(ReformerLM, train_gen, eval_gen, output_dir = \"./model/\"):\n","    \"\"\"\n","    Args:\n","        ReformerLM:  the Reformer language model you are building\n","        train_gen (generator): train data generator.\n","        eval_gen (generator): Validation generator. \n","        output_dir (string): Path to save the model output. Defaults to './model/'.\n","\n","    Returns:\n","        trax.supervised.training.Loop: Training loop for the model.\n","    \"\"\"\n","\n","    # use the warmup_and_rsqrt_decay learning rate schedule\n","    lr_schedule = trax.lr.warmup_and_rsqrt_decay(\n","        n_warmup_steps=1000, max_value=0.01)\n","\n","    # define the train task\n","    train_task = training.TrainTask(            \n","        # labeled data\n","        labeled_data=train_gen,\n","        # loss layer\n","        loss_layer=tl.CrossEntropyLoss(),\n","        # optimizer\n","        optimizer=trax.optimizers.Adam(0.01),\n","        # lr_schedule\n","        lr_schedule=lr_schedule,\n","        # n_steps\n","        n_steps_per_checkpoint=10\n","    )\n","\n","    # define the eval task\n","    eval_task = training.EvalTask(                      \n","        # labeled data\n","        labeled_data=eval_gen,\n","        # metrics\n","        metrics=[tl.CrossEntropyLoss(), tl.Accuracy()]\n","    )\n","    \n","    loop = training.Loop(ReformerLM(mode='train'),\n","                         train_task,\n","                         eval_tasks=[eval_task],\n","                         output_dir=output_dir)\n","    return loop"]},{"cell_type":"code","execution_count":null,"id":"p9jERXY46I6J","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":274917,"status":"ok","timestamp":1675435731861,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"p9jERXY46I6J","outputId":"73d46338-f255-441f-a052-f38f43f9b163"},"outputs":[],"source":["# we will now test your function\n","!rm -f model/model.pkl.gz\n","loop = training_loop(ReformerLM, train_stream, eval_stream)\n","loop.run(10)"]},{"cell_type":"code","execution_count":227,"id":"QHjHvWS_N3bh","metadata":{"executionInfo":{"elapsed":547,"status":"ok","timestamp":1675437909700,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"QHjHvWS_N3bh"},"outputs":[],"source":["# define the `predict_mem_len` and `predict_drop_len` of tl.SelfAttention\n","def attention(*args, **kwargs):\n","    # number of input positions to remember in a cache when doing fast inference. \n","    kwargs['predict_mem_len'] = 120\n","    # number of input elements to drop once the fast inference input cache fills up.\n","    kwargs['predict_drop_len'] = 120\n","    # return the attention layer with the parameters defined above\n","    return tl.SelfAttention(*args, **kwargs)\n","\n","# define the model using the ReformerLM function you implemented earlier.\n","model = ReformerLM(\n","    vocab_size=33000,\n","    n_layers=2,\n","    mode='predict',\n","    attention_type=attention,\n",")\n","\n","# define an input signature so we can initialize our model. shape will be (1, 1) and the data type is int32.\n","shape11 = trax.shapes.ShapeDtype((1, 1), dtype=np.int32)"]},{"cell_type":"code","execution_count":228,"id":"LOuYYkFRN3bh","metadata":{"executionInfo":{"elapsed":6459,"status":"ok","timestamp":1675437921093,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"LOuYYkFRN3bh"},"outputs":[],"source":["## initialize from file\n","\n","### in case you use in this notebook 'trained' simple model:\n","model.init_from_file('./model/model.pkl.gz',  \n","                     weights_only=True, \n","                     input_signature=shape11)\n","\n","### save the starting state\n","STARTING_STATE = model.state"]},{"cell_type":"code","execution_count":229,"id":"nobr6fsiN3bi","metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1675437926688,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"nobr6fsiN3bi"},"outputs":[],"source":["def tokenize(sentence, vocab_file, vocab_dir):\n","    return list(trax.data.tokenize(iter([sentence]), vocab_file=vocab_file, vocab_dir=vocab_dir))[0]\n","\n","def detokenize(tokens, vocab_file, vocab_dir):\n","    return trax.data.detokenize(tokens, vocab_file=vocab_file, vocab_dir=vocab_dir)"]},{"cell_type":"code","execution_count":197,"id":"7oP0vI5tN3bi","metadata":{"executionInfo":{"elapsed":43,"status":"ok","timestamp":1675435739142,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"7oP0vI5tN3bi"},"outputs":[],"source":["def ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file, vocab_dir, temperature, tokenize=tokenize):\n","    \"\"\"\n","    Args:\n","        ReformerLM:  the Reformer language model you just trained\n","        start_sentence (string): starting sentence of the conversation\n","        vocab_file (string): vocabulary filename\n","        vocab_dir (string): directory of the vocabulary file\n","        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n","            0.0: same as argmax, always pick the most probable token\n","            1.0: sampling from the distribution (can sometimes say random things)\n","\n","    Returns:\n","        generator: yields the next symbol generated by the model\n","    \"\"\"\n","    \n","    # Create input tokens using the the tokenize function\n","    input_tokens = tokenize(start_sentence, vocab_file=vocab_file, vocab_dir=vocab_dir)\n","    \n","    # Add batch dimension to array. Convert from (n,) to (x, n) where \n","    # x is the batch size. Default is 1. (hint: you can use np.expand_dims() with axis=0)\n","    input_tokens_with_batch = np.array(input_tokens)[None, :]\n","    \n","    # call the autoregressive_sample_stream function from trax\n","    output_gen = trax.supervised.decoding.autoregressive_sample_stream( \n","        # model\n","        ReformerLM,\n","        # inputs will be the tokens with batch dimension\n","        inputs=input_tokens_with_batch,\n","        # temperature\n","        temperature=temperature\n","    )\n","    \n","    return output_gen"]},{"cell_type":"code","execution_count":215,"id":"SVO74VOaN3bj","metadata":{"executionInfo":{"elapsed":252,"status":"ok","timestamp":1675437054535,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"SVO74VOaN3bj"},"outputs":[],"source":["# ## UNIT TEST\n","test_model = ReformerLM(vocab_size=5, n_layers=1, mode='predict', attention_type=attention)\n","test_output_gen = ReformerLM_output_gen(test_model, \"test\", vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, temperature=0)\n","\n","# ## test_ReformerLM_output_gen(test_model, test_output_gen)\n","del test_model, test_output_gen"]},{"cell_type":"code","execution_count":206,"id":"DV_7B3xcN3bj","metadata":{"executionInfo":{"elapsed":544,"status":"ok","timestamp":1675436710802,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"DV_7B3xcN3bj"},"outputs":[],"source":["shape11 = trax.shapes.ShapeDtype((1, 1), dtype=np.int32)\n","\n","def attention(*args, **kwargs):\n","    kwargs['predict_mem_len'] = 120  # max length for predictions\n","    kwargs['predict_drop_len'] = 120  # never drop old stuff\n","    return tl.SelfAttention(*args, **kwargs)\n","\n","model = ReformerLM(\n","    vocab_size=33000,\n","    n_layers=2,\n","    mode='predict',\n","    attention_type=attention,\n",")"]},{"cell_type":"code","execution_count":230,"id":"fp9Y6ZWnN3bk","metadata":{"executionInfo":{"elapsed":5834,"status":"ok","timestamp":1675438046350,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"fp9Y6ZWnN3bk"},"outputs":[],"source":["model.init_from_file('./model/model.pkl.gz',\n","                     weights_only=True, input_signature=shape11)\n","\n","STARTING_STATE = model.state"]},{"cell_type":"code","execution_count":285,"id":"3qTLL1r9N3bk","metadata":{"executionInfo":{"elapsed":412,"status":"ok","timestamp":1675447623520,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"3qTLL1r9N3bk"},"outputs":[],"source":["def generate_dialogue(ReformerLM, model_state, start_sentence, vocab_file, vocab_dir, max_len, temperature):\n","    \"\"\"\n","    Args:\n","        ReformerLM:  the Reformer language model you just trained\n","        model_state (np.array): initial state of the model before decoding\n","        start_sentence (string): starting sentence of the conversation\n","        vocab_file (string): vocabulary filename\n","        vocab_dir (string): directory of the vocabulary file\n","        max_len (int): maximum number of tokens to generate \n","        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n","            0.0: same as argmax, always pick the most probable token\n","            1.0: sampling from the distribution (can sometimes say random things)\n","\n","    Returns:\n","        generator: yields the next symbol generated by the model\n","    \"\"\"  \n","\n","    # define the delimiters we used during training\n","    delimiter_1 = 'Person 1: ' \n","    delimiter_2 = 'Person 2: '\n","    \n","    # initialize detokenized output\n","    sentence = ''\n","    \n","    # token counter\n","    counter = 0\n","    \n","    # output tokens. we insert a ': ' for formatting\n","    result = [tokenize(': ', vocab_file=vocab_file, vocab_dir=vocab_dir)]\n","    \n","    # reset the model state when starting a new dialogue\n","    ReformerLM.state = model_state\n","    \n","    # calls the output generator implemented earlier\n","    output = ReformerLM_output_gen(ReformerLM, start_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, temperature=temperature)\n","    \n","    # print the starting sentence\n","    print(start_sentence.split(delimiter_2)[0].strip())\n","    \n","    # loop below yields the next tokens until max_len is reached. the if-elif is just for prettifying the output.\n","    for o in output:\n","        \n","        result.append(o)\n","        \n","        sentence = detokenize(np.concatenate(result, axis=0), vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)\n","        \n","        #### in case your model is not really trained - sentence check for bad, purely trained model\n","        check_sentence = sentence\n","\n","        if sentence.endswith(delimiter_1):\n","            sentence = sentence.split(delimiter_1)[0]\n","            print(f'{delimiter_2}{sentence}')\n","            sentence = ''\n","            result.clear()\n","\n","        elif sentence.endswith(delimiter_2):\n","            sentence = sentence.split(delimiter_2)[0]\n","            print(f'{delimiter_1}{sentence}')\n","            sentence = ''\n","            result.clear()\n","\n","        counter += 1\n"," \n","        if counter > max_len:\n","            #### in case your model is not really trained - sentence check for bad, purely trained model\n","            print(f'we use check_sentence for the case when model is not well trained only to check the last sentence was:\\n {check_sentence}')\n","            break  \n","        \n","        "]},{"cell_type":"code","execution_count":null,"id":"7Ad21gweN3bl","metadata":{"id":"7Ad21gweN3bl"},"outputs":[],"source":["sample_sentence = ' Person 1: Are there theatres in town? Person 2: '\n","generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, \n","                  vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=120, temperature=0.2)"]},{"cell_type":"code","execution_count":null,"id":"-L5KjU9-N3bl","metadata":{"id":"-L5KjU9-N3bl"},"outputs":[],"source":["sample_sentence = ' Person 1: Is there a hospital nearby? Person 2: '\n","generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=120, temperature=0.2)"]},{"cell_type":"code","execution_count":null,"id":"lbzogfMYN3bl","metadata":{"id":"lbzogfMYN3bl"},"outputs":[],"source":["sample_sentence = ' Person 1: Can you book a taxi? Person 2: '\n","generate_dialogue(ReformerLM=model, model_state=STARTING_STATE, start_sentence=sample_sentence, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_len=120, temperature=0.2)"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"}},"nbformat":4,"nbformat_minor":5}
