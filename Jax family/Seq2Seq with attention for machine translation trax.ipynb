{"cells":[{"cell_type":"markdown","id":"sJfpHEv47Wol","metadata":{"id":"sJfpHEv47Wol"},"source":["Original paper: https://arxiv.org/abs/1409.0473\n","\n","Data: \n","\n","medical  https://www.tensorflow.org/datasets/catalog/ (from https://opus.nlpl.eu/) \n","\n","English and German subword wocabulary: https://drive.google.com/file/d/1mc1DQUyZg8FjvqDHVqvlEoW929mupnCw/view?usp=sharing \n","\n","\n","``this is where the file should go ./data/english_german.subword ``"]},{"cell_type":"code","execution_count":null,"id":"j554eOz4BXS8","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":48325,"status":"ok","timestamp":1675346761423,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"j554eOz4BXS8","outputId":"d634385c-c62e-44e3-c30d-98cffc40a1c0"},"outputs":[],"source":["!pip install -q -U trax"]},{"cell_type":"code","execution_count":2,"id":"8SKZ3fd72oOX","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":38827,"status":"ok","timestamp":1675346800233,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"8SKZ3fd72oOX","outputId":"c46e26e6-98e2-4a9a-d576-80a77e1421ed"},"outputs":[{"name":"stdout","output_type":"stream","text":["trax                          1.4.1\n"]}],"source":["from termcolor import colored\n","import random\n","import numpy as np\n","\n","import trax\n","from trax import layers as tl\n","from trax.fastmath import numpy as fastnp\n","from trax.supervised import training\n","\n","\n","!pip list | grep trax"]},{"cell_type":"code","execution_count":null,"id":"R9Qg5g972oOa","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":202,"referenced_widgets":["531b690e13ca428fbb2cd7aad6fe410f","f08d6e7a9f9546e49d94371e316a3c6b","1f424062372947218416e350d45031c4","8cc86550644442c4a21a072462075827","0f89a9655cac4c68b5aa4b0bbeeae096","9afd2252d62b40f0a9b108a9e99cd8ef","a513ee198700421d8656ca276f09cb5d","d87521b7340e47368b27528ba5ed1278","919f8d1f22ff42e8b06b2ca413c0e6f9","be3e7ec1cbd4404fbda87f0eab24e848","207a0ad27c72407d94deea3ad49e9301","7ded022381cd489e8a281a5f8eb51d2c","789feb0e8de143e09af7e95f8a496f96","e6bfeb5a8796468498e520c05d481999","595ab62007784a00bf42e0e4ad18ccde","15c8fc7218e04fbdbcfaebf7a5baf77e","cfd5fda75fee46968cfe561ec0dd9cee","9d0eb0a264c04503972cac022c62c3d1","a66b52e4a4cf4483adb82d98518aeaf6","c8f5e39b57f942e791bd90ed4f3cd69a","d314756539ee486d8e5efa35167b93bb","b6d37afec0584b87b45335d1bcdcbac3","46ae37dd9ee74005a0c31baca332e12c","0b4d481c55224b2d8de0c103a3b207e2","72c543cf65f344b8b76b6ad8687e9020","6e31fd1316d94c16b7517ced9a1a7e59","62b7773f79e4470dbe423a0736909d51","50a042229c1a4e6894da874e9723336e","eba1e272087f41f6bccbc7ccf6d1794f","f127c435c2f8478a971e9e131aea0556","87b464cc95a44ed7a899e6874dd7dae8","ab74ddb5c1c7492eb4bb11bb990a9319","3b5eccb1c72d4b959fe88017dd0f6022","476d33d5c86443b79fb1b08bdfea6038","2bfba65e95144566870238e5e340e88d","c3946cb34e494f288139ee0003897f22","df71aa4f321f4d0e96edd7f2be522bb7","06c19ea2344d419a92965923341f95e4","5c2439e4877d4e91adf023703b737625","67aa070a4e0747ee97197e0ee1d2faf4","c5f3730fdf7e4c3d9bff7cf10c86977c","1d280b41d5b04deab6e22fed3e08aa81","5c5bc4df0f0444619086f0bce88512b1","28a68b9847044a7aaa585fe7a43f58f7","e34dc9110b46468e9c71a8d669177fed","c00c2ad6aa3a4eecb7b787ec5395ab22","ce540a045ebd430f94afce78a4d8f5a4","1c3aa95a742b496da7403182b197395e","2624091f285a4bb28333a665007ee66f","8c089080046545acba67166ea5d52871","cbaba7bc954e47b3a1192c7a5ca10ea6","175fd930e9e5476eb453e9d68e9dbda9","b8b2448ad54b4c959ca16163cea33b20","2bb35b602f53485aa85321a28023285c","ef707a497db3499bbcd02dc13938de67","50ee702cc0b84099b457af5e4a6b6829","f57cbfc78b4742c9861346d066df8100","dbf82f8ebaee44a89e992948c0219f3a","74f3007de49a4f6d9238a406529bc634","9b6a2ebe2feb45acb696f01489323865","f87e98292b214bdfaa9b911579aa9a87","88ed082be82f41258d951d1168082344","fa462f5fbdac475d8796ffc525263069","23a7f3a9f2ac4c5fbd63d2dcdffb2a65","e6f14b13cf374b038bba53bde3d08df4","76d2fb8412c3430eacf29e7128bd233e"]},"executionInfo":{"elapsed":109507,"status":"ok","timestamp":1675346910352,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"R9Qg5g972oOa","outputId":"5ae6395a-4904-4747-dff3-9391ec0f52c4"},"outputs":[],"source":["# Get generator function for the training set\n","# This will download the train dataset if no data_dir is specified.\n","train_stream_fn = trax.data.TFDS('opus/medical',\n","                                 data_dir='./data/',\n","                                 keys=('en', 'de'),\n","                                 eval_holdout_size=0.01, # 1% for eval\n","                                 train=True\n","                                )\n","\n","# Get generator function for the eval set\n","eval_stream_fn = trax.data.TFDS('opus/medical',\n","                                data_dir='./data/',\n","                                keys=('en', 'de'),\n","                                eval_holdout_size=0.01, # 1% for eval                                \n","                                train=False\n","                               )"]},{"cell_type":"code","execution_count":null,"id":"u2oKy0Hu2oOb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1675346910352,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"u2oKy0Hu2oOb","outputId":"53fb8538-96fd-42be-ba48-59fcef97cb65"},"outputs":[],"source":["train_stream = train_stream_fn()\n","print(colored('train data (en, de) tuple:', 'red'), next(train_stream))\n","print()\n","\n","eval_stream = eval_stream_fn()\n","print(colored('eval data (en, de) tuple:', 'red'), next(eval_stream))"]},{"cell_type":"code","execution_count":6,"id":"0UztvGR42oOd","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1675346910353,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"0UztvGR42oOd"},"outputs":[],"source":["## we will use subword representations to tokenize our sentences. This is a common technique to \n","## avoid out-of-vocabulary words by allowing parts of words to be represented separately. For example, \n","## instead of having separate entries in your vocabulary for --\"fear\", \"fearless\", \"fearsome\", \"some\", and \"less\"--, \n","## you can simply store --\"fear\", \"some\", and \"less\"-- then allow your tokenizer to combine these subwords when needed. \n","## This allows it to be more flexible so you won't have to save uncommon words explicitly in your vocabulary \n","## (e.g. stylebender, nonce, etc). Tokenizing is done with the trax.data.Tokenize() command.\n","## combined subword vocabulary for English and German in file \"ende_32k.subword\"\n","\n","# global variables that state the filename and directory of the vocabulary file\n","## here are the ways you can build the subword vocabulary:\n","   ## 1. https://stackoverflow.com/questions/65485242/what-is-subwords-file-in-natural-language-processing-to-use-as-vocabulary-file\n","         ## https://github.com/google/sentencepiece/blob/master/python/sentencepiece_python_module_example.ipynb\n","   ## 2. https://www.tensorflow.org/text/guide/subwords_tokenizer\n","VOCAB_FILE = 'english_german.subword'\n","VOCAB_DIR = './data/'          ##'./data/'\n","\n","# Tokenize the dataset.\n","tokenized_train_stream = trax.data.Tokenize(vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)(train_stream)\n","tokenized_eval_stream = trax.data.Tokenize(vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR)(eval_stream)"]},{"cell_type":"code","execution_count":7,"id":"k4OyfoKC2oOe","metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1675346910353,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"k4OyfoKC2oOe"},"outputs":[],"source":["# Append EOS at the end of each sentence.\n","\n","# Integer assigned as end-of-sentence (EOS)\n","EOS = 1\n","\n","# generator helper function to append EOS to each sentence\n","def append_eos(stream):\n","    for (inputs, targets) in stream:\n","        inputs_with_eos = list(inputs) + [EOS]\n","        targets_with_eos = list(targets) + [EOS]\n","        yield np.array(inputs_with_eos), np.array(targets_with_eos)\n","\n","# append EOS to the train data\n","tokenized_train_stream = append_eos(tokenized_train_stream)\n","\n","# append EOS to the eval data\n","tokenized_eval_stream = append_eos(tokenized_eval_stream)"]},{"cell_type":"code","execution_count":null,"id":"Iho5779h2oOf","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":706,"status":"ok","timestamp":1675346911050,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Iho5779h2oOf","outputId":"4f4ac13c-d506-4307-dbab-7824c9192cec"},"outputs":[],"source":["# Filter too long sentences to not run out of memory.\n","# length_keys=[0, 1] means we filter both English and German sentences, so\n","# both must be not longer than 512 tokens for training / 512 for eval.\n","filtered_train_stream = trax.data.FilterByLength(\n","    max_length=512, length_keys=[0, 1])(tokenized_train_stream)\n","filtered_eval_stream = trax.data.FilterByLength(\n","    max_length=512, length_keys=[0, 1])(tokenized_eval_stream)\n","\n","# print a sample input-target pair of tokenized sentences\n","train_input, train_target = next(filtered_train_stream)\n","print(colored(f'Single tokenized example input:', 'red' ), train_input)\n","print(colored(f'Single tokenized example target:', 'red'), train_target)"]},{"cell_type":"code","execution_count":9,"id":"22ER9OP22oOg","metadata":{"executionInfo":{"elapsed":37,"status":"ok","timestamp":1675346911050,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"22ER9OP22oOg"},"outputs":[],"source":["# Setup helper functions for tokenizing and detokenizing sentences\n","\n","def tokenize(input_str, vocab_file=None, vocab_dir=None):\n","    \"\"\"Encodes a string to an array of integers\n","\n","    Args:\n","        input_str (str): human-readable string to encode\n","        vocab_file (str): filename of the vocabulary text file\n","        vocab_dir (str): path to the vocabulary file\n","  \n","    Returns:\n","        numpy.ndarray: tokenized version of the input string\n","    \"\"\"\n","    \n","    # Set the encoding of the \"end of sentence\" as 1\n","    EOS = 1\n","    \n","    # Use the trax.data.tokenize method. It takes streams and returns streams,\n","    # we get around it by making a 1-element stream with `iter`.\n","    inputs =  next(trax.data.tokenize(iter([input_str]),\n","                                      vocab_file=vocab_file, vocab_dir=vocab_dir))\n","    \n","    # Mark the end of the sentence with EOS\n","    inputs = list(inputs) + [EOS]\n","    \n","    # Adding the batch dimension to the front of the shape\n","    batch_inputs = np.reshape(np.array(inputs), [1, -1])\n","    \n","    return batch_inputs\n","\n","\n","def detokenize(integers, vocab_file=None, vocab_dir=None):\n","    \"\"\"Decodes an array of integers to a human readable string\n","\n","    Args:\n","        integers (numpy.ndarray): array of integers to decode\n","        vocab_file (str): filename of the vocabulary text file\n","        vocab_dir (str): path to the vocabulary file\n","  \n","    Returns:\n","        str: the decoded sentence.\n","    \"\"\"\n","    \n","    # Remove the dimensions of size 1\n","    integers = list(np.squeeze(integers))\n","    \n","    # Set the encoding of the \"end of sentence\" as 1\n","    EOS = 1\n","    \n","    # Remove the EOS to decode only the original tokens\n","    if EOS in integers:\n","        integers = integers[:integers.index(EOS)] \n","    \n","    return trax.data.detokenize(integers, vocab_file=vocab_file, vocab_dir=vocab_dir)"]},{"cell_type":"code","execution_count":null,"id":"S1TyIWzL2oOh","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1675346911053,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"S1TyIWzL2oOh","outputId":"7c36f8a5-2238-49f8-cd0e-32a873a02f3f"},"outputs":[],"source":["# As declared earlier:\n","# VOCAB_FILE = 'ende_32k.subword'\n","# VOCAB_DIR = 'data/'\n","\n","# Detokenize an input-target pair of tokenized sentences\n","print(colored(f'Single detokenized example input:', 'red'), detokenize(train_input, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))\n","print(colored(f'Single detokenized example target:', 'red'), detokenize(train_target, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))\n","print()\n","\n","# Tokenize and detokenize a word that is not explicitly saved in the vocabulary file.\n","# See how it combines the subwords -- 'hell' and 'o'-- to form the word 'hello'.\n","print(colored(f\"tokenize('hello'): \", 'green'), tokenize('hello', vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))\n","print(colored(f\"detokenize([17332, 140, 1]): \", 'green'), detokenize([17332, 140, 1], vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR))"]},{"cell_type":"code","execution_count":11,"id":"8qquGX922oOi","metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1675346911054,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"8qquGX922oOi"},"outputs":[],"source":["# Bucketing to create streams of batches.\n","\n","# Buckets are defined in terms of boundaries and batch sizes.\n","# Batch_sizes[i] determines the batch size for items with length < boundaries[i]\n","# So below, we'll take a batch of 256 sentences of length < 8, 128 if length is\n","# between 8 and 16, and so on -- and only 2 if length is over 512.\n","boundaries =  [8,   16,  32, 64, 128, 256, 512]\n","batch_sizes = [256, 128, 64, 32, 16,    8,   4,  2]\n","\n","# Create the generators.\n","train_batch_stream = trax.data.BucketByLength(\n","    boundaries, batch_sizes,\n","    length_keys=[0, 1]  # As before: count inputs and targets to length.\n",")(filtered_train_stream)\n","\n","eval_batch_stream = trax.data.BucketByLength(\n","    boundaries, batch_sizes,\n","    length_keys=[0, 1]  # As before: count inputs and targets to length.\n",")(filtered_eval_stream)\n","\n","# Add masking for the padding (0s).\n","train_batch_stream = trax.data.AddLossWeights(id_to_mask=0)(train_batch_stream)\n","eval_batch_stream = trax.data.AddLossWeights(id_to_mask=0)(eval_batch_stream)"]},{"cell_type":"code","execution_count":null,"id":"2dAfEITx2oOj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33,"status":"ok","timestamp":1675346911054,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"2dAfEITx2oOj","outputId":"00535d48-5a5c-450a-b74d-7f91614e7eeb"},"outputs":[],"source":["input_batch, target_batch, mask_batch = next(train_batch_stream)\n","\n","# let's see the data type of a batch\n","print(\"input_batch data type: \", type(input_batch))\n","print(\"target_batch data type: \", type(target_batch))\n","\n","# let's see the shape of this particular batch (batch length, sentence length)\n","print(\"input_batch shape: \", input_batch.shape)\n","print(\"target_batch shape: \", target_batch.shape)"]},{"cell_type":"code","execution_count":null,"id":"yq9qJglF2oOj","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1675346911057,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"yq9qJglF2oOj","outputId":"367c91e8-6dc8-4d33-cb4a-cf3169899be1"},"outputs":[],"source":["# pick a random index less than the batch size.\n","index = random.randrange(len(input_batch))\n","\n","# use the index to grab an entry from the input and target batch\n","print(colored('THIS IS THE ENGLISH SENTENCE: \\n', 'red'), detokenize(input_batch[index], vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR), '\\n')\n","print(colored('THIS IS THE TOKENIZED VERSION OF THE ENGLISH SENTENCE: \\n ', 'red'), input_batch[index], '\\n')\n","print(colored('THIS IS THE GERMAN TRANSLATION: \\n', 'red'), detokenize(target_batch[index], vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR), '\\n')\n","print(colored('THIS IS THE TOKENIZED VERSION OF THE GERMAN TRANSLATION: \\n', 'red'), target_batch[index], '\\n')"]},{"cell_type":"code","execution_count":14,"id":"NLVLspNX2oOl","metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1675346911058,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"NLVLspNX2oOl"},"outputs":[],"source":["def input_encoder_fn(input_vocab_size, d_model, n_encoder_layers):\n","    \"\"\" Input encoder runs on the input sentence and creates\n","    activations that will be the keys and values for attention.\n","    \n","    Args:\n","        input_vocab_size: int: vocab size of the input\n","        d_model: int:  depth of embedding (n_units in the LSTM cell)\n","        n_encoder_layers: int: number of LSTM layers in the encoder\n","    Returns:\n","        tl.Serial: The input encoder\n","    \"\"\"\n","    \n","    # create a serial network\n","    input_encoder = tl.Serial( \n","        \n","        # create an embedding layer to convert tokens to vectors\n","        tl.Embedding(input_vocab_size, d_model),\n","        \n","        # feed the embeddings to the LSTM layers. It is a stack of n_encoder_layers LSTM layers\n","        [tl.LSTM(d_model) for _ in range(n_encoder_layers)],\n","    )\n","\n","    return input_encoder"]},{"cell_type":"code","execution_count":16,"id":"xQTG26QZ2oOm","metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1675346911059,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"xQTG26QZ2oOm"},"outputs":[],"source":["def pre_attention_decoder_fn(mode, target_vocab_size, d_model):\n","    \"\"\" Pre-attention decoder runs on the targets and creates\n","    activations that are used as queries in attention.\n","    \n","    Args:\n","        mode: str: 'train' or 'eval'\n","        target_vocab_size: int: vocab size of the target\n","        d_model: int:  depth of embedding (n_units in the LSTM cell)\n","    Returns:\n","        tl.Serial: The pre-attention decoder\n","    \"\"\"\n","    \n","    # create a serial network\n","    pre_attention_decoder = tl.Serial(\n","        \n","        tl.ShiftRight(mode=mode),\n","\n","        # run an embedding layer to convert tokens to vectors\n","        tl.Embedding(target_vocab_size, d_model),\n","\n","        # feed to an LSTM layer\n","        tl.LSTM(d_model)\n","\n","    )\n","    \n","    return pre_attention_decoder"]},{"cell_type":"code","execution_count":18,"id":"y-TerfOD2oOn","metadata":{"executionInfo":{"elapsed":28,"status":"ok","timestamp":1675346911060,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"y-TerfOD2oOn"},"outputs":[],"source":["def prepare_attention_input(encoder_activations, decoder_activations, inputs):\n","    \"\"\"Prepare queries, keys, values and mask for attention.\n","    \n","    Args:\n","        encoder_activations fastnp.array(batch_size, padded_input_length, d_model): output from the input encoder\n","        decoder_activations fastnp.array(batch_size, padded_input_length, d_model): output from the pre-attention decoder\n","        inputs fastnp.array(batch_size, padded_input_length): input tokens\n","    \n","    Returns:\n","        queries, keys, values and mask for attention.\n","    \"\"\"\n","    \n","    # set the keys and values to the encoder activations\n","    keys = encoder_activations\n","    values = encoder_activations\n","\n","    \n","    # set the queries to the decoder activations\n","    queries = decoder_activations\n","    \n","    # generate the mask to distinguish real tokens from padding\n","    # hint: inputs is 1 for real tokens and 0 where they are padding\n","    mask = (inputs != 0)\n","    \n","    # add axes to the mask for attention heads and decoder length.\n","    mask = fastnp.reshape(mask, (mask.shape[0], 1, 1, mask.shape[1]))\n","    \n","    # broadcast so mask shape is [batch size, attention heads, decoder-len, encoder-len].\n","    # note: for this assignment, attention heads is set to 1.\n","    mask = mask + fastnp.zeros((1, 1, decoder_activations.shape[1], 1))\n","        \n","    \n","    return queries, keys, values, mask"]},{"cell_type":"code","execution_count":20,"id":"j-lzRg_A2oOo","metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1675346911061,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"j-lzRg_A2oOo"},"outputs":[],"source":["def NMTAttn(input_vocab_size=33300,\n","            target_vocab_size=33300,\n","            d_model=1024,\n","            n_encoder_layers=2,\n","            n_decoder_layers=2,\n","            n_attention_heads=4,\n","            attention_dropout=0.0,\n","            mode='train'):\n","    \"\"\"Returns an LSTM sequence-to-sequence model with attention.\n","\n","    The input to the model is a pair (input tokens, target tokens), e.g.,\n","    an English sentence (tokenized) and its translation into German (tokenized).\n","\n","    Args:\n","    input_vocab_size: int: vocab size of the input\n","    target_vocab_size: int: vocab size of the target\n","    d_model: int:  depth of embedding (n_units in the LSTM cell)\n","    n_encoder_layers: int: number of LSTM layers in the encoder\n","    n_decoder_layers: int: number of LSTM layers in the decoder after attention\n","    n_attention_heads: int: number of attention heads\n","    attention_dropout: float, dropout for the attention layer\n","    mode: str: 'train', 'eval' or 'predict', predict mode is for fast inference\n","\n","    Returns:\n","    An LSTM sequence-to-sequence model with attention.\n","    \"\"\"\n","\n","    # Step 0: call the helper function to create layers for the input encoder\n","    input_encoder = input_encoder_fn(input_vocab_size, d_model, n_encoder_layers)\n","\n","    # Step 0: call the helper function to create layers for the pre-attention decoder\n","    pre_attention_decoder = pre_attention_decoder_fn(mode, target_vocab_size, d_model)\n","\n","    # Step 1: create a serial network\n","    model = tl.Serial( \n","        \n","      # Step 2: copy input tokens and target tokens as they will be needed later.\n","      tl.Select([0, 1, 0, 1]),\n","        \n","      # Step 3: run input encoder on the input and pre-attention decoder the target.\n","      tl.Parallel(input_encoder, pre_attention_decoder),\n","        \n","      # Step 4: prepare queries, keys, values and mask for attention.\n","      tl.Fn('PrepareAttentionInput', prepare_attention_input, n_out=4),\n","        \n","      # Step 5: run the AttentionQKV layer\n","      # nest it inside a Residual layer to add to the pre-attention decoder activations(i.e. queries)\n","      tl.Residual(tl.AttentionQKV(d_model, n_heads=n_attention_heads, dropout=attention_dropout, mode=mode)),\n","      \n","      # Step 6: drop attention mask (i.e. index = None\n","      tl.Select([0, 2]),\n","        \n","      # Step 7: run the rest of the RNN decoder\n","      [tl.LSTM(d_model) for _ in range(n_decoder_layers)],\n","        \n","      # Step 8: prepare output by making it the right size\n","      tl.Dense(target_vocab_size),\n","        \n","      # Step 9: Log-softmax for output\n","      tl.LogSoftmax()\n","    )\n","    \n","    return model"]},{"cell_type":"code","execution_count":null,"id":"kR4bozEv2oOp","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28,"status":"ok","timestamp":1675346911062,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"kR4bozEv2oOp","outputId":"45e5ba59-1719-4f4c-e3c5-1da80b937884"},"outputs":[],"source":["# print your model\n","model = NMTAttn()\n","print(model)"]},{"cell_type":"code","execution_count":23,"id":"SOmgqjEx2oOq","metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1675346911063,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"SOmgqjEx2oOq"},"outputs":[],"source":["def train_task_function(train_batch_stream):\n","    \"\"\"Returns a trax.training.TrainTask object.\n","\n","    Args:\n","    train_batch_stream generator: labeled data generator\n","\n","    Returns:\n","    A trax.training.TrainTask object.\n","    \"\"\"\n","    return training.TrainTask(\n","\n","        # use the train batch stream as labeled data\n","    labeled_data= train_batch_stream,\n","    \n","    # use the cross entropy loss\n","    loss_layer= tl.CrossEntropyLoss(),\n","    \n","    # use the Adam optimizer with learning rate of 0.01\n","    optimizer= trax.optimizers.Adam(.01),\n","    \n","    # use the `trax.lr.warmup_and_rsqrt_decay` as the learning rate schedule\n","    # have 1000 warmup steps with a max value of 0.01\n","    lr_schedule= trax.lr.warmup_and_rsqrt_decay(1000, .01),\n","    \n","    # have a checkpoint every 10 steps\n","    n_steps_per_checkpoint= 10,\n","    \n","    )"]},{"cell_type":"code","execution_count":24,"id":"6DgsUDSa2oOr","metadata":{"executionInfo":{"elapsed":482,"status":"ok","timestamp":1675346911522,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"6DgsUDSa2oOr"},"outputs":[],"source":["train_task = train_task_function(train_batch_stream)"]},{"cell_type":"code","execution_count":26,"id":"Hr5mvbkZ2oOs","metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1675346911523,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Hr5mvbkZ2oOs"},"outputs":[],"source":["eval_task = training.EvalTask(\n","    \n","    ## use the eval batch stream as labeled data\n","    labeled_data=eval_batch_stream,\n","    \n","    ## use the cross entropy loss and accuracy as metrics\n","    metrics=[tl.CrossEntropyLoss(), tl.Accuracy()],\n",")"]},{"cell_type":"code","execution_count":27,"id":"inZhPVSI2oOs","metadata":{"executionInfo":{"elapsed":5838,"status":"ok","timestamp":1675346917355,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"inZhPVSI2oOs","lines_to_next_cell":2},"outputs":[],"source":["## this may fail in case you run the notebook second or more times with:\n","## TypeError: unsupported operand type(s) for ==: 'DeviceArray' and 'tuple'\n","## so, you need to go to manage sessions, delete last session and only after that run the code\n","\n","# define the output directory\n","output_dir = 'output_dir/'\n","\n","# remove old model if it exists. restarts training.\n","!rm -f ~/output_dir/model.pkl.gz  \n","\n","# define the training loop\n","training_loop = training.Loop(NMTAttn(mode='train'),\n","                              train_task,\n","                              eval_tasks=[eval_task],\n","                              output_dir=output_dir)"]},{"cell_type":"code","execution_count":null,"id":"6Gz4d-BK2oOt","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":500265,"status":"ok","timestamp":1675347417604,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"6Gz4d-BK2oOt","outputId":"0321cbaa-de1a-42e7-e407-0cddeb9889c2"},"outputs":[],"source":["# NOTE: Execute the training loop. This will take around 11 minutes to complete.\n","training_loop.run(10)"]},{"cell_type":"code","execution_count":29,"id":"usz5X64m2oOt","metadata":{"executionInfo":{"elapsed":4954,"status":"ok","timestamp":1675347422542,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"usz5X64m2oOt"},"outputs":[],"source":["# instantiate the model we built in eval mode\n","model = NMTAttn(mode='eval')\n","\n","# initialize weights from a pre-trained model\n","model.init_from_file(\"./output_dir/model.pkl.gz\", weights_only=True)\n","model = tl.Accelerate(model)"]},{"cell_type":"code","execution_count":30,"id":"OShcJX9ZZFWr","metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1675347422543,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"OShcJX9ZZFWr"},"outputs":[],"source":["## this is same as trax.layers.logsoftmax_sample()\n","\n","def logsoftmax_sample(log_probs, temperature=1.0):  # pylint: disable=invalid-name\n","  \"\"\"Returns a sample from a log-softmax output, with temperature.\n","\n","  Args:\n","    log_probs: Logarithms of probabilities (often coming from LogSofmax)\n","    temperature: For scaling before sampling (1.0 = default, 0.0 = pick argmax)\n","  \"\"\"\n","  # This is equivalent to sampling from a softmax with temperature.\n","  u = np.random.uniform(low=1e-6, high=1.0 - 1e-6, size=log_probs.shape)\n","  g = -np.log(-np.log(u))\n","  return np.argmax(log_probs + g * temperature, axis=-1)"]},{"cell_type":"code","execution_count":31,"id":"5wg6tawr2oOu","metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1675347422543,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"5wg6tawr2oOu"},"outputs":[],"source":["def next_symbol(NMTAttn, input_tokens, cur_output_tokens, temperature):\n","    \"\"\"Returns the index of the next token.\n","\n","    Args:\n","        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n","        input_tokens (np.ndarray 1 x n_tokens): tokenized representation of the input sentence\n","        cur_output_tokens (list): tokenized representation of previously translated words\n","        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n","            0.0: same as argmax, always pick the most probable token\n","            1.0: sampling from the distribution (can sometimes say random things)\n","\n","    Returns:\n","        int: index of the next token in the translated sentence\n","        float: log probability of the next symbol\n","    \"\"\"\n","\n","    # set the length of the current output tokens\n","    token_length = len(cur_output_tokens)\n","\n","    # calculate next power of 2 for padding length \n","    padded_length = 2**int(np.ceil(np.log2(token_length + 1))) \n","\n","    # pad cur_output_tokens up to the padded_length\n","    padded = cur_output_tokens + [0] * (padded_length - token_length)\n","    \n","    # model expects the output to have an axis for the batch size in front so\n","    # convert `padded` list to a numpy array with shape (None, <padded_length>) where\n","    # None is a placeholder for the batch size\n","    padded_with_batch = np.expand_dims(padded, axis=0)\n","    \n","    # get the model prediction (remember to use the `NMAttn` argument defined above)\n","    output, _ = NMTAttn((input_tokens, padded_with_batch))\n","\n","    # get log probabilities from the last token output\n","    log_probs = output[0, token_length, :]\n","    \n","    # get the next symbol by getting a logsoftmax sample (*hint: cast to an int)\n","    symbol = int(tl.logsoftmax_sample(log_probs, temperature))\n","       \n","    return symbol, float(log_probs[symbol])"]},{"cell_type":"code","execution_count":33,"id":"2540McuR2oOv","metadata":{"executionInfo":{"elapsed":22,"status":"ok","timestamp":1675347422544,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"2540McuR2oOv"},"outputs":[],"source":["def sampling_decode(input_sentence, NMTAttn = None, temperature=0.0, vocab_file=None, vocab_dir=None, \n","                    next_symbol=next_symbol, tokenize=tokenize, detokenize=detokenize, max_length=None):\n","    \"\"\"Returns the translated sentence.\n","\n","    Args:\n","        input_sentence (str): sentence to translate.\n","        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n","        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n","            0.0: same as argmax, always pick the most probable token\n","            1.0: sampling from the distribution (can sometimes say random things)\n","        vocab_file (str): filename of the vocabulary\n","        vocab_dir (str): path to the vocabulary file\n","\n","    Returns:\n","        tuple: (list, str, float)\n","            list of int: tokenized version of the translated sentence\n","            float: log probability of the translated sentence\n","            str: the translated sentence\n","    \"\"\"\n","    \n","    # encode the input sentence\n","    input_tokens = tokenize(input_sentence,vocab_file,vocab_dir)\n","    \n","    # initialize the list of output tokens\n","    cur_output_tokens = []\n","    \n","    # initialize an integer that represents the current output index\n","    cur_output = 0\n","    \n","    # Set the encoding of the \"end of sentence\" as 1\n","    EOS = 1\n","    \n","    # check that the current output is not the end of sentence token\n","    while cur_output != EOS:\n","        \n","        # update the current output token by getting the index of the next word (hint: use next_symbol)\n","        cur_output, log_prob = next_symbol(NMTAttn, input_tokens, cur_output_tokens, temperature)\n","        \n","        # append the current output token to the list of output tokens\n","        cur_output_tokens.append(cur_output)\n","\n","        if max_length==len(cur_output_tokens): break\n","    \n","    # detokenize the output tokens\n","    sentence = detokenize(cur_output_tokens, vocab_file, vocab_dir)\n","    \n","    return tuple((cur_output_tokens, log_prob, sentence))"]},{"cell_type":"code","execution_count":null,"id":"NiYf_eNZ2oOv","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16870,"status":"ok","timestamp":1675347439392,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"NiYf_eNZ2oOv","outputId":"4d0c1ad7-73a7-4874-ddb2-4e74ce284eb0"},"outputs":[],"source":["# Test the function above. Try varying the temperature setting with values from 0 to 1.\n","# Run it several times with each setting and see how often the output changes. \n","sentence = \"I love languages.\"\n","\n","sampling_decode(sentence, NMTAttn=model, temperature=0.1, vocab_file=VOCAB_FILE, \n","                vocab_dir=VOCAB_DIR, max_length=2*len(sentence))"]},{"cell_type":"code","execution_count":36,"id":"RV-YqZb32oOw","metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1675347439394,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"RV-YqZb32oOw"},"outputs":[],"source":["def greedy_decode_test(sentence, NMTAttn=None, vocab_file=None, vocab_dir=None, \n","                       sampling_decode=sampling_decode, next_symbol=next_symbol, \n","                       tokenize=tokenize, detokenize=detokenize, max_length=None):\n","    \"\"\"Prints the input and output of our NMTAttn model using greedy decode\n","\n","    Args:\n","        sentence (str): a custom string.\n","        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n","        vocab_file (str): filename of the vocabulary\n","        vocab_dir (str): path to the vocabulary file\n","\n","    Returns:\n","        str: the translated sentence\n","    \"\"\"\n","    \n","    _,_, translated_sentence = sampling_decode(sentence, NMTAttn=NMTAttn, temperature=0.0, vocab_file=vocab_file, \n","                                               vocab_dir=vocab_dir, next_symbol=next_symbol, tokenize=tokenize, \n","                                               detokenize=detokenize, max_length=max_length)\n","    \n","    print(\"English: \", sentence)\n","    print(\"German: \", translated_sentence)\n","    \n","    return translated_sentence"]},{"cell_type":"code","execution_count":null,"id":"k8pm4IwE2oOw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4322,"status":"ok","timestamp":1675347443693,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"k8pm4IwE2oOw","outputId":"ec210556-2e48-4378-9a76-854196b43f09"},"outputs":[],"source":["# put a custom string here\n","sentence = 'I am hungry'\n","\n","greedy_decode_test(sentence, NMTAttn=model, vocab_file=VOCAB_FILE, \n","                   vocab_dir=VOCAB_DIR, max_length=2*len(sentence));"]},{"cell_type":"code","execution_count":39,"id":"b8hl3Y_d2oOx","metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1675347443695,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"b8hl3Y_d2oOx"},"outputs":[],"source":["def generate_samples(sentence, n_samples, NMTAttn=None, temperature=0.6, vocab_file=None, vocab_dir=None, \n","                     sampling_decode=sampling_decode, next_symbol=next_symbol, \n","                     tokenize=tokenize, detokenize=detokenize, max_length=None):\n","    \"\"\"Generates samples using sampling_decode()\n","\n","    Args:\n","        sentence (str): sentence to translate.\n","        n_samples (int): number of samples to generate\n","        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n","        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n","            0.0: same as argmax, always pick the most probable token\n","            1.0: sampling from the distribution (can sometimes say random things)\n","        vocab_file (str): filename of the vocabulary\n","        vocab_dir (str): path to the vocabulary file\n","        \n","    Returns:\n","        tuple: (list, list)\n","            list of lists: token list per sample\n","            list of floats: log probability per sample\n","    \"\"\"\n","    # define lists to contain samples and probabilities\n","    samples, log_probs = [], []\n","\n","    # run a for loop to generate n samples\n","    for _ in range(n_samples):\n","        \n","        # get a sample using the sampling_decode() function\n","        sample, logp, _ = sampling_decode(sentence, NMTAttn, temperature, vocab_file=vocab_file, vocab_dir=vocab_dir, \n","                                          next_symbol=next_symbol, max_length=max_length)\n","        \n","        # append the token list to the samples list\n","        samples.append(sample)\n","        \n","        # append the log probability to the log_probs list\n","        log_probs.append(logp)\n","                \n","    return tuple((samples, log_probs))"]},{"cell_type":"code","execution_count":null,"id":"nUmY2f7b2oOy","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":22065,"status":"ok","timestamp":1675347465741,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"nUmY2f7b2oOy","outputId":"ab634293-c27a-402d-e411-246f490dd1e5"},"outputs":[],"source":["# generate 4 samples with the default temperature (0.6)\n","sentence = 'how are you today?'\n","generate_samples(sentence, 3, model, vocab_file=VOCAB_FILE, \n","                 vocab_dir=VOCAB_DIR, max_length=2*len(sentence))"]},{"cell_type":"code","execution_count":41,"id":"p4n-pNeM2oOy","metadata":{"executionInfo":{"elapsed":49,"status":"ok","timestamp":1675347465742,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"p4n-pNeM2oOy"},"outputs":[],"source":["def jaccard_similarity(candidate, reference):\n","    \"\"\"Returns the Jaccard similarity between two token lists\n","\n","    Args:\n","        candidate (list of int): tokenized version of the candidate translation\n","        reference (list of int): tokenized version of the reference translation\n","\n","    Returns:\n","        float: overlap between the two token lists\n","    \"\"\"\n","    \n","    # convert the lists to a set to get the unique tokens\n","    can_unigram_set, ref_unigram_set = set(candidate), set(reference)  \n","    \n","    # get the set of tokens common to both candidate and reference\n","    joint_elems = can_unigram_set.intersection(ref_unigram_set)\n","    \n","    # get the set of all tokens found in either candidate or reference\n","    all_elems = can_unigram_set.union(ref_unigram_set)\n","    \n","    # divide the number of joint elements by the number of all elements\n","    overlap = len(joint_elems) / len(all_elems)\n","    \n","    return overlap"]},{"cell_type":"code","execution_count":null,"id":"mX4lERLU2oOz","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":49,"status":"ok","timestamp":1675347465743,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"mX4lERLU2oOz","outputId":"55493281-b2ab-40f5-a373-8f56f80097f1"},"outputs":[],"source":["# let's try using the function. remember the result here and compare with the next function below.\n","jaccard_similarity([1, 2, 3], [1, 2, 3, 4])"]},{"cell_type":"code","execution_count":43,"id":"Aes54JTn2oOz","metadata":{"executionInfo":{"elapsed":46,"status":"ok","timestamp":1675347465743,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Aes54JTn2oOz"},"outputs":[],"source":["# for making a frequency table easily\n","from collections import Counter\n","\n","def rouge1_similarity(system, reference):\n","    \"\"\"Returns the ROUGE-1 score between two token lists\n","\n","    Args:\n","        system (list of int): tokenized version of the system translation\n","        reference (list of int): tokenized version of the reference translation\n","\n","    Returns:\n","        float: overlap between the two token lists\n","    \"\"\"    \n","    \n","    # make a frequency table of the system tokens (hint: use the Counter class)\n","    sys_counter = Counter(system)\n","\n","    # make a frequency table of the reference tokens (hint: use the Counter class)\n","    ref_counter = Counter(reference)\n","    \n","    # initialize overlap to 0\n","    overlap = 0\n","    \n","    # run a for loop over the sys_counter object (can be treated as a dictionary)\n","    for token in sys_counter:\n","        \n","        # lookup the value of the token in the sys_counter dictionary (hint: use the get() method)\n","        token_count_sys = sys_counter.get(token,0)\n","        \n","        # lookup the value of the token in the ref_counter dictionary (hint: use the get() method)\n","        token_count_ref = ref_counter.get(token,0)\n","        \n","        # update the overlap by getting the smaller number between the two token counts above\n","        overlap += min(token_count_sys, token_count_ref)\n","    \n","    # get the precision (i.e. number of overlapping tokens / number of system tokens)\n","    \n","    \n","    precision = overlap / sum(sys_counter.values())\n","    \n","    # get the recall (i.e. number of overlapping tokens / number of reference tokens)\n","    recall = overlap / sum(ref_counter.values())\n","    \n","    if precision + recall != 0:\n","        # compute the f1-score\n","        rouge1_score = 2 * ((precision * recall)/(precision + recall))\n","    else:\n","        rouge1_score = 0 \n","    \n","    return rouge1_score"]},{"cell_type":"code","execution_count":null,"id":"mLyctETt2oO0","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":46,"status":"ok","timestamp":1675347465744,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"mLyctETt2oO0","outputId":"10922663-8f0d-4d02-f183-b0733639fdc1"},"outputs":[],"source":["# notice that this produces a different value from the jaccard similarity earlier\n","rouge1_similarity([1, 2, 3], [1, 2, 3, 4])"]},{"cell_type":"code","execution_count":46,"id":"gUiJzwfV2oO0","metadata":{"executionInfo":{"elapsed":42,"status":"ok","timestamp":1675347465745,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"gUiJzwfV2oO0"},"outputs":[],"source":["def average_overlap(similarity_fn, samples, *ignore_params):\n","    \"\"\"Returns the arithmetic mean of each candidate sentence in the samples\n","\n","    Args:\n","        similarity_fn (function): similarity function used to compute the overlap\n","        samples (list of lists): tokenized version of the translated sentences\n","        *ignore_params: additional parameters will be ignored\n","\n","    Returns:\n","        dict: scores of each sample\n","            key: index of the sample\n","            value: score of the sample\n","    \"\"\"  \n","    \n","    # initialize dictionary\n","    scores = {}\n","    \n","    # run a for loop for each sample\n","    for index_candidate, candidate in enumerate(samples):    \n","        \n","        # initialize overlap to 0.0\n","        overlap = 0.0\n","        \n","        # run a for loop for each sample\n","        for index_sample, sample in enumerate(samples): \n","\n","            # skip if the candidate index is the same as the sample index\n","            if index_candidate == index_sample:\n","                continue\n","                \n","            # get the overlap between candidate and sample using the similarity function\n","            sample_overlap = similarity_fn(candidate,sample)\n","\n","            # add the sample overlap to the total overlap\n","            overlap += sample_overlap\n","\n","        # get the score for the candidate by computing the average\n","        score = overlap/index_sample\n","        \n","        # save the score in the dictionary. use index as the key.\n","        scores[index_candidate] = score\n","        \n","    return scores"]},{"cell_type":"code","execution_count":null,"id":"jawX1QUn2oO1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1675347465746,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"jawX1QUn2oO1","outputId":"f8aba1fc-92a7-4717-8901-9dfeb6dcf4c4"},"outputs":[],"source":["average_overlap(jaccard_similarity, [[1, 2, 3], [1, 2, 4], [1, 2, 4, 5]], [0.4, 0.2, 0.5])"]},{"cell_type":"code","execution_count":49,"id":"m0KBdx862oO2","metadata":{"executionInfo":{"elapsed":39,"status":"ok","timestamp":1675347465747,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"m0KBdx862oO2"},"outputs":[],"source":["def weighted_avg_overlap(similarity_fn, samples, log_probs):\n","    \"\"\"Returns the weighted mean of each candidate sentence in the samples\n","\n","    Args:\n","        samples (list of lists): tokenized version of the translated sentences\n","        log_probs (list of float): log probability of the translated sentences\n","\n","    Returns:\n","        dict: scores of each sample\n","            key: index of the sample\n","            value: score of the sample\n","    \"\"\"\n","    \n","    # initialize dictionary\n","    scores = {}\n","    \n","    # run a for loop for each sample\n","    for index_candidate, candidate in enumerate(samples):    \n","        \n","        # initialize overlap and weighted sum\n","        overlap, weight_sum = 0.0, 0.0\n","        \n","        # run a for loop for each sample\n","        for index_sample, (sample, logp) in enumerate(zip(samples, log_probs)):\n","\n","            # skip if the candidate index is the same as the sample index            \n","            if index_candidate == index_sample:\n","                continue\n","                \n","            # convert log probability to linear scale\n","            sample_p = float(np.exp(logp))\n","\n","            # update the weighted sum\n","            weight_sum += sample_p\n","\n","            # get the unigram overlap between candidate and sample\n","            sample_overlap = similarity_fn(candidate, sample)\n","            \n","            # update the overlap\n","            overlap += sample_p * sample_overlap\n","            \n","        # get the score for the candidate\n","        score = overlap / weight_sum\n","        \n","        # save the score in the dictionary. use index as the key.\n","        scores[index_candidate] = score\n","    \n","    return scores"]},{"cell_type":"code","execution_count":null,"id":"AJ0-lbp02oO2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":40,"status":"ok","timestamp":1675347465748,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"AJ0-lbp02oO2","outputId":"da1b2a53-12cb-4c4d-a5ba-fb58155690c9"},"outputs":[],"source":["weighted_avg_overlap(jaccard_similarity, [[1, 2, 3], [1, 2, 4], [1, 2, 4, 5]], [0.4, 0.2, 0.5])"]},{"cell_type":"code","execution_count":51,"id":"XsTF3FlJ2oO3","metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1675347465748,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"XsTF3FlJ2oO3"},"outputs":[],"source":["def mbr_decode(sentence, n_samples, score_fn, similarity_fn, NMTAttn=None, temperature=0.6, vocab_file=None, vocab_dir=None, \n","               generate_samples=generate_samples, sampling_decode=sampling_decode, \n","               next_symbol=next_symbol, tokenize=tokenize, detokenize=detokenize, max_length=None):\n","    \"\"\"Returns the translated sentence using Minimum Bayes Risk decoding\n","\n","    Args:\n","        sentence (str): sentence to translate.\n","        n_samples (int): number of samples to generate\n","        score_fn (function): function that generates the score for each sample\n","        similarity_fn (function): function used to compute the overlap between a pair of samples\n","        NMTAttn (tl.Serial): An LSTM sequence-to-sequence model with attention.\n","        temperature (float): parameter for sampling ranging from 0.0 to 1.0.\n","            0.0: same as argmax, always pick the most probable token\n","            1.0: sampling from the distribution (can sometimes say random things)\n","        vocab_file (str): filename of the vocabulary\n","        vocab_dir (str): path to the vocabulary file\n","\n","    Returns:\n","        str: the translated sentence\n","    \"\"\"\n","    \n","    # generate samples\n","    samples, log_probs = generate_samples(sentence, n_samples, NMTAttn, \n","                                          temperature, vocab_file, vocab_dir, max_length=max_length)\n","    \n","    # use the scoring function to get a dictionary of scores\n","    # pass in the relevant parameters as shown in the function definition of \n","    # the mean methods you developed earlier\n","    scores = score_fn(similarity_fn, samples, log_probs )\n","\n","    # find the key with the highest score\n","    max_score_key = max(scores, key=scores.get)\n","    \n","    # detokenize the token list associated with the max_index\n","    translated_sentence = detokenize(samples[max_score_key], vocab_file, vocab_dir)\n","    \n","    return translated_sentence"]},{"cell_type":"code","execution_count":null,"id":"C4rw4oZP2oO3","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":24325,"status":"ok","timestamp":1675347490038,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"C4rw4oZP2oO3","outputId":"5c90ea1c-d567-4f04-b0f2-ab8edad0d99c"},"outputs":[],"source":["TEMPERATURE = 1.0\n","\n","# put a custom string here\n","your_sentence = 'She speaks English and German.'\n","\n","mbr_decode(your_sentence, 2, weighted_avg_overlap, jaccard_similarity, model, \n","           TEMPERATURE, vocab_file=VOCAB_FILE, vocab_dir=VOCAB_DIR, max_length=2*len(your_sentence))[0]"]}],"metadata":{"colab":{"provenance":[]},"gpuClass":"standard","jupytext":{"encoding":"# -*- coding: utf-8 -*-"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"widgets":{"application/vnd.jupyter.widget-state+json":{"06c19ea2344d419a92965923341f95e4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"0b4d481c55224b2d8de0c103a3b207e2":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_50a042229c1a4e6894da874e9723336e","placeholder":"​","style":"IPY_MODEL_eba1e272087f41f6bccbc7ccf6d1794f","value":"Extraction completed...: 100%"}},"0f89a9655cac4c68b5aa4b0bbeeae096":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"15c8fc7218e04fbdbcfaebf7a5baf77e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"175fd930e9e5476eb453e9d68e9dbda9":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1c3aa95a742b496da7403182b197395e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2bb35b602f53485aa85321a28023285c","placeholder":"​","style":"IPY_MODEL_ef707a497db3499bbcd02dc13938de67","value":" 1108310/1108752 [01:24&lt;00:00, 13665.66 examples/s]"}},"1d280b41d5b04deab6e22fed3e08aa81":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f424062372947218416e350d45031c4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d87521b7340e47368b27528ba5ed1278","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_919f8d1f22ff42e8b06b2ca413c0e6f9","value":1}},"207a0ad27c72407d94deea3ad49e9301":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"23a7f3a9f2ac4c5fbd63d2dcdffb2a65":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2624091f285a4bb28333a665007ee66f":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"28a68b9847044a7aaa585fe7a43f58f7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2bb35b602f53485aa85321a28023285c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2bfba65e95144566870238e5e340e88d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c2439e4877d4e91adf023703b737625","placeholder":"​","style":"IPY_MODEL_67aa070a4e0747ee97197e0ee1d2faf4","value":"Generating splits...: 100%"}},"3b5eccb1c72d4b959fe88017dd0f6022":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"46ae37dd9ee74005a0c31baca332e12c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0b4d481c55224b2d8de0c103a3b207e2","IPY_MODEL_72c543cf65f344b8b76b6ad8687e9020","IPY_MODEL_6e31fd1316d94c16b7517ced9a1a7e59"],"layout":"IPY_MODEL_62b7773f79e4470dbe423a0736909d51"}},"476d33d5c86443b79fb1b08bdfea6038":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2bfba65e95144566870238e5e340e88d","IPY_MODEL_c3946cb34e494f288139ee0003897f22","IPY_MODEL_df71aa4f321f4d0e96edd7f2be522bb7"],"layout":"IPY_MODEL_06c19ea2344d419a92965923341f95e4"}},"50a042229c1a4e6894da874e9723336e":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"50ee702cc0b84099b457af5e4a6b6829":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f57cbfc78b4742c9861346d066df8100","IPY_MODEL_dbf82f8ebaee44a89e992948c0219f3a","IPY_MODEL_74f3007de49a4f6d9238a406529bc634"],"layout":"IPY_MODEL_9b6a2ebe2feb45acb696f01489323865"}},"531b690e13ca428fbb2cd7aad6fe410f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_f08d6e7a9f9546e49d94371e316a3c6b","IPY_MODEL_1f424062372947218416e350d45031c4","IPY_MODEL_8cc86550644442c4a21a072462075827"],"layout":"IPY_MODEL_0f89a9655cac4c68b5aa4b0bbeeae096"}},"595ab62007784a00bf42e0e4ad18ccde":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d314756539ee486d8e5efa35167b93bb","placeholder":"​","style":"IPY_MODEL_b6d37afec0584b87b45335d1bcdcbac3","value":" 34/34 [00:12&lt;00:00, 10.38 MiB/s]"}},"5c2439e4877d4e91adf023703b737625":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5c5bc4df0f0444619086f0bce88512b1":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"62b7773f79e4470dbe423a0736909d51":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"67aa070a4e0747ee97197e0ee1d2faf4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6e31fd1316d94c16b7517ced9a1a7e59":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_ab74ddb5c1c7492eb4bb11bb990a9319","placeholder":"​","style":"IPY_MODEL_3b5eccb1c72d4b959fe88017dd0f6022","value":" 3/3 [00:12&lt;00:00, 12.21s/ file]"}},"72c543cf65f344b8b76b6ad8687e9020":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f127c435c2f8478a971e9e131aea0556","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_87b464cc95a44ed7a899e6874dd7dae8","value":1}},"74f3007de49a4f6d9238a406529bc634":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_e6f14b13cf374b038bba53bde3d08df4","placeholder":"​","style":"IPY_MODEL_76d2fb8412c3430eacf29e7128bd233e","value":" 1085321/1108752 [00:03&lt;00:00, 460989.62 examples/s]"}},"76d2fb8412c3430eacf29e7128bd233e":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"789feb0e8de143e09af7e95f8a496f96":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfd5fda75fee46968cfe561ec0dd9cee","placeholder":"​","style":"IPY_MODEL_9d0eb0a264c04503972cac022c62c3d1","value":"Dl Size...: 100%"}},"7ded022381cd489e8a281a5f8eb51d2c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_789feb0e8de143e09af7e95f8a496f96","IPY_MODEL_e6bfeb5a8796468498e520c05d481999","IPY_MODEL_595ab62007784a00bf42e0e4ad18ccde"],"layout":"IPY_MODEL_15c8fc7218e04fbdbcfaebf7a5baf77e"}},"87b464cc95a44ed7a899e6874dd7dae8":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"88ed082be82f41258d951d1168082344":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8c089080046545acba67166ea5d52871":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8cc86550644442c4a21a072462075827":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_be3e7ec1cbd4404fbda87f0eab24e848","placeholder":"​","style":"IPY_MODEL_207a0ad27c72407d94deea3ad49e9301","value":" 1/1 [00:12&lt;00:00,  9.52s/ url]"}},"919f8d1f22ff42e8b06b2ca413c0e6f9":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9afd2252d62b40f0a9b108a9e99cd8ef":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9b6a2ebe2feb45acb696f01489323865":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":"hidden","width":null}},"9d0eb0a264c04503972cac022c62c3d1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a513ee198700421d8656ca276f09cb5d":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a66b52e4a4cf4483adb82d98518aeaf6":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"ab74ddb5c1c7492eb4bb11bb990a9319":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b6d37afec0584b87b45335d1bcdcbac3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b8b2448ad54b4c959ca16163cea33b20":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"be3e7ec1cbd4404fbda87f0eab24e848":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c00c2ad6aa3a4eecb7b787ec5395ab22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8c089080046545acba67166ea5d52871","placeholder":"​","style":"IPY_MODEL_cbaba7bc954e47b3a1192c7a5ca10ea6","value":"Generating train examples...: 100%"}},"c3946cb34e494f288139ee0003897f22":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_c5f3730fdf7e4c3d9bff7cf10c86977c","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1d280b41d5b04deab6e22fed3e08aa81","value":1}},"c5f3730fdf7e4c3d9bff7cf10c86977c":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8f5e39b57f942e791bd90ed4f3cd69a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"cbaba7bc954e47b3a1192c7a5ca10ea6":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ce540a045ebd430f94afce78a4d8f5a4":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_175fd930e9e5476eb453e9d68e9dbda9","max":1108752,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b8b2448ad54b4c959ca16163cea33b20","value":1108752}},"cfd5fda75fee46968cfe561ec0dd9cee":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d314756539ee486d8e5efa35167b93bb":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d87521b7340e47368b27528ba5ed1278":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"dbf82f8ebaee44a89e992948c0219f3a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_fa462f5fbdac475d8796ffc525263069","max":1108752,"min":0,"orientation":"horizontal","style":"IPY_MODEL_23a7f3a9f2ac4c5fbd63d2dcdffb2a65","value":1108752}},"df71aa4f321f4d0e96edd7f2be522bb7":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5c5bc4df0f0444619086f0bce88512b1","placeholder":"​","style":"IPY_MODEL_28a68b9847044a7aaa585fe7a43f58f7","value":" 1/1 [01:28&lt;00:00, 88.49s/ splits]"}},"e34dc9110b46468e9c71a8d669177fed":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_c00c2ad6aa3a4eecb7b787ec5395ab22","IPY_MODEL_ce540a045ebd430f94afce78a4d8f5a4","IPY_MODEL_1c3aa95a742b496da7403182b197395e"],"layout":"IPY_MODEL_2624091f285a4bb28333a665007ee66f"}},"e6bfeb5a8796468498e520c05d481999":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_a66b52e4a4cf4483adb82d98518aeaf6","max":1,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c8f5e39b57f942e791bd90ed4f3cd69a","value":1}},"e6f14b13cf374b038bba53bde3d08df4":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eba1e272087f41f6bccbc7ccf6d1794f":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef707a497db3499bbcd02dc13938de67":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f08d6e7a9f9546e49d94371e316a3c6b":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9afd2252d62b40f0a9b108a9e99cd8ef","placeholder":"​","style":"IPY_MODEL_a513ee198700421d8656ca276f09cb5d","value":"Dl Completed...: 100%"}},"f127c435c2f8478a971e9e131aea0556":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":"20px"}},"f57cbfc78b4742c9861346d066df8100":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f87e98292b214bdfaa9b911579aa9a87","placeholder":"​","style":"IPY_MODEL_88ed082be82f41258d951d1168082344","value":"Shuffling data/opus/medical/0.1.0.incompleteCQXDEO/opus-train.tfrecord*...:  98%"}},"f87e98292b214bdfaa9b911579aa9a87":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fa462f5fbdac475d8796ffc525263069":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":5}
