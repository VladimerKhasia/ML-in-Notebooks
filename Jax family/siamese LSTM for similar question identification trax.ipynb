{"cells":[{"cell_type":"markdown","id":"1t9vmbcffFyi","metadata":{"id":"1t9vmbcffFyi"},"source":["Data:\n","\n","If you do not want to use Kaggle API here is quora dublicate questions full dataset for manual download: \n","\n","https://www.kaggle.com/datasets/quora/question-pairs-dataset"]},{"cell_type":"code","execution_count":null,"id":"yCAFZwIbR3he","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":56602,"status":"ok","timestamp":1675282765041,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"yCAFZwIbR3he","outputId":"77134164-8231-4c15-a223-06f53b62d31a"},"outputs":[],"source":["!pip install -q -U trax"]},{"cell_type":"code","execution_count":null,"id":"zdACgs491cs2","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":65132,"status":"ok","timestamp":1675282830145,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"zdACgs491cs2","outputId":"06d57ece-da1e-44f0-a00e-59ccebff3795"},"outputs":[],"source":["import os\n","import random as rnd\n","import nltk\n","import trax\n","from trax import layers as tl\n","from trax.supervised import training\n","from trax.fastmath import numpy as fastnp\n","from trax import shapes\n","import numpy as np\n","import pandas as pd\n","\n","# set nltk path\n","nltk.data.path.append('./nltk_data')\n","nltk.download('punkt')\n","\n","# set random seeds\n","rnd.seed(34)"]},{"cell_type":"code","execution_count":null,"id":"hzSGBHVEn9Pw","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":103671,"status":"ok","timestamp":1675282933799,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"hzSGBHVEn9Pw","outputId":"ac1f1891-1ac6-4259-b772-ecd2a72c06f2"},"outputs":[],"source":["! pip install -q kaggle                                         # directdownload from kaggle but first upload Apikey in files\n","! mkdir ~/.kaggle                                               # https://www.analyticsvidhya.com/blog/2021/06/how-to-load-kaggle-datasets-directly-into-google-colab/ , https://www.kaggle.com/general/74235 \n","! cp kaggle.json ~/.kaggle/\n","! chmod 600 ~/.kaggle/kaggle.json\n","# ! kaggle competitions download <name-of-competition>\n","! kaggle datasets download -d quora/question-pairs-dataset\n","! unzip question-pairs-dataset.zip"]},{"cell_type":"code","execution_count":null,"id":"sXWBVGWnpity","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":224},"executionInfo":{"elapsed":1281,"status":"ok","timestamp":1675282935076,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"sXWBVGWnpity","outputId":"132bebfa-d92e-421d-9de3-bd7773d9386a"},"outputs":[],"source":["data = pd.read_csv(\"./questions.csv\")\n","N=len(data)\n","print('Number of question pairs: ', N)\n","data.head()"]},{"cell_type":"code","execution_count":null,"id":"z00A7vEMpit1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":31,"status":"ok","timestamp":1675282935077,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"z00A7vEMpit1","outputId":"7253598b-42cf-4815-da90-3bd8475ff431"},"outputs":[],"source":["N_train = 300000\n","N_test  = 10*1024\n","data_train = data[:N_train]\n","data_test  = data[N_train:N_train+N_test]\n","print(\"Train set:\", len(data_train), \"Test set:\", len(data_test))\n","del(data) # remove to free memory"]},{"cell_type":"code","execution_count":null,"id":"Xi_TwXxxpit4","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1675282935078,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Xi_TwXxxpit4","outputId":"a516e0a1-fa04-43cf-ce56-d09f1be6ff89"},"outputs":[],"source":["td_index = (data_train['is_duplicate'] == 1).to_numpy()\n","td_index = [i for i, x in enumerate(td_index) if x] \n","print('number of duplicate questions: ', len(td_index))\n","print('indexes of first ten duplicate questions:', td_index[:10])"]},{"cell_type":"code","execution_count":null,"id":"3I9oXSsKpit7","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1675282935079,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"3I9oXSsKpit7","outputId":"5982fb3c-80f0-4194-e7f0-c3fe0037cb8a"},"outputs":[],"source":["print(data_train['question1'][5])  #  Example of question duplicates (first one in data)\n","print(data_train['question2'][5])\n","print('is_duplicate: ', data_train['is_duplicate'][5])"]},{"cell_type":"code","execution_count":10,"id":"XHpZO58Dss_v","metadata":{"executionInfo":{"elapsed":361,"status":"ok","timestamp":1675282935428,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"XHpZO58Dss_v"},"outputs":[],"source":["Q1_train_words = np.array(data_train['question1'][td_index])\n","Q2_train_words = np.array(data_train['question2'][td_index])\n","\n","Q1_test_words = np.array(data_test['question1'])\n","Q2_test_words = np.array(data_test['question2'])\n","y_test  = np.array(data_test['is_duplicate'])"]},{"cell_type":"code","execution_count":null,"id":"joyrS1XEpLWn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8,"status":"ok","timestamp":1675282935429,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"joyrS1XEpLWn","outputId":"501a3202-dd72-4214-ff25-b860ced456c9"},"outputs":[],"source":["print('TRAINING QUESTIONS:\\n')\n","print('Question 1: ', Q1_train_words[0])\n","print('Question 2: ', Q2_train_words[0], '\\n')\n","print('Question 1: ', Q1_train_words[5])\n","print('Question 2: ', Q2_train_words[5], '\\n')\n","\n","print('TESTING QUESTIONS:\\n')\n","print('Question 1: ', Q1_test_words[0])\n","print('Question 2: ', Q2_test_words[0], '\\n')\n","print('is_duplicate =', y_test[0], '\\n')"]},{"cell_type":"code","execution_count":12,"id":"QbCoIgLQpiuF","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1675282935430,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"QbCoIgLQpiuF"},"outputs":[],"source":["#create arrays\n","Q1_train = np.empty_like(Q1_train_words)\n","Q2_train = np.empty_like(Q2_train_words)\n","\n","Q1_test = np.empty_like(Q1_test_words)\n","Q2_test = np.empty_like(Q2_test_words)"]},{"cell_type":"code","execution_count":null,"id":"m9ZmfpGWpiuI","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39088,"status":"ok","timestamp":1675282974513,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"m9ZmfpGWpiuI","outputId":"bc6dcd24-b12a-4823-df5f-7d61f8a8ec79"},"outputs":[],"source":["# Building the vocabulary with the train set         (this might take a minute)\n","from collections import defaultdict\n","\n","vocab = defaultdict(lambda: 0)\n","vocab['<PAD>'] = 1\n","\n","for idx in range(len(Q1_train_words)):\n","    Q1_train[idx] = nltk.word_tokenize(Q1_train_words[idx])\n","    Q2_train[idx] = nltk.word_tokenize(Q2_train_words[idx])\n","    q = Q1_train[idx] + Q2_train[idx]\n","    for word in q:\n","        if word not in vocab:\n","            vocab[word] = len(vocab) + 1\n","print('The length of the vocabulary is: ', len(vocab))"]},{"cell_type":"code","execution_count":null,"id":"TTMRF8eZpiuK","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":35,"status":"ok","timestamp":1675282974514,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"TTMRF8eZpiuK","outputId":"a7cfcc61-4b86-4d52-fd9c-4407b95425d7"},"outputs":[],"source":["print(vocab['<PAD>'])\n","print(vocab['Astrology'])\n","print(vocab['Astronomy'])  #not in vocabulary, returns 0"]},{"cell_type":"code","execution_count":15,"id":"5sDs36m81g6f","metadata":{"executionInfo":{"elapsed":2747,"status":"ok","timestamp":1675282977235,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"5sDs36m81g6f"},"outputs":[],"source":["for idx in range(len(Q1_test_words)): \n","    Q1_test[idx] = nltk.word_tokenize(Q1_test_words[idx])\n","    Q2_test[idx] = nltk.word_tokenize(Q2_test_words[idx])"]},{"cell_type":"code","execution_count":null,"id":"3QgGE9KlpiuP","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1675282977236,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"3QgGE9KlpiuP","outputId":"6b48692e-2ac7-4225-d46f-b00a99dadf47"},"outputs":[],"source":["print('Train set has reduced to: ', len(Q1_train) ) \n","print('Test set length: ', len(Q1_test) ) "]},{"cell_type":"code","execution_count":17,"id":"zOhNa-sapiuS","metadata":{"executionInfo":{"elapsed":472,"status":"ok","timestamp":1675282977696,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"zOhNa-sapiuS"},"outputs":[],"source":["# Converting questions to array of integers\n","for i in range(len(Q1_train)):\n","    Q1_train[i] = [vocab[word] for word in Q1_train[i]]\n","    Q2_train[i] = [vocab[word] for word in Q2_train[i]]\n","\n","        \n","for i in range(len(Q1_test)):\n","    Q1_test[i] = [vocab[word] for word in Q1_test[i]]\n","    Q2_test[i] = [vocab[word] for word in Q2_test[i]]"]},{"cell_type":"code","execution_count":null,"id":"Dpawm38dpiuU","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":26,"status":"ok","timestamp":1675282977697,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Dpawm38dpiuU","outputId":"1488b4ea-47a0-45f2-90b3-e91527a1e63a"},"outputs":[],"source":["print('first question in the train set:\\n')\n","print(Q1_train_words[0], '\\n') \n","print('encoded version:')\n","print(Q1_train[0],'\\n')\n","\n","print('first question in the test set:\\n')\n","print(Q1_test_words[0], '\\n')\n","print('encoded version:')\n","print(Q1_test[0]) "]},{"cell_type":"code","execution_count":null,"id":"BmhrWPtgpiuY","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19,"status":"ok","timestamp":1675282977698,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"BmhrWPtgpiuY","outputId":"63cc7a35-a190-48d2-b74b-4264c25c5434"},"outputs":[],"source":["# Splitting the data\n","cut_off = int(len(Q1_train)*.8)\n","train_Q1, train_Q2 = Q1_train[:cut_off], Q2_train[:cut_off]\n","val_Q1, val_Q2 = Q1_train[cut_off: ], Q2_train[cut_off:]\n","print('Number of duplicate questions: ', len(Q1_train))\n","print(\"The length of the training set is:  \", len(train_Q1))\n","print(\"The length of the validation set is: \", len(val_Q1))"]},{"cell_type":"code","execution_count":20,"id":"ibchgos48MtA","metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1675282978022,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"ibchgos48MtA"},"outputs":[],"source":["def data_generator(Q1, Q2, batch_size, pad=1, shuffle=True):\n","    \"\"\"Generator function that yields batches of data\n","\n","    Args:\n","        Q1 (list): List of transformed (to tensor) questions.\n","        Q2 (list): List of transformed (to tensor) questions.\n","        batch_size (int): Number of elements per batch.\n","        pad (int, optional): Pad character from the vocab. Defaults to 1.\n","        shuffle (bool, optional): If the batches should be randomnized or not. Defaults to True.\n","    Yields:\n","        tuple: Of the form (input1, input2) with types (numpy.ndarray, numpy.ndarray)\n","        NOTE: input1: inputs to your model [q1a, q2a, q3a, ...] i.e. (q1a,q1b) are duplicates\n","              input2: targets to your model [q1b, q2b,q3b, ...] i.e. (q1a,q2i) i!=a are not duplicates\n","    \"\"\"\n","\n","    input1 = []\n","    input2 = []\n","    idx = 0\n","    len_q = len(Q1)\n","    question_indexes = [*range(len_q)]\n","    \n","    if shuffle:\n","        rnd.shuffle(question_indexes)\n","    \n","    while True:\n","        if idx >= len_q:\n","            # if idx is greater than or equal to len_q, set idx accordingly \n","            # (Hint: look at the instructions above)\n","            idx = len_q\n","            # shuffle to get random batches if shuffle is set to True\n","            if shuffle:\n","                rnd.shuffle(question_indexes)\n","        \n","        # get questions at the `question_indexes[idx]` position in Q1 and Q2\n","        q1 = Q1[question_indexes[idx]]\n","        q2 = Q2[question_indexes[idx]]\n","        \n","        # increment idx by 1\n","        idx += 1\n","        # append q1\n","        input1.append(q1)\n","        # append q2\n","        input2.append(q2)\n","        if len(input1) == batch_size:\n","            # determine max_len as the longest question in input1 & input 2\n","            # Hint: use the `max` function. \n","            # take max of input1 & input2 and then max out of the two of them.\n","            max_len = max(max([len(q) for q in input1]),\n","                          max([len(q) for q in input2]))\n","            # pad to power-of-2 (Hint: look at the instructions above)\n","            max_len = 2**int(np.ceil(np.log2(max_len)))\n","            b1 = []\n","            b2 = []\n","            for q1, q2 in zip(input1, input2):\n","                # add [pad] to q1 until it reaches max_len\n","                q1 = q1 + [pad] * (max_len - len(q1))\n","                # add [pad] to q2 until it reaches max_len\n","                q2 = q2 + [pad] * (max_len - len(q2))\n","                # append q1\n","                b1.append(q1)\n","                # append q2\n","                b2.append(q2)\n","            # use b1 and b2\n","            yield np.array(b1), np.array(b2)\n","            \n","            # reset the batches\n","            input1, input2 = [], []  # reset the batches"]},{"cell_type":"code","execution_count":null,"id":"ZFZeBPnW8Mlb","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1675282978023,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"ZFZeBPnW8Mlb","outputId":"9642ae15-b566-4bc6-9f76-348d5e77dbca"},"outputs":[],"source":["batch_size = 2\n","res1, res2 = next(data_generator(train_Q1, train_Q2, batch_size))\n","print(\"First questions  : \",'\\n', res1, '\\n')\n","print(\"Second questions : \",'\\n', res2)"]},{"cell_type":"code","execution_count":23,"id":"hww76f8_wt0x","metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1675282978024,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"hww76f8_wt0x"},"outputs":[],"source":["def Siamese(vocab_size=41699, d_model=128, mode='train'):\n","    \"\"\"Returns a Siamese model.\n","\n","    Args:\n","        vocab_size (int, optional): Length of the vocabulary. Defaults to len(vocab).\n","        d_model (int, optional): Depth of the model. Defaults to 128.\n","        mode (str, optional): 'train', 'eval' or 'predict', predict mode is for fast inference. Defaults to 'train'.\n","\n","    Returns:\n","        trax.layers.combinators.Parallel: A Siamese model. \n","    \"\"\"\n","\n","    def normalize(x):  # normalizes the vectors to have L2 norm 1\n","        return x / fastnp.sqrt(fastnp.sum(x * x, axis=-1, keepdims=True))\n","    \n","    q_processor = tl.Serial(  # Processor will run on Q1 and Q2.\n","        tl.Embedding(vocab_size, d_model),\n","        # Run LSTM. If this is not dim d_model it raises an error\n","        tl.LSTM(d_model),\n","        # Average vectors on the length axis.\n","        tl.Mean(axis=1),\n","        tl.Fn('Normalize', lambda x: normalize(x))  # Apply normalize function\n","    )  # Returns one vector of shape [batch_size, d_model].\n","    \n","    # Run on Q1 and Q2 in parallel.\n","    model = tl.Parallel(q_processor, q_processor)\n","    return model"]},{"cell_type":"code","execution_count":null,"id":"kvQ_jf52-JAn","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":16,"status":"ok","timestamp":1675282978025,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"kvQ_jf52-JAn","outputId":"5db48e4f-87ef-4ccc-da19-655e20e97558"},"outputs":[],"source":["# check your model\n","model = Siamese()\n","print(model)"]},{"cell_type":"code","execution_count":26,"id":"iRY0a362LSEH","metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1675282978026,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"iRY0a362LSEH"},"outputs":[],"source":["def TripletLossFn(v1, v2, margin=0.25):\n","    \"\"\"Custom Loss function.\n","\n","    Args:\n","        v1 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q1.\n","        v2 (numpy.ndarray): Array with dimension (batch_size, model_dimension) associated to Q2.\n","        margin (float, optional): Desired margin. Defaults to 0.25.\n","\n","    Returns:\n","        jax.interpreters.xla.DeviceArray: Triplet Loss.\n","    \"\"\"\n","    # use fastnp to take the dot product of the two batches (don't forget to transpose the second argument)\n","    scores = fastnp.dot(v1, v2.T)   # pairwise cosine sim\n","    # calculate new batch size\n","    batch_size = len(scores)\n","    # use fastnp to grab all postive `diagonal` entries in `scores`\n","    positive = fastnp.diagonal(scores)  # the positive ones (duplicates)\n","    # multiply `fastnp.eye(batch_size)` with 2.0 and subtract it out of `scores`\n","    negative_without_positive = scores - 2.0 * fastnp.eye(batch_size)\n","    # take the row by row `max` of `negative_without_positive`. \n","    # Hint: negative_without_positive.max(axis = [?])  \n","    closest_negative = negative_without_positive.max(axis=1)\n","    # subtract `fastnp.eye(batch_size)` out of 1.0 and do element-wise multiplication with `scores`\n","    negative_zero_on_duplicate = scores * (1.0 - fastnp.eye(batch_size))\n","    # use `fastnp.sum` on `negative_zero_on_duplicate` for `axis=1` and divide it by `(batch_size - 1)` \n","    mean_negative = np.sum(negative_zero_on_duplicate, axis=1) / (batch_size-1)\n","    # compute `fastnp.maximum` among 0.0 and `A`\n","    # A = subtract `positive` from `margin` and add `closest_negative` \n","    triplet_loss1 = fastnp.maximum(0.0, margin - positive + closest_negative)\n","    # compute `fastnp.maximum` among 0.0 and `B`\n","    # B = subtract `positive` from `margin` and add `mean_negative`\n","    triplet_loss2 = fastnp.maximum(0.0, margin - positive + mean_negative)\n","    # add the two losses together and take the `fastnp.mean` of it\n","    triplet_loss = fastnp.mean(triplet_loss1 + triplet_loss2)\n","    \n","    return triplet_loss"]},{"cell_type":"code","execution_count":null,"id":"eHkHu9s-LSEH","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1651,"status":"ok","timestamp":1675282979669,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"eHkHu9s-LSEH","outputId":"c353f2fc-73a8-4eb8-e437-7295fda07ff4"},"outputs":[],"source":["v1 = np.array([[ 0.26726124,  0.53452248,  0.80178373],[-0.5178918 , -0.57543534, -0.63297887]])\n","v2 = np.array([[0.26726124, 0.53452248, 0.80178373],[0.5178918 , 0.57543534, 0.63297887]])\n","print(\"Triplet Loss:\", TripletLossFn(v1,v2))"]},{"cell_type":"code","execution_count":29,"id":"-QvFh5rPLSEI","metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675282979670,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"-QvFh5rPLSEI"},"outputs":[],"source":["from functools import partial\n","def TripletLoss(margin=0.25):\n","    triplet_loss_fn = partial(TripletLossFn, margin=margin)\n","    return tl.Fn('TripletLoss', triplet_loss_fn)"]},{"cell_type":"code","execution_count":null,"id":"iPk7gh-nzCBg","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1675282979670,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"iPk7gh-nzCBg","outputId":"234a5c6e-498c-4fba-fd63-5bc37f815f0b"},"outputs":[],"source":["batch_size = 256\n","train_generator = data_generator(train_Q1, train_Q2, batch_size, vocab['<PAD>'])\n","val_generator = data_generator(val_Q1, val_Q2, batch_size, vocab['<PAD>'])\n","print('train_Q1.shape ', train_Q1.shape)\n","print('val_Q1.shape   ', val_Q1.shape)"]},{"cell_type":"code","execution_count":31,"id":"_kbtfz4T_m7x","metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1675282979671,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"_kbtfz4T_m7x"},"outputs":[],"source":["def train_model(Siamese, TripletLoss, lr_schedule, \n","                train_generator=train_generator, val_generator=val_generator, output_dir='model/'):\n","    \"\"\"Training the Siamese Model\n","\n","    Args:\n","        Siamese (function): Function that returns the Siamese model.\n","        TripletLoss (function): Function that defines the TripletLoss loss function.\n","        lr_schedule (function): Trax multifactor schedule function.\n","        train_generator (generator, optional): Training generator. Defaults to train_generator.\n","        val_generator (generator, optional): Validation generator. Defaults to val_generator.\n","        output_dir (str, optional): Path to save model to. Defaults to 'model/'.\n","\n","    Returns:\n","        trax.supervised.training.Loop: Training loop for the model.\n","    \"\"\"\n","    output_dir = os.path.expanduser(output_dir)\n","\n","    train_task = training.TrainTask(\n","        labeled_data=train_generator,         # Use generator (train)\n","        loss_layer=TripletLoss(),             # Use triplet loss. Don't forget to instantiate this object\n","        optimizer=trax.optimizers.Adam(0.01), # Don't forget to add the learning rate parameter\n","        lr_schedule=lr_schedule,              # Use Trax multifactor schedule function\n","    )\n","\n","    eval_task = training.EvalTask(\n","        labeled_data=val_generator,       # Use generator (val)\n","        metrics=[TripletLoss()],          # Use triplet loss. Don't forget to instantiate this object\n","    )\n","\n","    training_loop = training.Loop(Siamese(),\n","                                  train_task,\n","                                  eval_tasks=[eval_task],\n","                                  output_dir=output_dir)\n","\n","    return training_loop"]},{"cell_type":"code","execution_count":null,"id":"-3KXjmBo_6Xa","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19370,"status":"ok","timestamp":1675282999030,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"-3KXjmBo_6Xa","outputId":"ebce6714-5472-4cfd-f801-152cd38af13d"},"outputs":[],"source":["## Note: if breaks, sometimes you have to terminate session and run cells again\n","\n","train_steps = 5\n","lr_schedule = trax.lr.warmup_and_rsqrt_decay(400, 0.01)\n","\n","training_loop = train_model(Siamese, TripletLoss, lr_schedule, train_generator, val_generator)\n","training_loop.run(train_steps)"]},{"cell_type":"code","execution_count":null,"id":"26-O4cGuLSEL","metadata":{"id":"26-O4cGuLSEL"},"outputs":[],"source":["model = Siamese()\n","model.init_from_file(file_name='./model/model.pkl.gz', weights_only=True, input_signature=shapes.signature(next(train_generator)))"]},{"cell_type":"code","execution_count":34,"id":"K-h6ZH507fUm","metadata":{"executionInfo":{"elapsed":18,"status":"ok","timestamp":1675282999610,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"K-h6ZH507fUm"},"outputs":[],"source":["def classify(test_Q1, test_Q2, y, threshold, model, vocab, data_generator=data_generator, batch_size=64):\n","    \"\"\"Function to test the accuracy of the model.\n","\n","    Args:\n","        test_Q1 (numpy.ndarray): Array of Q1 questions.\n","        test_Q2 (numpy.ndarray): Array of Q2 questions.\n","        y (numpy.ndarray): Array of actual target.\n","        threshold (float): Desired threshold.\n","        model (trax.layers.combinators.Parallel): The Siamese model.\n","        vocab (collections.defaultdict): The vocabulary used.\n","        data_generator (function): Data generator function. Defaults to data_generator.\n","        batch_size (int, optional): Size of the batches. Defaults to 64.\n","\n","    Returns:\n","        float: Accuracy of the model.\n","    \"\"\"    \n","    \n","    \n","    accuracy = 0\n","    for i in range(0, len(test_Q1), batch_size):\n","        # Call the data generator (built in Ex 01) with shuffle=False using next()\n","        # use batch size chuncks of questions as Q1 & Q2 arguments of the data generator. e.g x[i:i + batch_size]\n","        # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator\n","        q1, q2 = next(data_generator(\n","            test_Q1[i:i + batch_size], test_Q2[i:i + batch_size], batch_size, vocab['<PAD>'], shuffle=False))\n","        # use batch size chuncks of actual output targets (same syntax as example above)\n","        y_test = y[i:i + batch_size]\n","        # Call the model\n","        v1, v2 = model((q1, q2))\n","\n","        for j in range(batch_size):\n","            # take dot product to compute cos similarity of each pair of entries, v1[j], v2[j]\n","            # don't forget to transpose the second argument\n","            d = np.dot(v1[j], v2[j].T)\n","            # is d greater than the threshold?\n","            res = d > threshold\n","            # increment accurancy if y_test is equal `res`\n","            accuracy += (y_test[j] == res)\n","    # compute accuracy using accuracy and total length of test questions\n","    accuracy = accuracy / len(test_Q1)\n","    \n","    return accuracy"]},{"cell_type":"code","execution_count":null,"id":"yeQjHxkfpivH","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29799,"status":"ok","timestamp":1675283029393,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"yeQjHxkfpivH","outputId":"251fc99a-1d66-4b44-c93e-07512f712051"},"outputs":[],"source":["# this takes around 1 minute\n","accuracy = classify(Q1_test,Q2_test, y_test, 0.7, model, vocab, batch_size = 512) \n","print(\"Accuracy\", accuracy)"]},{"cell_type":"code","execution_count":37,"id":"Xs3CW8kNLSEO","metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1675283029394,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Xs3CW8kNLSEO"},"outputs":[],"source":["def predict(question1, question2, threshold, model, vocab, data_generator=data_generator, verbose=False):\n","    \"\"\"Function for predicting if two questions are duplicates.\n","\n","    Args:\n","        question1 (str): First question.\n","        question2 (str): Second question.\n","        threshold (float): Desired threshold.\n","        model (trax.layers.combinators.Parallel): The Siamese model.\n","        vocab (collections.defaultdict): The vocabulary used.\n","        data_generator (function): Data generator function. Defaults to data_generator.\n","        verbose (bool, optional): If the results should be printed out. Defaults to False.\n","\n","    Returns:\n","        bool: True if the questions are duplicates, False otherwise.\n","    \"\"\"\n","    # use `nltk` word tokenize function to tokenize\n","    q1 = nltk.word_tokenize(question1)  # tokenize\n","    q2 = nltk.word_tokenize(question2)  # tokenize\n","    Q1, Q2 = [], []\n","    for word in q1:  # encode q1\n","        # increment by checking the 'word' index in `vocab`\n","        Q1 += [vocab[word]]\n","    for word in q2:  # encode q2\n","        # increment by checking the 'word' index in `vocab`\n","        Q2 += [vocab[word]]\n","        \n","    # Call the data generator (built in Ex 01) using next()\n","    # pass [Q1] & [Q2] as Q1 & Q2 arguments of the data generator. Set batch size as 1\n","    # Hint: use `vocab['<PAD>']` for the `pad` argument of the data generator\n","    Q1, Q2 = next(data_generator([Q1], [Q2], 1, vocab['<PAD>']))\n","    # Call the model\n","    v1, v2 = model((Q1, Q2))\n","    # take dot product to compute cos similarity of each pair of entries, v1, v2\n","    # don't forget to transpose the second argument\n","    d = np.dot(v1[0], v2[0].T)\n","    # is d greater than the threshold?\n","    res = d > threshold\n","    \n","    if(verbose):\n","        print(\"Q1  = \", Q1, \"\\nQ2  = \", Q2)\n","        print(\"d   = \", d)\n","        print(\"res = \", res)\n","\n","    return res"]},{"cell_type":"code","execution_count":null,"id":"Raojyhw3z7HE","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":804,"status":"ok","timestamp":1675283030176,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"Raojyhw3z7HE","outputId":"9a3f2cf5-ddee-4b30-aeaa-c5547bad5b3e"},"outputs":[],"source":["# Feel free to try with your own questions\n","question1 = \"When will I see you?\"\n","question2 = \"When can I see you again?\"\n","# 1/True means it is duplicated, 0/False otherwise\n","predict(question1 , question2, 0.7, model, vocab, verbose = True)"]},{"cell_type":"code","execution_count":null,"id":"DZccIQ_lpivQ","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":468,"status":"ok","timestamp":1675283030636,"user":{"displayName":"David Learn","userId":"08846131768927784273"},"user_tz":-240},"id":"DZccIQ_lpivQ","outputId":"accea72f-9d53-4206-a481-230ae1c048e3"},"outputs":[],"source":["# Feel free to try with your own questions\n","question1 = \"Do they enjoy eating the dessert?\"\n","question2 = \"Do they like hiking in the desert?\"\n","# 1/True means it is duplicated, 0/False otherwise\n","predict(question1 , question2, 0.7, model, vocab, verbose=True)"]}],"metadata":{"colab":{"provenance":[]},"jupytext":{"encoding":"# -*- coding: utf-8 -*-"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"vscode":{"interpreter":{"hash":"56d44d6a8424451b5ce45d1ae0b0b7865dc60710e7f74571dd51dd80d7829ee9"}}},"nbformat":4,"nbformat_minor":5}
