{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Great resources for developing your understanding in Transformer based models:\n",
        "- Luis Serrano will make the start of your jurney magical [with this playlist](https://www.youtube.com/watch?v=OxCpWwDCDFQ&list=PLs8w1Cdi-zva4fwKkl9EK13siFvL9Wewf).\n",
        "- Great blog post by Jay Alamar: [The illustrated Transformer](https://jalammar.github.io/illustrated-transformer/).\n",
        "- Some other great blog posts: [By Google research](https://blog.research.google/2017/08/transformer-novel-neural-network.html), [By Lilian Weng](https://lilianweng.github.io/posts/2018-06-24-attention/), [Lilian Weng again](https://lilianweng.github.io/posts/2020-04-07-the-transformer-family/), [By Raimi Karim](https://towardsdatascience.com/illustrated-self-attention-2d627e33b20a).\n",
        "- And finally the paper itself: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)."
        "- Interactive visualization of LLM: [by Brendan Bycroft](https://bbycroft.net/llm)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_HdrmWMlpD-"
      },
      "source": [
        "Data : https://www.statmt.org/ (see european parlaiment proceedings)\n",
        "\n",
        "REFERENCE: https://arxiv.org/abs/1706.03762\n",
        "\n",
        "Got help : [here](https://github.com/rasbt/machine-learning-book/blob/main/ch15/ch15_part2.ipynb) and [here](https://github.com/dksifoua/Neural-Machine-Translation/blob/master/notebooks/5%20-%20SeqToSeq%20Model%20with%20Transformer.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "j_Kf8tiNj6G6"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import re\n",
        "import string\n",
        "import unicodedata\n",
        "import tqdm\n",
        "import pickle\n",
        "from pickle import dump, load\n",
        "from collections import Counter, OrderedDict\n",
        "from nltk.translate.bleu_score import sentence_bleu, corpus_bleu, SmoothingFunction\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataset import random_split\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "import torchtext\n",
        "from torchtext.vocab import vocab\n",
        "#from torchtext.data.metrics import bleu_score   #imported above from nltk\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ixjYxQp7DHe5"
      },
      "outputs": [],
      "source": [
        "!wget -q https://www.statmt.org/europarl/v7/fr-en.tgz\n",
        "!tar -xf fr-en.tgz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "zPaf2v9ADNBx"
      },
      "outputs": [],
      "source": [
        "#@title preprocess raw data\n",
        "\n",
        "# load doc into memory\n",
        "def load_doc(filename):\n",
        "    # open the file as read only\n",
        "    file = open(filename, mode='rt', encoding='utf-8')\n",
        "    # read all text\n",
        "    text = file.read()\n",
        "    # close the file\n",
        "    file.close()\n",
        "    return text\n",
        "\n",
        "# split a loaded document into sentences\n",
        "def to_sentences(doc):\n",
        "    return doc.strip().split('\\n')\n",
        "\n",
        "# shortest and longest sentence lengths\n",
        "def sentence_lengths(sentences):\n",
        "    lengths = [len(s.split()) for s in sentences]\n",
        "    return min(lengths), max(lengths)\n",
        "\n",
        "# clean lines\n",
        "def clean_lines(lines):\n",
        "    cleaned = list()\n",
        "    # prepare regex for char filtering\n",
        "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
        "    # prepare translation table for removing punctuation\n",
        "    # prepare translation table for removing punctuation\n",
        "    table = str.maketrans('', '', string.punctuation)\n",
        "    for line in lines:\n",
        "        # normalize unicode characters\n",
        "        line = unicodedata.normalize('NFD', line).encode('ascii', 'ignore')\n",
        "        line = line.decode('UTF-8')\n",
        "        # tokenize on white space\n",
        "        line = line.split()\n",
        "        # convert to lower case\n",
        "        line = [word.lower() for word in line]\n",
        "        # remove punctuation from each token\n",
        "        line = [word.translate(table) for word in line]\n",
        "        # remove non-printable chars form each token\n",
        "        line = [re_print.sub('', w) for w in line]\n",
        "        # remove tokens with numbers in them\n",
        "        line = [word for word in line if word.isalpha()]\n",
        "        # store as string\n",
        "        cleaned.append(' '.join(line))\n",
        "    return cleaned\n",
        "\n",
        "# load English data\n",
        "filename = 'europarl-v7.fr-en.en'\n",
        "doc = load_doc(filename)\n",
        "sentences = to_sentences(doc)\n",
        "minlen, maxlen = sentence_lengths(sentences)\n",
        "print('English data: sentences=%d, min=%d, max=%d' % (len(sentences),\n",
        "minlen, maxlen))\n",
        "cleanf=clean_lines(sentences)\n",
        "filename = 'English.pkl'\n",
        "\n",
        "with open(filename,'wb') as fl:\n",
        "  outfile = fl\n",
        "  pickle.dump(cleanf,outfile)\n",
        "#outfile.close()             #do this with context manager\n",
        "  print(filename,\" saved\")\n",
        "\n",
        "# load French data\n",
        "filename = 'europarl-v7.fr-en.fr'\n",
        "doc = load_doc(filename)\n",
        "sentences = to_sentences(doc)\n",
        "minlen, maxlen = sentence_lengths(sentences)\n",
        "print('French data: sentences=%d, min=%d, max=%d' % (len(sentences),\n",
        "minlen, maxlen))\n",
        "cleanf=clean_lines(sentences)\n",
        "filename = 'French.pkl'\n",
        "with open(filename,'wb') as fl:\n",
        "  outfile = fl\n",
        "  pickle.dump(cleanf,outfile)\n",
        "  print(filename,\" saved\")\n",
        "\n",
        "# load a clean dataset\n",
        "def load_clean_sentences(filename):\n",
        "    with open(filename, 'rb') as fl:\n",
        "      loaded = load(fl)\n",
        "    return loaded\n",
        "\n",
        "# save a list of clean sentences to file\n",
        "def save_clean_sentences(sentences, filename):\n",
        "    with open(filename, 'wb') as fl:\n",
        "        dump(sentences, fl)\n",
        "        print('Saved: %s' % filename)\n",
        "\n",
        "# create a frequency table for all words\n",
        "def to_vocab(lines):\n",
        "    vocab = Counter()\n",
        "    for line in lines:\n",
        "        tokens = line.split()\n",
        "        vocab.update(tokens)\n",
        "    return vocab\n",
        "\n",
        "# remove all words with a frequency below a threshold\n",
        "def trim_vocab(vocab, min_occurance):\n",
        "    tokens = [k for k,c in vocab.items() if c >= min_occurance]\n",
        "    return set(tokens)\n",
        "\n",
        "# mark all out-of-vocabulary words with \"unk\" for all lines\n",
        "def update_dataset(lines, vocab):\n",
        "    new_lines = list()\n",
        "    for line in lines:\n",
        "        new_tokens = list()\n",
        "        for token in line.split():\n",
        "\n",
        "           if token in vocab:\n",
        "              new_tokens.append(token)\n",
        "           else:\n",
        "              new_tokens.append('unk')\n",
        "        new_line = ' '.join(new_tokens)\n",
        "        new_lines.append(new_line)\n",
        "    return new_lines\n",
        "\n",
        "\n",
        "## load English dataset\n",
        "filename = 'English.pkl'\n",
        "lines = load_clean_sentences(filename)\n",
        "# calculate vocabulary\n",
        "vocab = to_vocab(lines)\n",
        "print('English Vocabulary: %d' % len(vocab))\n",
        "# reduce vocabulary\n",
        "vocab = trim_vocab(vocab, 5)\n",
        "print('New English Vocabulary: %d' % len(vocab))\n",
        "# mark out of vocabulary words\n",
        "lines = update_dataset(lines, vocab)\n",
        "# save updated dataset\n",
        "filename = 'english_vocab.pkl'\n",
        "save_clean_sentences(lines, filename)\n",
        "# spot check\n",
        "for i in range(20):\n",
        "    print(\"line\",i,\":\",lines[i])\n",
        "\n",
        "\n",
        "## load French dataset\n",
        "filename = 'French.pkl'\n",
        "lines = load_clean_sentences(filename)\n",
        "# calculate vocabulary\n",
        "vocab = to_vocab(lines)\n",
        "print('French Vocabulary: %d' % len(vocab))\n",
        "# reduce vocabulary\n",
        "vocab = trim_vocab(vocab, 5)\n",
        "print('New French Vocabulary: %d' % len(vocab))\n",
        "# mark out of vocabulary words\n",
        "lines = update_dataset(lines, vocab)\n",
        "# save updated dataset\n",
        "filename = 'french_vocab.pkl'\n",
        "save_clean_sentences(lines, filename)\n",
        "# spot check\n",
        "for i in range(20):\n",
        "    print(\"line\",i,\":\",lines[i])\n",
        "\n",
        "\n",
        "###----------------------------------------------------\n",
        "# ff = 'french_vocab.pkl'\n",
        "# french_lines = load_clean_sentences(ff)\n",
        "#french_vocab = to_vocab(french_lines)\n",
        "#print('French Vocabulary: %d' % len(french_vocab))\n",
        "\n",
        "# ef = 'english_vocab.pkl'\n",
        "# english_lines = load_clean_sentences(ef)\n",
        "#english_vocab = to_vocab(english_lines)\n",
        "#print('english Vocabulary: %d' % len(english_vocab))\n",
        "\n",
        "#print([english_vocab[token] for token in ['this', 'is', 'an', 'example']]) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "cellView": "form",
        "id": "W5cr8wGusC2x"
      },
      "outputs": [],
      "source": [
        "#@title custom dataset and dataloader\n",
        "\n",
        "def tokenizer(text):\n",
        "    text = re.sub('<[^>]*>', '', text)\n",
        "    emoticons = re.findall('(?::|;|=)(?:-)?(?:\\)|\\(|D|P)', text.lower())\n",
        "    text = re.sub('[\\W]+', ' ', text.lower()) +\\\n",
        "        ' '.join(emoticons).replace('-', '')\n",
        "    tokenized = text.split()\n",
        "    return tokenized\n",
        "\n",
        "# to_vocab() is unsorted so not to do same thing twice integrate this into to_vocab function above \n",
        "def sorted_tokentoint(lines):\n",
        "    token_vocab = Counter()\n",
        "    for line in lines:\n",
        "        tokens = tokenizer(line)\n",
        "        token_vocab.update(tokens)\n",
        "    sorted_by_freq_tuples = sorted(token_vocab.items(), key=lambda x: x[1], reverse=True)\n",
        "    ordered_dict = OrderedDict(sorted_by_freq_tuples)\n",
        "    vocab = torchtext.vocab.vocab(ordered_dict)\n",
        "    vocab.insert_token(\"<pad>\", 0)\n",
        "    vocab.insert_token(\"<unk>\", 1)\n",
        "    vocab.insert_token(\"<sos>\", 2)\n",
        "    vocab.insert_token(\"<eos>\", 3)\n",
        "    vocab.set_default_index(1)    # for out of vocabulary words\n",
        "    return vocab\n",
        "\n",
        "\n",
        "ef = 'english_vocab.pkl'\n",
        "english_lines = load_clean_sentences(ef)\n",
        "ff = 'french_vocab.pkl'\n",
        "french_lines = load_clean_sentences(ff)\n",
        "\n",
        "sorted_french_vocab = sorted_tokentoint(french_lines)\n",
        "sorted_english_vocab = sorted_tokentoint(english_lines)\n",
        "\n",
        "# text_pipeline = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "def text_pipeline(text, language_vocab):\n",
        "    return [language_vocab[token] for token in tokenizer(text)]\n",
        "\n",
        "def collate_batch(batch):\n",
        "    textin_list, textout_list, lengthsin, lengthsout = [], [], [], []\n",
        "    for _textin, _textout in batch:\n",
        "        _textin = '<sos> '+_textin +' <eos>'\n",
        "        _textout = '<sos> '+_textout+' <eos>'\n",
        "        processed_textin = torch.tensor(text_pipeline(_textin, sorted_english_vocab), \n",
        "                                      dtype=torch.int64)\n",
        "        processed_textout = torch.tensor(text_pipeline(_textout, sorted_french_vocab), \n",
        "                                      dtype=torch.int64)\n",
        "       \n",
        "        textin_list.append(processed_textin)\n",
        "        textout_list.append(processed_textout)\n",
        "        # lengthsin.append(processed_textin.size(0))\n",
        "        # lengthsout.append(processed_textout.size(0))\n",
        "\n",
        "    # lengthsin = torch.tensor(lengthsin)\n",
        "    # lengthsout = torch.tensor(lengthsout)\n",
        "\n",
        "    padded_textin_list = nn.utils.rnn.pad_sequence(\n",
        "        textin_list, batch_first=True)\n",
        "    padded_textout_list = nn.utils.rnn.pad_sequence(\n",
        "        textout_list, batch_first=True)\n",
        "    \n",
        "    return padded_textin_list.to(device), padded_textout_list.to(device) \n",
        "    #, lengthsin.to(device), lengthsout.to(device)\n",
        "\n",
        "\n",
        "class TranslationDataset(Dataset):\n",
        "    def __init__(self, in_lang_lines, out_lang_lines, custom_test_length=None):\n",
        "        super().__init__()\n",
        "        self.in_lang_lines = in_lang_lines\n",
        "        self.out_lang_lines = out_lang_lines\n",
        "        self.custom_test_length = custom_test_length\n",
        "\n",
        "    def __len__(self):\n",
        "        assert self.out_lang_lines==self.out_lang_lines\n",
        "        return len(self.out_lang_lines) if not self.custom_test_length else self.custom_test_length\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        in_sentence = self.in_lang_lines[idx]  \n",
        "        out_sentence = self.out_lang_lines[idx]  \n",
        "        return  in_sentence, out_sentence       ###tokenizer(in_sentence), tokenizer(out_sentence)  \n",
        "\n",
        "\n",
        "\n",
        "length = len(english_lines[:256])  ## note, for full scale learning you should remove [:256] everywhere\n",
        "trn = int(length*0.8)\n",
        "val = int(length*0.1)\n",
        "tst = length - trn - val\n",
        "\n",
        "dataset = TranslationDataset(english_lines[:256], french_lines[:256], custom_test_length=256) ##remove 256 for full scale learning\n",
        "torch.manual_seed(1)\n",
        "train_dataset, valid_dataset, test_dataset = random_split(list(dataset), [trn, val, tst])\n",
        "\n",
        "batch_size = 64  \n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size,\n",
        "                      shuffle=True, collate_fn=collate_batch)   #, drop_last=True\n",
        "valid_dl = DataLoader(valid_dataset, batch_size=batch_size,\n",
        "                      shuffle=False, collate_fn=collate_batch)\n",
        "test_dl = DataLoader(test_dataset, batch_size=batch_size,\n",
        "                     shuffle=False, collate_fn=collate_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "cellView": "form",
        "id": "BrOB-aYe7Yf4"
      },
      "outputs": [],
      "source": [
        "#@title multihead attention\n",
        "\n",
        "class MultiHeadAttentionLayer(nn.Module):\n",
        "\n",
        "    def __init__(self, d_model, n_heads):\n",
        "        super(MultiHeadAttentionLayer, self).__init__()\n",
        "        assert d_model % n_heads == 0\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.head_size = d_model // n_heads\n",
        "        self.fc_q = nn.Linear(d_model, d_model)\n",
        "        self.fc_k = nn.Linear(d_model, d_model)\n",
        "        self.fc_v = nn.Linear(d_model, d_model)\n",
        "        self.fc_o = nn.Linear(d_model, d_model)\n",
        "        \n",
        "    def forward(self, query, key, value, mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, q_len, d_model] query\n",
        "        :param Tensor[batch_size, k_len, d_model] key\n",
        "        :param Tensor[batch_size, v_len, d_model] value\n",
        "        :param Tensor[batch_size, ..., k_len] mask\n",
        "        :return Tensor[batch_size, q_len, d_model] context\n",
        "        :return Tensor[batch_size, n_heads, q_len, k_len] attention_weights\n",
        "        \"\"\"\n",
        "        Q = self.fc_q(query) # [batch_size, q_len, d_model]\n",
        "        K = self.fc_k(key) # [batch_size, k_len, d_model]\n",
        "        V = self.fc_v(value) # [batch_size, v_len, d_model]\n",
        "\n",
        "        Q = Q.view(Q.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, q_len, head_size]\n",
        "        K = K.view(K.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, k_len, head_size]\n",
        "        V = V.view(V.size(0), -1, self.n_heads, self.head_size).permute(0, 2, 1, 3) # [batch_size, n_heads, v_len, head_size]\n",
        "\n",
        "        scores = torch.matmul(Q, K.transpose(-1, -2)) # [batch_size, n_heads, q_len, k_len]\n",
        "        scores = scores / torch.sqrt(torch.FloatTensor([self.head_size]).to(Q.device))\n",
        "        if mask is not None:\n",
        "            scores = scores.masked_fill(mask == 0, -1e18)  # also see https://pytorch.org/docs/stable/generated/torch.Tensor.masked_fill_.html#torch.Tensor.masked_fill_\n",
        "        attention_weights = F.softmax(scores , dim=-1) # [batch_size, n_heads, q_len, k_len]                \n",
        "        \n",
        "        context = torch.matmul(attention_weights, V) # [batch_size, n_heads, q_len, v_len]\n",
        "        context = context.permute(0, 2, 1, 3).contiguous() # [batch_size, q_len, n_heads, v_len]\n",
        "        context = context.view(context.size(0), -1, self.d_model)\n",
        "        context = self.fc_o(context) # [batch_size, q_len, d_model]\n",
        "\n",
        "        return context, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "PItRNXZj7Z0G"
      },
      "outputs": [],
      "source": [
        "#@title positionwise feedforward and positional encoding \n",
        "\n",
        "# positionwise feedforward\n",
        "\n",
        "class PositionWiseFeedForwardLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, hidden_size):\n",
        "        super(PositionWiseFeedForwardLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.hidden_size = hidden_size\n",
        "        self.fc_in = nn.Linear(d_model, hidden_size)\n",
        "        self.fc_ou = nn.Linear(hidden_size, d_model)\n",
        "        \n",
        "    def forward(self, inputs):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len, d_model] inputs\n",
        "        :return Tensor[batch_size, seq_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        outputs = F.relu(self.fc_in(inputs)) # [batch_size, seq_len, hidden_size]\n",
        "        return self.fc_ou(outputs) # [batch_size, seq_len, d_model]\n",
        "\n",
        "# positional encoding layer is designed for giving positional / sequential awarenes of the words in the sentence to the model\n",
        "\n",
        "class PositionalEncodingLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, max_len=100):\n",
        "        super(PositionalEncodingLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.max_len = max_len\n",
        "    \n",
        "    def get_angles(self, positions, indexes):\n",
        "        d_model_tensor = torch.FloatTensor([[self.d_model]]).to(positions.device) # to same device as positions (generally and d_model are made to be same)\n",
        "        angle_rates = torch.pow(10000, (2 * (indexes // 2)) / d_model_tensor)   #torch.pow(input, exponent) takes pover \n",
        "        return positions / angle_rates\n",
        "\n",
        "    def forward(self, input_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, seq_len] input_sequences\n",
        "        :return Tensor[batch_size, seq_len, d_model] position_encoding\n",
        "        \"\"\"\n",
        "        positions = torch.arange(input_sequences.size(1)).unsqueeze(1).to(input_sequences.device) # [seq_len, 1]\n",
        "        indexes = torch.arange(self.d_model).unsqueeze(0).to(input_sequences.device) # [1, d_model]\n",
        "        angles = self.get_angles(positions, indexes) # [seq_len, d_model]\n",
        "        angles[:, 0::2] = torch.sin(angles[:, 0::2]) # apply sin to even indices in the tensor; 2i\n",
        "        angles[:, 1::2] = torch.cos(angles[:, 1::2]) # apply cos to odd indices in the tensor; 2i\n",
        "        position_encoding = angles.unsqueeze(0).repeat(input_sequences.size(0), 1, 1) # [batch_size, seq_len, d_model]\n",
        "        return position_encoding\n",
        "\n",
        "pos_encoding = PositionalEncodingLayer(d_model=512)(torch.randint(100, size=(64, 50))).numpy()\n",
        "print(pos_encoding.shape)\n",
        "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
        "plt.xlabel('Depth')\n",
        "plt.ylabel('Position')\n",
        "plt.colorbar()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "cellView": "form",
        "id": "-O1By8GL75g9"
      },
      "outputs": [],
      "source": [
        "#@title encoder block and layer\n",
        "\n",
        "class EncoderBlockLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, n_heads, hidden_size, dropout):\n",
        "        super(EncoderBlockLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(d_model=d_model, hidden_size=hidden_size)\n",
        "        self.position_wise_feed_forward_layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, src_inputs, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len, d_model] src_inputs\n",
        "        :param Tensor[batch_size,  src_len] src_mask\n",
        "        :return Tensor[batch_size, src_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        context, _ = self.multi_head_attention_layer(query=src_inputs, key=src_inputs, value=src_inputs, mask=src_mask)\n",
        "        context = self.multi_head_attention_layer_norm(self.dropout(context) + src_inputs)\n",
        "        \n",
        "        outputs = self.position_wise_feed_forward_layer(context)\n",
        "        outputs = self.position_wise_feed_forward_layer_norm(self.dropout(outputs) + context)\n",
        "        \n",
        "        return outputs\n",
        "\n",
        "class EncoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, max_len, d_model, n_heads, hidden_size, dropout, n_layers):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.n_layers = n_layers\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_encoding = PositionalEncodingLayer(d_model=d_model, max_len=max_len)\n",
        "        self.encoder_block_layers = nn.ModuleList([EncoderBlockLayer(d_model=d_model, n_heads=n_heads, hidden_size=hidden_size,\n",
        "                                                                     dropout=dropout) for _ in range(n_layers)])\n",
        "    \n",
        "    def forward(self, src_sequences, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :param Tensor[batch_size, src_len] src_mask\n",
        "        :return Tensor[batch_size, src_len, d_model] outputs\n",
        "        \"\"\"\n",
        "        token_embedded = self.token_embedding(src_sequences) # [batch_size, src_len, d_model]\n",
        "        position_encoded = self.position_encoding(src_sequences) # [batch_size, src_len, d_model]\n",
        "        outputs = self.dropout(token_embedded) + position_encoded # [batch_size, src_len, d_model]\n",
        "        for layer in self.encoder_block_layers:\n",
        "            outputs = layer(src_inputs=outputs, src_mask=src_mask) # [batch_size, src_len, d_model]\n",
        "        return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "cellView": "form",
        "id": "45QO8sS78DtF"
      },
      "outputs": [],
      "source": [
        "#@title decoder block and layer\n",
        "\n",
        "class DecoderBlockLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, d_model, n_heads, hidden_size, dropout):\n",
        "        super(DecoderBlockLayer, self).__init__()\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.mask_multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.mask_multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.multi_head_attention_layer = MultiHeadAttentionLayer(d_model=d_model, n_heads=n_heads)\n",
        "        self.multi_head_attention_layer_norm = nn.LayerNorm(d_model)\n",
        "        self.position_wise_feed_forward_layer = PositionWiseFeedForwardLayer(d_model=d_model, hidden_size=hidden_size)\n",
        "        self.position_wise_feed_forward_layer_norm = nn.LayerNorm(d_model)\n",
        "    \n",
        "    def forward(self, dest_inputs, src_encoded, dest_mask, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_len, d_model] dest_inputs\n",
        "        :param Tensor[batch_size, src_len, d_model] src_encoded\n",
        "        :param Tensor[batch_size,  dest_len] dest_mask\n",
        "        :param Tensor[batch_size,  src_len] src_mask\n",
        "        :return Tensor[batch_size, dest_len, d_model] outputs\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        masked_context, _ = self.mask_multi_head_attention_layer(query=dest_inputs, key=dest_inputs, value=dest_inputs, mask=dest_mask)\n",
        "        masked_context = self.mask_multi_head_attention_layer_norm(self.dropout(masked_context) + dest_inputs)\n",
        "        \n",
        "        context, attention_weights = self.multi_head_attention_layer(query=masked_context, key=src_encoded, value=src_encoded, mask=src_mask)\n",
        "        context = self.multi_head_attention_layer_norm(self.dropout(context) + masked_context)\n",
        "        \n",
        "        outputs = self.position_wise_feed_forward_layer(context)\n",
        "        outputs = self.position_wise_feed_forward_layer_norm(self.dropout(outputs) + context)\n",
        "        \n",
        "        return outputs, attention_weights\n",
        "\n",
        "\n",
        "class DecoderLayer(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, max_len, d_model, n_heads, hidden_size, dropout, n_layers):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.max_len = max_len\n",
        "        self.d_model = d_model\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_size = hidden_size\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "        self.n_layers = n_layers\n",
        "        self.token_embedding = nn.Embedding(vocab_size, d_model)\n",
        "        self.position_encoding = PositionalEncodingLayer(d_model=d_model, max_len=max_len)\n",
        "        self.decoder_block_layers = nn.ModuleList([DecoderBlockLayer(d_model=d_model, n_heads=n_heads, hidden_size=hidden_size, dropout=dropout) for _ in range(n_layers)])\n",
        "        self.fc = nn.Linear(d_model, vocab_size)\n",
        "    \n",
        "    def forward(self, dest_sequences, src_encoded, dest_mask, src_mask):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :param Tensor[batch_size, src_len, d_model] src_encoded\n",
        "        :param Tensor[batch_size, dest_len, d_model] dest_mask\n",
        "        :param Tensor[batch_size, src_len, d_model] src_mask\n",
        "        :return Tensor[batch_size, dest_len, vocab_size] logits\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        token_embedded = self.token_embedding(dest_sequences) # [batch_size, dest_len, d_model]\n",
        "        position_encoded = self.position_encoding(dest_sequences) # [batch_size, dest_len, d_model]\n",
        "        outputs = self.dropout(token_embedded) + position_encoded # [batch_size, dest_len, d_model]\n",
        "        for layer in self.decoder_block_layers:\n",
        "            outputs, attention_weights = layer(dest_inputs=outputs, src_encoded=src_encoded, dest_mask=dest_mask, src_mask=src_mask)\n",
        "        logits = self.fc(outputs)\n",
        "        return logits, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "id": "qiFmlPkD8b88"
      },
      "outputs": [],
      "source": [
        "#@title combining all in one transformer model\n",
        "\n",
        "class Transformer(nn.Module):\n",
        "    \n",
        "    def __init__(self, encoder, decoder, src_pad_index, dest_pad_index):\n",
        "        super(Transformer, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_pad_index = src_pad_index\n",
        "        self.dest_pad_index = dest_pad_index\n",
        "\n",
        "    def make_src_mask(self, src_sequences):\n",
        "        \"\"\"Mask <pad> tokens.\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :return Tensor[batch size, 1, 1, src len] src_mask\n",
        "        \"\"\"        \n",
        "        src_mask = (src_sequences != self.src_pad_index).unsqueeze(1).unsqueeze(2)\n",
        "        return src_mask\n",
        "    \n",
        "    def make_dest_mask(self, dest_sequences):\n",
        "        \"\"\"Mask <pad> tokens and future tokens as well.\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :return tensor[batch_size, 1, dest_len, dest_len] dest_mask\n",
        "        \"\"\"\n",
        "        mask = (dest_sequences != self.dest_pad_index).unsqueeze(1).unsqueeze(2) # [batch size, 1, 1, trg len]\n",
        "        # torch.tril() lower triangular part of the matrix \n",
        "        sub_mask = torch.tril(torch.ones((dest_sequences.size(1), dest_sequences.size(1))).to(dest_sequences.device)).bool() # [trg len, trg len]        \n",
        "        return mask & sub_mask      #both hold for masking: mask--> true everywhere except dest_pad_index; sub_mask-->'triangular' filter\n",
        "    \n",
        "    def forward(self, src_sequences, dest_sequences):\n",
        "        \"\"\"\n",
        "        :param Tensor[batch_size, src_len] src_sequences\n",
        "        :param Tensor[batch_size, dest_len] dest_sequences\n",
        "        :return Tensor[batch_size, dest_len, vocab_size] logits\n",
        "        :return Tensor[batch_size, n_heads, dest_len, src_len] attention_weights\n",
        "        \"\"\"\n",
        "        src_mask, dest_mask = self.make_src_mask(src_sequences), self.make_dest_mask(dest_sequences)\n",
        "        src_encoded = self.encoder(src_sequences=src_sequences, src_mask=src_mask)\n",
        "        logits, attention_weights = self.decoder(dest_sequences=dest_sequences, src_encoded=src_encoded, dest_mask=dest_mask, src_mask=src_mask)\n",
        "        return logits, attention_weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "cellView": "form",
        "id": "o41qH06h8w0V"
      },
      "outputs": [],
      "source": [
        "#@title building parts for training\n",
        "\n",
        "class Metrics:\n",
        "    \n",
        "    def __init__(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def reset(self):\n",
        "        self.value = 0.\n",
        "        self.sum = 0.\n",
        "        self.count = 0\n",
        "        self.average = 0.\n",
        "        \n",
        "    def update(self, value, n=1):\n",
        "        self.value = value\n",
        "        self.sum += value * n\n",
        "        self.count += n\n",
        "        self.average = self.sum / self.count\n",
        "\n",
        "def accuracy(outputs, target_sequences, k=5):\n",
        "    \"\"\" Calculate Top-k accuracy\n",
        "    :param Tensor[batch_size, dest_seq_len, vocab_size] outputs\n",
        "    :param Tensor[batch_size, dest_seq_len] target_sequences\n",
        "    :return float Top-k accuracy\n",
        "    \"\"\"\n",
        "    batch_size = target_sequences.size(0)\n",
        "    _, indices = outputs.topk(k, dim=2, largest=True, sorted=True) # [batch_size, dest_seq_len, 5]  #also see torch.topk() https://pytorch.org/docs/stable/generated/torch.topk.html\n",
        "    correct = indices.eq(target_sequences.unsqueeze(-1).expand_as(indices))  #also see torch.eq() https://pytorch.org/docs/stable/generated/torch.eq.html\n",
        "    correct_total = correct.view(-1).float().sum()  # 0D tensor\n",
        "    return correct_total.item() * (100.0 / indices.numel())\n",
        "\n",
        "\n",
        "class Trainer:\n",
        "    \n",
        "    def __init__(self, model, optimizer, criterion):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.criterion = criterion\n",
        "    \n",
        "    def train_step(self, loader, epoch, grad_clip):\n",
        "        loss_tracker, acc_tracker = Metrics(), Metrics()\n",
        "        self.model.train()\n",
        "        progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "        for i, batch in progress_bar:\n",
        "            src, trg = batch[0], batch[1]\n",
        "            self.optimizer.zero_grad()\n",
        "            logits, _ = self.model(src, trg[:, :-1]) # [batch_size, dest_len, vocab_size]\n",
        "            loss = self.criterion(logits.contiguous().view(-1, self.model.decoder.vocab_size), trg[:, 1:].contiguous().view(-1))\n",
        "            loss.backward()\n",
        "            nn.utils.clip_grad_norm_(self.model.parameters(), grad_clip)\n",
        "            self.optimizer.step()\n",
        "            loss_tracker.update(loss.item())\n",
        "            acc_tracker.update(accuracy(logits, trg[:, 1:]))\n",
        "            loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "            progress_bar.set_description(f'Epoch: {epoch+1:02d} -     loss: {loss_:.3f} -     ppl: {ppl_:.3f} -     acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def validate(self, loader, epoch):\n",
        "        loss_tracker, acc_tracker = Metrics(), Metrics()\n",
        "        self.model.eval()\n",
        "        with torch.no_grad():\n",
        "            progress_bar = tqdm.tqdm(enumerate(loader), total=len(loader))\n",
        "            for i, batch in progress_bar:\n",
        "                src, trg = batch[0], batch[1]\n",
        "                logits, _ = self.model(src, trg[:, :-1]) # [batch_size, dest_len, vocab_size]\n",
        "                loss = self.criterion(logits.contiguous().view(-1, self.model.decoder.vocab_size), trg[:, 1:].contiguous().view(-1))\n",
        "                loss_tracker.update(loss.item())\n",
        "                acc_tracker.update(accuracy(logits, trg[:, 1:]))\n",
        "                loss_, ppl_, acc_ = loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "                progress_bar.set_description(f'Epoch: {epoch+1:02d} - val_loss: {loss_:.3f} - val_ppl: {ppl_:.3f} - val_acc: {acc_:.3f}%')\n",
        "        return loss_tracker.average, np.exp(loss_tracker.average), acc_tracker.average\n",
        "    \n",
        "    def train(self, train_loader, valid_loader, n_epochs, grad_clip):\n",
        "        history, best_loss = {'loss': [], 'val_loss': [], 'acc': [], 'val_acc': [], 'ppl': [], 'val_ppl': []}, np.inf\n",
        "        for epoch in range(n_epochs):\n",
        "            loss, ppl, acc = self.train_step(train_loader, epoch, grad_clip)\n",
        "            val_loss, val_ppl, val_acc = self.validate(valid_loader, epoch)\n",
        "            if best_loss > val_loss:\n",
        "                best_loss = val_loss\n",
        "                torch.save(self.model.state_dict(), './transformer.pth')\n",
        "            history['acc'].append(acc); history['val_acc'].append(val_acc)\n",
        "            history['ppl'].append(ppl); history['val_ppl'].append(val_ppl)\n",
        "            history['loss'].append(loss); history['val_loss'].append(val_loss)\n",
        "        return history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ECVcj_0y9Q7F"
      },
      "outputs": [],
      "source": [
        "#@title training\n",
        "\n",
        "D_MODEL = 256\n",
        "N_LAYERS = 2\n",
        "N_HEADS = 8\n",
        "HIDDEN_SIZE = 512\n",
        "MAX_LEN = 50\n",
        "DROPOUT = 0.25\n",
        "BATCH_SIZE = 64\n",
        "LR = 1e-3\n",
        "N_EPOCHS = 10\n",
        "GRAD_CLIP = 1.0\n",
        "\n",
        "\n",
        "transformer = Transformer(\n",
        "    encoder=EncoderLayer(\n",
        "        vocab_size=len(sorted_english_vocab),\n",
        "        max_len=MAX_LEN,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        n_layers=N_LAYERS\n",
        "    ),\n",
        "    decoder=DecoderLayer(\n",
        "        vocab_size=len(sorted_french_vocab),\n",
        "        max_len=MAX_LEN,\n",
        "        d_model=D_MODEL,\n",
        "        n_heads=N_HEADS,\n",
        "        hidden_size=HIDDEN_SIZE,\n",
        "        dropout=DROPOUT,\n",
        "        n_layers=N_LAYERS\n",
        "    ),\n",
        "    src_pad_index= 0, #after using torch.nn.utils.rnn.pad_sequence() the default value for padded element == 0 \n",
        "    dest_pad_index= 0, \n",
        ").to(device)\n",
        "optimizer = optim.Adam(params=transformer.parameters(), lr=LR)\n",
        "criterion = nn.CrossEntropyLoss() #nn.CrossEntropyLoss(ignore_index=0) \n",
        "# print(f'Number of parameters of the model: {sum(p.numel() for p in transformer.parameters() if p.requires_grad):,}')\n",
        "# print(transformer)\n",
        "trainer = Trainer(model=transformer, optimizer=optimizer, criterion=criterion)\n",
        "\n",
        "\n",
        "history = trainer.train(train_loader=train_dl, valid_loader=valid_dl, n_epochs=N_EPOCHS, grad_clip=GRAD_CLIP)\n",
        "\n",
        "### visualize training results\n",
        "titlelist = ['Loss', 'Perplexity', 'Top-5 Accuracy & BLEU-4']\n",
        "eval_type_list = ['Loss', 'Perplexity', 'Accuracy & BLEU-4 (%)']\n",
        "def plot(titlelist, eval_type_list):\n",
        "    _, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "    for i in range(3):\n",
        "        a, b = list(history.keys())[:i+2][-2:]\n",
        "        axes[i].plot(history[a], label='train')\n",
        "        axes[i].plot(history[b], label='valid')\n",
        "        axes[i].set_title(titlelist[i])\n",
        "        axes[i].set_xlabel('Epoch')\n",
        "        axes[i].set_ylabel(eval_type_list[i])\n",
        "        axes[i].grid(True)\n",
        "        axes[i].legend();\n",
        "    plt.show()\n",
        "\n",
        "plot(titlelist, eval_type_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ry4-DZnOFAxG"
      },
      "outputs": [],
      "source": [
        "#@title evaluate or translate with vanilla argmax\n",
        "\n",
        "\n",
        "def visualize_attention(attentions, inputtext, outputtext):\n",
        "  np.random.seed(0)\n",
        "  sns.set_theme()\n",
        "  xticks = inputtext.split(' ')                         #[''] + inputtext.split(' ') + ['<eos>']\n",
        "  outputtext = outputtext.split(' ')\n",
        "  plt.figure(figsize=(16,16))\n",
        "  ax = sns.heatmap(attentions.cpu().detach().numpy(), xticklabels=xticks, yticklabels=outputtext)\n",
        "  ax.set_xticklabels(ax.get_xticklabels(), rotation = 90, fontsize = 9)\n",
        "  ax.set_yticklabels(ax.get_yticklabels(), rotation = 0, fontsize = 9)\n",
        "  print('input: ', inputtext)\n",
        "  print('output: ', ' '.join(outputtext))   \n",
        "\n",
        "\n",
        "def translate_or_evaluate(sentence=None, target=None, model=transformer, max_len=5, device=device):\n",
        "    if sentence == None:\n",
        "        sentence, target = test_dataset[random.choice(range(len(test_dataset)))]  #randomly choose one peir from test_dataset\n",
        "   \n",
        "    src_sequence = text_pipeline(sentence, sorted_english_vocab)\n",
        "    translated_sentence, attention_weights, pred_logps = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        src_sequence = torch.LongTensor(src_sequence).unsqueeze(0).to(device)\n",
        "        src_mask = model.make_src_mask(src_sequence)\n",
        "        src_encoded = model.encoder(src_sequences=src_sequence, src_mask=src_mask)\n",
        "        predicted = [sorted_english_vocab['<sos>']]\n",
        "\n",
        "        for i in range(max_len):   \n",
        "            already_translated = torch.LongTensor(predicted).unsqueeze(0).to(device)\n",
        "            dest_mask = model.make_dest_mask(already_translated)\n",
        "            logit, attn_weights = model.decoder(dest_sequences=already_translated, src_encoded=src_encoded,\n",
        "                                      dest_mask=dest_mask, src_mask=src_mask) # [1, dest_seq_len, vocab_size]                      \n",
        "            logp = F.log_softmax(logit[:, -1, :], dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "            \n",
        "            # this part should be removed when model predicts well as it is not necessary\n",
        "            if torch.argmax(logp)==sorted_french_vocab['<pad>']:\n",
        "                logp[sorted_french_vocab['<pad>']] = -float('inf')\n",
        "            #----------------------------------------------------------------------------\n",
        "\n",
        "            predicted_token = torch.argmax(logp)                  \n",
        "            if predicted_token.cpu().item()==sorted_french_vocab['<eos>']: \n",
        "                break\n",
        "            else:\n",
        "              predicted.append(predicted_token.cpu().item())\n",
        "\n",
        "    translation = ' '.join(sorted_french_vocab.lookup_tokens(predicted[1:])) # I generally avoid using vocab functionalities, but this time let it be so\n",
        "    attention = torch.mean(attn_weights.squeeze(0), dim=0)    #you can average across all attention head results\n",
        "    #attention = attn_weights[0][random.choice(range(N_HEADS))]  #randomly choose one of 8 attention head results\n",
        "    vis_translation = visualize_attention(attention, sentence, translation) \n",
        "\n",
        "    if target != None:\n",
        "        smoothing_function = SmoothingFunction()\n",
        "        sentence_bleu_score = sentence_bleu(target, translation, smoothing_function=smoothing_function.method3)\n",
        "        #bleu_score = corpus_bleu(list_of_references, hypotheses, smoothing_function=smoothing_function.method3) #for more than one translation pairs\n",
        "        #f\"INPUT: {sentence}\\nTARGET: {target}\\nOUTPUT: {translation}\\nBLEU: {sentence_bleu_score}\"\n",
        "        evaluation = f\"target: {target}\\nbleu: {sentence_bleu_score}\"  \n",
        "\n",
        "    # in any case you get visualization. If you need real either or: delete vis_translation above and directly return here following:\n",
        "    return print(evaluation) if target!=None else vis_translation  # evaluation if target!=None else visualize_attention(attention, sentence, translation)\n",
        "\n",
        "\n",
        "\n",
        "## ----------initialize and translate or evaluate with single sample-------------\n",
        "transformer = Transformer(\n",
        "    encoder=EncoderLayer(\n",
        "        vocab_size=len(sorted_english_vocab),\n",
        "        max_len=50,\n",
        "        d_model=256,\n",
        "        n_heads=8,\n",
        "        hidden_size=512,\n",
        "        dropout=0.25,\n",
        "        n_layers=2\n",
        "    ),\n",
        "    decoder=DecoderLayer(\n",
        "        vocab_size=len(sorted_french_vocab),\n",
        "        max_len=50,\n",
        "        d_model=256,\n",
        "        n_heads=8,\n",
        "        hidden_size=512,\n",
        "        dropout=0.25,\n",
        "        n_layers=2\n",
        "    ),\n",
        "    src_pad_index= 0, \n",
        "    dest_pad_index= 0, \n",
        ").to(device)\n",
        "\n",
        "transformer.load_state_dict(torch.load('./transformer.pth'))\n",
        "transformer.to(device)\n",
        "\n",
        "#translate_or_evaluate('good morning world')   #to translate\n",
        "translate_or_evaluate(max_len=20)             #to evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#@title evaluate or translate with beam search\n",
        "\n",
        "\n",
        "def find_path(tree):\n",
        "    path = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(path) == 0:\n",
        "            path.append(nodes[0])\n",
        "        else:\n",
        "            parent_id = path[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.id == parent_id:\n",
        "                    path.append(node)\n",
        "    return path\n",
        "\n",
        "def find_best_path(tree):\n",
        "    best = []\n",
        "    for nodes in reversed(tree):\n",
        "        if len(best) == 0:\n",
        "            best.append(nodes[0])\n",
        "        else:\n",
        "            nodes_eos = []\n",
        "            parent_id = best[-1].parent_id\n",
        "            for node in nodes:\n",
        "                if node.eos:\n",
        "                    nodes_eos.append(node)\n",
        "                if node.id == parent_id:\n",
        "                    best.append(node)\n",
        "            if len(nodes_eos) > 0:\n",
        "                candidates = sorted([best[-1], *nodes_eos],\n",
        "                                    key=lambda node: node.logps,\n",
        "                                    reverse=True)\n",
        "                candidate = candidates[0]\n",
        "                if candidate.eos:\n",
        "                    best = [candidate]\n",
        "    return best\n",
        "\n",
        "class Node:\n",
        "    id_ = 0\n",
        "    \n",
        "    def __init__(self, token, states, logp=0., parent=None, eos=False):\n",
        "        self.__id = self.__class__.id_\n",
        "        self.__token = token\n",
        "        self.__states = states\n",
        "        self.__logp = logp\n",
        "        self.__parent_id = None if parent is None else parent.id\n",
        "        self.__eos = eos\n",
        "        self.__level = 0 if parent is None else parent.level + 1\n",
        "        self.__logps = logp if parent is None else parent.logps + logp\n",
        "        self.__class__.id_ += 1\n",
        "        \n",
        "    def __str__(self):\n",
        "        return f'Node[id={self.__id}, ' + \\\n",
        "                    f'index={sorted_english_vocab[self.__token.cpu().item()]}, ' + \\\n",
        "                    f'logp={self.__logp}, ' + \\\n",
        "                    f'logps={self.__logps}, ' + \\\n",
        "                    f'parent_id={self.__parent_id}, ' + \\\n",
        "                    f'level={self.__level}]'\n",
        "                    ### instead of sorted_english_vocab make it general\n",
        "    @property\n",
        "    def token(self):\n",
        "        return self.__token\n",
        "    \n",
        "    @token.setter\n",
        "    def token(self, token):\n",
        "        self.__token = token\n",
        "    \n",
        "    @property\n",
        "    def parent_id(self):\n",
        "        return self.__parent_id\n",
        "    \n",
        "    @parent_id.setter\n",
        "    def parent_id(self, parent_id):\n",
        "        self.__parent_id = parent_id\n",
        "        \n",
        "    @property\n",
        "    def id(self):\n",
        "        return self.__id\n",
        "    \n",
        "    @id.setter\n",
        "    def id(self, id_):\n",
        "        self.__id = id_\n",
        "    \n",
        "    @property\n",
        "    def token(self):\n",
        "        return self.__token\n",
        "    \n",
        "    @token.setter\n",
        "    def token(self, token):\n",
        "        self.__token = token\n",
        "    \n",
        "    @property\n",
        "    def states(self):\n",
        "        return self.__states\n",
        "    \n",
        "    @states.setter\n",
        "    def states(self, states):\n",
        "        self.__states = states\n",
        "      \n",
        "    @property\n",
        "    def eos(self):\n",
        "        return self.__eos\n",
        "    \n",
        "    @eos.setter\n",
        "    def eos(self, eos):\n",
        "        self.__eos = eos\n",
        "    \n",
        "    @property\n",
        "    def logps(self):\n",
        "        return self.__logps\n",
        "    \n",
        "    @logps.setter\n",
        "    def logps(self, logps):\n",
        "        self.__logps = logps\n",
        "        \n",
        "    @property\n",
        "    def level(self):\n",
        "        return self.__level\n",
        "    \n",
        "    @level.setter\n",
        "    def level(self, level):\n",
        "        self.__level = level\n",
        "\n",
        "\n",
        "\n",
        "def visualize_attention(attentions, inputtext, outputtext):\n",
        "  np.random.seed(0)\n",
        "  sns.set_theme()\n",
        "  xticks = inputtext.split(' ')                         #[''] + inputtext.split(' ') + ['<eos>']\n",
        "  outputtext = outputtext.split(' ')\n",
        "  plt.figure(figsize=(16,16))\n",
        "  ax = sns.heatmap(attentions.cpu().detach().numpy(), xticklabels=xticks, yticklabels=outputtext)\n",
        "  ax.set_xticklabels(ax.get_xticklabels(), rotation = 90, fontsize = 9)\n",
        "  ax.set_yticklabels(ax.get_yticklabels(), rotation = 0, fontsize = 9)\n",
        "  print('input: ', inputtext)\n",
        "  print('output: ', ' '.join(outputtext))   \n",
        "\n",
        "\n",
        "def translate_or_evaluate(sentence=None, target=None, model=transformer, beam=2, max_len=5, device=device):\n",
        "    if sentence == None:\n",
        "        sentence, target = test_dataset[random.choice(range(len(test_dataset)))]  #randomly choose one peir from test_dataset\n",
        "   \n",
        "    src_sequence = text_pipeline(sentence, sorted_english_vocab)\n",
        "    translated_sentence, attention_weights, pred_logps = [], [], []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        \n",
        "        src_sequence = torch.LongTensor(src_sequence).unsqueeze(0).to(device)\n",
        "        src_mask = model.make_src_mask(src_sequence)\n",
        "        src_encoded = model.encoder(src_sequences=src_sequence, src_mask=src_mask)\n",
        "        predicted = [[ Node(token=torch.LongTensor( [sorted_english_vocab['<sos>']] ).to(device), states=() ) ]]\n",
        "\n",
        "        for i in range(max_len):   \n",
        "           \n",
        "            next_nodes = []\n",
        "            for node in predicted[-1]:\n",
        "                if node.eos: # Skip eos token\n",
        "                    continue            \n",
        "                already_translated = torch.LongTensor([*map(lambda node: node.token, find_path(predicted))][::-1]).unsqueeze(0).to(device) ##torch.LongTensor(predicted).unsqueeze(0).to(device)\n",
        "                dest_mask = model.make_dest_mask(already_translated)\n",
        "                logit, attn_weights = model.decoder(dest_sequences=already_translated, src_encoded=src_encoded,\n",
        "                                          dest_mask=dest_mask, src_mask=src_mask) # [1, dest_seq_len, vocab_size]                      \n",
        "                logp = F.log_softmax(logit[:, -1, :], dim=1).squeeze(dim=0) # [vocab_size] Get scores                    \n",
        "\n",
        "                topk_logps, topk_tokens = torch.topk(logp, beam) # Get top k tokens & logps\n",
        "                for k in range(beam):\n",
        "                    next_nodes.append(Node(token=topk_tokens[k, None], states=(attn_weights,),\n",
        "                                            logp=topk_logps[k, None].cpu().item(), parent=node,\n",
        "                                            eos=topk_tokens[k].cpu().item() == sorted_english_vocab['<eos>']))\n",
        "\n",
        "            if len(next_nodes) == 0:\n",
        "                    break\n",
        "            next_nodes = sorted(next_nodes, key=lambda node: node.logps, reverse=True)\n",
        "            predicted.append(next_nodes[:beam])\n",
        "\n",
        "        best_path = find_best_path(predicted)[::-1]\n",
        "    \n",
        "    ### translation:\n",
        "    ## translation = ' '.join(sorted_french_vocab.lookup_tokens(predicted[1:])) # I generally avoid using vocab functionalities, but this time let it be so\n",
        "    ## for testing: ##print(sorted_english_vocab.lookup_tokens([best_path[0].token])[0])\n",
        "    pre_translation = [*map(lambda node: sorted_english_vocab.lookup_tokens([node.token])[0], best_path)]\n",
        "    translation = [*filter(lambda word: word not in [sorted_english_vocab['<sos>'], sorted_english_vocab['<eos>']], pre_translation[::-1])]\n",
        "    translation_for_visualization = ' '.join(translation)\n",
        "    \n",
        "    ### probabilities:\n",
        "    pred_logps = sum([*map(lambda node: node.logps, best_path)])  ## if many --> pred_logps.append(sum([*map(lambda node: node.logps, best_path)]))\n",
        "\n",
        "    ### attentions:\n",
        "    ## attention = torch.mean(attn_weights.squeeze(0), dim=0)    #you can average across all attention head results\n",
        "    ## attention = attn_weights[0][random.choice(range(N_HEADS))]  #randomly choose one of 8 attention head results\n",
        "    ## attention_weights = best_path[-1].states[0].cpu().numpy()\n",
        "    attention_weights = best_path[-1].states[0]  ## if many --> attention_weights.append(best_path[-1].states[0].cpu().numpy())\n",
        "    attention = attention_weights[0][random.choice(range(N_HEADS))]\n",
        "\n",
        "    ### visualization\n",
        "    vis_translation = visualize_attention(attention, sentence, translation_for_visualization) \n",
        "\n",
        "    if target != None:\n",
        "        smoothing_function = SmoothingFunction()\n",
        "        sentence_bleu_score = sentence_bleu(target, translation, smoothing_function=smoothing_function.method3)\n",
        "        #bleu_score = corpus_bleu(list_of_references, hypotheses, smoothing_function=smoothing_function.method3) #for more than one translation pairs\n",
        "        #f\"INPUT: {sentence}\\nTARGET: {target}\\nOUTPUT: {translation}\\nBLEU: {sentence_bleu_score}\"\n",
        "        evaluation = f\"target: {target}\\nbleu: {sentence_bleu_score}\"  \n",
        "\n",
        "    # in any case you get visualization. If you need real either or: delete vis_translation above and directly return here following:\n",
        "    return print(evaluation) if target!=None else vis_translation  # evaluation if target!=None else visualize_attention(attention, sentence, translation)\n",
        "\n",
        "\n",
        "## ----------initialize and translate or evaluate with single sample-------------\n",
        "transformer = Transformer(\n",
        "    encoder=EncoderLayer(\n",
        "        vocab_size=len(sorted_english_vocab),\n",
        "        max_len=50,\n",
        "        d_model=256,\n",
        "        n_heads=8,\n",
        "        hidden_size=512,\n",
        "        dropout=0.25,\n",
        "        n_layers=2\n",
        "    ),\n",
        "    decoder=DecoderLayer(\n",
        "        vocab_size=len(sorted_french_vocab),\n",
        "        max_len=50,\n",
        "        d_model=256,\n",
        "        n_heads=8,\n",
        "        hidden_size=512,\n",
        "        dropout=0.25,\n",
        "        n_layers=2\n",
        "    ),\n",
        "    src_pad_index= 0, \n",
        "    dest_pad_index= 0, \n",
        ").to(device)\n",
        "\n",
        "transformer.load_state_dict(torch.load('./transformer.pth'))\n",
        "transformer.to(device)\n",
        "\n",
        "\n",
        "#translate_or_evaluate('good morning world', beam=3)   #to translate\n",
        "translate_or_evaluate(beam=3, max_len=20)              #to evaluate"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
