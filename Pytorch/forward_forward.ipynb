{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yq34u0ar4r_F"
      },
      "source": [
        "Have a look at this as well: \n",
        "\n",
        "https://github.com/Trel725/forward-forward/blob/main/forward-forward.ipynb\n",
        "\n",
        "https://github.com/keras-team/keras-io/blob/master/examples/vision/forwardforward.py\n",
        "\n",
        "https://github.com/ghadialhajj/FF_unsupervised"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Evx9RS-LlsVm"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision.transforms import Compose, Lambda, Normalize, ToTensor\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "2YzoxFEVjx7v"
      },
      "outputs": [],
      "source": [
        "def load_data(train_batch_size=50000, test_batch_size=10000):\n",
        "\n",
        "    transform = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize((0.1307,), (0.3081,)),\n",
        "        Lambda(lambda x: torch.flatten(x))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        MNIST('./', train=True,\n",
        "              download=True,\n",
        "              transform=transform),\n",
        "        batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        MNIST('./', train=False,\n",
        "              download=True,\n",
        "              transform=transform),\n",
        "        batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def add_label(x, y):\n",
        "    \"\"\"changes first 10 pixels with one-hot encoding of the label 0-9\"\"\"\n",
        "    x_ = x.clone()\n",
        "    x_[:, :10] *= 0.0\n",
        "    x_[range(x.shape[0]), y] = x.max()\n",
        "    return x_\n",
        "\n",
        "    \n",
        "def make_y_negative(y):\n",
        "    y_neg = y.clone()\n",
        "    for idx, y_samp in enumerate(y):\n",
        "        allowed_indices = list(range(10))\n",
        "        allowed_indices.remove(y_samp.item())\n",
        "        y_neg[idx] = torch.tensor(allowed_indices)[\n",
        "            torch.randint(len(allowed_indices), size=(1,))\n",
        "        ].item()\n",
        "    return y_neg.to(device)\n",
        "\n",
        "\n",
        "\n",
        "class ForwardLayer(nn.Linear):\n",
        "    ''' Implements just single layer forward and 'backward' pass\n",
        "    '''\n",
        "    def __init__(self, in_features, out_features,\n",
        "                 bias=True, device=None, dtype=None):\n",
        "        super().__init__(in_features, out_features, bias, device, dtype)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.opt = Adam(self.parameters(), lr=0.03)\n",
        "        self.threshold = 2.0\n",
        "        self.num_epochs = 1000\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n",
        "        return self.relu(\n",
        "            torch.mm(x_direction, self.weight.T) +\n",
        "            self.bias.unsqueeze(0))\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        for i in tqdm(range(self.num_epochs)):\n",
        "            g_pos = self.forward(x_pos).pow(2).mean(1)\n",
        "            g_neg = self.forward(x_neg).pow(2).mean(1)\n",
        "            loss = torch.log(1 + torch.exp(torch.cat([\n",
        "                -g_pos + self.threshold,\n",
        "                g_neg - self.threshold]))).mean()\n",
        "            self.opt.zero_grad()\n",
        "            loss.backward()\n",
        "            self.opt.step()\n",
        "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
        "\n",
        "\n",
        "class ForwardNet(torch.nn.Module):\n",
        "    ''' implements goodness evaluation per layer\n",
        "    '''\n",
        "    def __init__(self, dims):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for d in range(len(dims) - 1):\n",
        "            self.layers += [ForwardLayer(dims[d], dims[d + 1]).to(device)]\n",
        "\n",
        "    def predict(self, x):\n",
        "        goodness_per_label = []\n",
        "        for label in range(10):\n",
        "            h = add_label(x, label)\n",
        "            goodness = []\n",
        "            for layer in self.layers:\n",
        "                h = layer(h)\n",
        "                goodness += [h.pow(2).mean(1)]\n",
        "            goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
        "        goodness_per_label = torch.cat(goodness_per_label, 1)\n",
        "        return goodness_per_label.argmax(1)\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        h_pos, h_neg = x_pos, x_neg\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            print('training layer', i, '...')\n",
        "            h_pos, h_neg = layer.train(h_pos, h_neg)\n",
        "\n",
        "    \n",
        "def sample_show(data, name='', idx=0):\n",
        "    reshaped = data[idx].cpu().reshape(28, 28)\n",
        "    plt.figure(figsize = (4, 4))\n",
        "    plt.title(name)\n",
        "    plt.imshow(reshaped, cmap=\"gray\")\n",
        "    plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RuEgZcZ5lj_2"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(1234)\n",
        "load_train, load_test = load_data()\n",
        "\n",
        "net = ForwardNet([784, 500, 500])\n",
        "x, y = next(iter(load_train))\n",
        "x, y = x.to(device), y.to(device)\n",
        "x_pos = add_label(x, y)\n",
        "                           ### rnd = torch.randperm(x.size(0))\n",
        "y_neg = make_y_negative(y) ### y[rnd] \n",
        "x_neg = add_label(x, y_neg)\n",
        "\n",
        "for data, name in zip([x, x_pos, x_neg], ['orig', 'pos', 'neg']):\n",
        "    sample_show(data, name)\n",
        "\n",
        "net.train(x_pos, x_neg)\n",
        "\n",
        "print('train error:', 1.0 - net.predict(x).eq(y).float().mean().item())\n",
        "\n",
        "x_test, y_test = next(iter(load_test))\n",
        "x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "print('test error:', 1.0 - net.predict(x_test).eq(y_test).float().mean().item())"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
