{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Have a look at this as well: \n",
        "\n",
        "https://github.com/Trel725/forward-forward/blob/main/forward-forward.ipynb\n",
        "\n",
        "https://github.com/keras-team/keras-io/blob/master/examples/vision/forwardforward.py\n",
        "\n",
        "https://github.com/ghadialhajj/FF_unsupervised"
      ],
      "metadata": {
        "id": "Yq34u0ar4r_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.signal import convolve2d\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from torch import tensor, Tensor\n",
        "\n",
        "import torchvision\n",
        "from torchvision.transforms import Compose, Lambda, Normalize, ToTensor\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "Evx9RS-LlsVm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Supervised Version:"
      ],
      "metadata": {
        "id": "Dp9BYMIMOv6z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YzoxFEVjx7v"
      },
      "outputs": [],
      "source": [
        "def load_data(train_batch_size=50000, test_batch_size=10000):\n",
        "\n",
        "    transform = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize((0.1307,), (0.3081,)),\n",
        "        Lambda(lambda x: torch.flatten(x))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        MNIST('./', train=True,\n",
        "              download=True,\n",
        "              transform=transform),\n",
        "        batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        MNIST('./', train=False,\n",
        "              download=True,\n",
        "              transform=transform),\n",
        "        batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader\n",
        "\n",
        "\n",
        "def add_label(x, y):\n",
        "    \"\"\"changes first 10 pixels with one-hot encoding of the label 0-9\"\"\"\n",
        "    x_ = x.clone()\n",
        "    x_[:, :10] *= 0.0\n",
        "    x_[range(x.shape[0]), y] = x.max()\n",
        "    return x_\n",
        "\n",
        "    \n",
        "def make_y_negative(y):\n",
        "    y_neg = y.clone()\n",
        "    for idx, y_samp in enumerate(y):\n",
        "        allowed_indices = list(range(10))\n",
        "        allowed_indices.remove(y_samp.item())\n",
        "        y_neg[idx] = torch.tensor(allowed_indices)[torch.randint(len(allowed_indices), size=(1,))].item()\n",
        "    return y_neg.to(device)\n",
        "\n",
        "\n",
        "class ForwardLayer(nn.Linear):\n",
        "    ''' Implements just single layer forward and 'backward' pass\n",
        "    '''\n",
        "    def __init__(self, in_features, out_features,\n",
        "                 bias=True, device=None, dtype=None):\n",
        "        super().__init__(in_features, out_features, bias, device, dtype)\n",
        "        self.relu = torch.nn.ReLU()\n",
        "        self.opt = Adam(self.parameters(), lr=0.03)\n",
        "        self.threshold = 2.0\n",
        "        self.num_epochs = 1000\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_direction = x / (x.norm(2, 1, keepdim=True) + 1e-4)\n",
        "        return self.relu(\n",
        "            torch.mm(x_direction, self.weight.T) +\n",
        "            self.bias.unsqueeze(0))\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        for i in tqdm(range(self.num_epochs)):\n",
        "            g_pos = self.forward(x_pos).pow(2).mean(1)\n",
        "            g_neg = self.forward(x_neg).pow(2).mean(1)\n",
        "            loss = torch.log(1 + torch.exp(torch.cat([-g_pos + self.threshold, g_neg - self.threshold]))).mean()\n",
        "            self.opt.zero_grad()\n",
        "            loss.backward()\n",
        "            self.opt.step()\n",
        "        return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n",
        "\n",
        "\n",
        "class ForwardNet(torch.nn.Module):\n",
        "    ''' implements goodness evaluation per layer\n",
        "    '''\n",
        "    def __init__(self, dims):\n",
        "        super().__init__()\n",
        "        self.layers = []\n",
        "        for d in range(len(dims) - 1):\n",
        "            self.layers += [ForwardLayer(dims[d], dims[d + 1]).to(device)]\n",
        "\n",
        "    def predict(self, x):\n",
        "        goodness_per_label = []\n",
        "        for label in range(10):\n",
        "            h = add_label(x, label)\n",
        "            goodness = []\n",
        "            for layer in self.layers:\n",
        "                h = layer(h)\n",
        "                goodness += [h.pow(2).mean(1)]\n",
        "            goodness_per_label += [sum(goodness).unsqueeze(1)]\n",
        "        goodness_per_label = torch.cat(goodness_per_label, 1)\n",
        "        return goodness_per_label.argmax(1)\n",
        "\n",
        "    def train(self, x_pos, x_neg):\n",
        "        h_pos, h_neg = x_pos, x_neg\n",
        "        for i, layer in enumerate(self.layers):\n",
        "            print('training layer', i, '...')\n",
        "            h_pos, h_neg = layer.train(h_pos, h_neg)\n",
        "\n",
        "    \n",
        "def sample_show(data, name='', idx=0):\n",
        "    reshaped = data[idx].cpu().reshape(28, 28)\n",
        "    plt.figure(figsize = (4, 4))\n",
        "    plt.title(name)\n",
        "    plt.imshow(reshaped, cmap=\"gray\")\n",
        "    plt.show()\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(1234)\n",
        "load_train, load_test = load_data()\n",
        "\n",
        "net = ForwardNet([784, 500, 500])\n",
        "x, y = next(iter(load_train))\n",
        "x, y = x.to(device), y.to(device)\n",
        "x_pos = add_label(x, y)\n",
        "                           ### rnd = torch.randperm(x.size(0))\n",
        "y_neg = make_y_negative(y) ### y[rnd] \n",
        "x_neg = add_label(x, y_neg)\n",
        "\n",
        "for data, name in zip([x, x_pos, x_neg], ['orig', 'pos', 'neg']):\n",
        "    sample_show(data, name)\n",
        "\n",
        "net.train(x_pos, x_neg)\n",
        "\n",
        "print('train error:', 1.0 - net.predict(x).eq(y).float().mean().item())\n",
        "\n",
        "x_test, y_test = next(iter(load_test))\n",
        "x_test, y_test = x_test.to(device), y_test.to(device)\n",
        "\n",
        "print('test error:', 1.0 - net.predict(x_test).eq(y_test).float().mean().item())"
      ],
      "metadata": {
        "id": "RuEgZcZ5lj_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsupervised Version"
      ],
      "metadata": {
        "id": "6v6Poc6CNccO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_mask(shape, iterations: int = 10):\n",
        "    blur_filter_1 = np.array(((0, 0, 0), (0.25, 0.5, 0.25), (0, 0, 0)))\n",
        "    blur_filter_2 = blur_filter_1.T\n",
        "    image = np.random.randint(0, 2, size=shape)\n",
        "    for i in range(iterations):\n",
        "        image = np.abs(convolve2d(image, blur_filter_1, mode='same') / blur_filter_1.sum())\n",
        "        image = np.abs(convolve2d(image, blur_filter_2, mode='same') / blur_filter_2.sum())\n",
        "    mask = np.round(image).astype(np.uint8)\n",
        "    return tensor(mask)\n",
        "\n",
        "\n",
        "def create_negative_image(image_1: Tensor, image_2: Tensor):\n",
        "    assert image_1.shape == image_2.shape, \"Incompatible images and mask shapes.\"\n",
        "    mask = create_mask((image_1.shape[0], image_1.shape[1]))\n",
        "    image_1 = torch.mul(image_1, mask)\n",
        "    image_2 = torch.mul(image_2, 1 - mask)\n",
        "    return torch.add(image_1, image_2)\n",
        "\n",
        "\n",
        "def create_negative_batch(images: Tensor):\n",
        "    neg_imgs = []\n",
        "    batch_size = images.shape[0]\n",
        "    for _ in range(batch_size):\n",
        "        idx1, idx2 = np.random.randint(batch_size, size=2)\n",
        "        neg_imgs.append(create_negative_image(images[idx1].squeeze(), images[idx2].squeeze()))\n",
        "    return torch.unsqueeze(torch.stack(neg_imgs), dim=1)\n",
        "\n",
        "\n",
        "def prepare_data():\n",
        "    transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "    train_mnist_dataset = torchvision.datasets.MNIST(root=\"./\", train=True, transform=transform,\n",
        "                                                     download=False)\n",
        "    n_train_samples = len(train_mnist_dataset)\n",
        "    test_mnist_dataset = torchvision.datasets.MNIST(root=\"./\", train=False, transform=transform,\n",
        "                                                    download=False)\n",
        "    if not os.path.exists(\"negatives.pt\"):\n",
        "        random_pairs = np.random.randint(n_train_samples, size=[n_train_samples, 2])\n",
        "        random_pairs = [(row[0], row[1]) for row in random_pairs]\n",
        "\n",
        "        transformed_dataset = [\n",
        "            create_negative_image(train_mnist_dataset[pair[0]][0].squeeze(), train_mnist_dataset[pair[1]][0].squeeze())\n",
        "            for pair in tqdm(random_pairs)]\n",
        "\n",
        "        torch.save(transformed_dataset, 'negatives.pt')\n"
      ],
      "metadata": {
        "id": "Mb-2sM_ANrbU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ForwardLayer_Unsupervised(nn.Linear):\n",
        "    def __init__(self, in_features: int, out_features: int, n_epochs: int, bias: bool, device, threshold=2.0):\n",
        "        super().__init__(in_features, out_features, bias=bias)\n",
        "        self.n_epochs = n_epochs\n",
        "        self.opt = torch.optim.Adam(self.parameters())\n",
        "        self.threshold = threshold\n",
        "        self.to(device)\n",
        "        self.ln_layer = nn.LayerNorm(normalized_shape=[1, out_features]).to(device)\n",
        "\n",
        "    def ff_train(self, pos_acts, neg_acts):\n",
        "        self.opt.zero_grad()\n",
        "        pos_goodness = -torch.sum(torch.pow(pos_acts, 2)) + self.threshold\n",
        "        neg_goodness = torch.sum(torch.pow(neg_acts, 2)) - self.threshold\n",
        "        goodness = torch.add(pos_goodness, neg_goodness)\n",
        "        goodness.backward()\n",
        "        self.opt.step()\n",
        "\n",
        "    def forward(self, input):\n",
        "        input = super().forward(input)\n",
        "        input = self.ln_layer(input.detach())\n",
        "        return input\n",
        "\n",
        "\n",
        "class ForwardNet_Unsupervised(nn.Module):\n",
        "    def __init__(self, n_layers: int = 4, n_neurons=2000, input_size: int = 28 * 28, n_epochs: int = 100,\n",
        "                 bias: bool = True, n_classes: int = 10, n_hid_to_log: int = 3, device=device):\n",
        "        super().__init__()\n",
        "        self.n_hid_to_log = n_hid_to_log\n",
        "        self.n_epochs = n_epochs\n",
        "        self.device = device\n",
        "\n",
        "        ff_layers = [\n",
        "            ForwardLayer_Unsupervised(in_features=input_size if idx == 0 else n_neurons,\n",
        "                     out_features=n_neurons,\n",
        "                     n_epochs=n_epochs,\n",
        "                     bias=bias,\n",
        "                     device=device) for idx in range(n_layers)]\n",
        "\n",
        "        self.ff_layers = ff_layers\n",
        "        self.last_layer = nn.Linear(in_features=n_neurons * n_hid_to_log, out_features=n_classes, bias=bias)\n",
        "        self.to(device)\n",
        "        self.opt = torch.optim.Adam(self.last_layer.parameters())\n",
        "        self.loss = torch.nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "    def train_ff_layers(self, pos_dataloader, neg_dataloader):\n",
        "        outer_tqdm = tqdm(range(self.n_epochs), desc=\"Training FF Layers\", position=0)\n",
        "        for epoch in outer_tqdm:\n",
        "            inner_tqdm = tqdm(zip(pos_dataloader, neg_dataloader), desc=f\"Training FF Layers | Epoch {epoch}\",\n",
        "                              leave=False, position=1)\n",
        "            for pos_data, neg_imgs in inner_tqdm:\n",
        "                pos_imgs, _ = pos_data\n",
        "                pos_acts = torch.reshape(pos_imgs, (pos_imgs.shape[0], 1, -1)).to(self.device)\n",
        "                neg_acts = torch.reshape(neg_imgs, (neg_imgs.shape[0], 1, -1)).to(self.device)\n",
        "\n",
        "                for idx, layer in enumerate(self.ff_layers):\n",
        "                    pos_acts = layer(pos_acts)\n",
        "                    neg_acts = layer(neg_acts)\n",
        "                    layer.ff_train(pos_acts, neg_acts)\n",
        "\n",
        "    def train_last_layer(self, dataloader: DataLoader):\n",
        "        num_examples = len(dataloader)\n",
        "        outer_tqdm = tqdm(range(self.n_epochs), desc=\"Training Last Layer\", position=0)\n",
        "        loss_list = []\n",
        "        for epoch in outer_tqdm:\n",
        "            epoch_loss = 0\n",
        "            inner_tqdm = tqdm(dataloader, desc=f\"Training Last Layer | Epoch {epoch}\", leave=False, position=1)\n",
        "            for images, labels in inner_tqdm:\n",
        "                images = images.to(self.device)\n",
        "                labels = labels.to(self.device)\n",
        "                self.opt.zero_grad()\n",
        "                preds = self(images)\n",
        "                loss = self.loss(preds, labels)\n",
        "                epoch_loss += loss\n",
        "                loss.backward()\n",
        "                self.opt.step()\n",
        "            loss_list.append(epoch_loss / num_examples)\n",
        "            # Update progress bar with current loss\n",
        "        return [l.detach().cpu().numpy() for l in loss_list]\n",
        "\n",
        "    def forward(self, image: torch.Tensor):\n",
        "        image = image.to(self.device)\n",
        "        image = torch.reshape(image, (image.shape[0], 1, -1))\n",
        "        concat_output = []\n",
        "        for idx, layer in enumerate(self.ff_layers):\n",
        "            image = layer(image)\n",
        "            if idx > len(self.ff_layers) - self.n_hid_to_log - 1:\n",
        "                concat_output.append(image)\n",
        "        concat_output = torch.concat(concat_output, 2)\n",
        "        logits = self.last_layer(concat_output)\n",
        "        return logits.squeeze()\n",
        "\n",
        "    def evaluate(self, dataloader: DataLoader, dataset_type: str = \"train\"):\n",
        "        self.eval()\n",
        "        inner_tqdm = tqdm(dataloader, desc=f\"Evaluating model\", leave=False, position=1)\n",
        "        all_labels = []\n",
        "        all_preds = []\n",
        "        for images, labels in inner_tqdm:\n",
        "            images = images.to(self.device)\n",
        "            labels = labels.to(self.device)\n",
        "            preds = self(images)\n",
        "            preds = torch.argmax(preds, 1)\n",
        "            all_labels.append(labels.detach().cpu())\n",
        "            all_preds.append(preds.detach().cpu())\n",
        "        all_labels = torch.concat(all_labels, 0).numpy()\n",
        "        all_preds = torch.concat(all_preds, 0).numpy()\n",
        "        acc = accuracy_score(all_labels, all_preds)\n",
        "        metrics_dict = dict(accuracy_score=acc)\n",
        "        print(f\"{dataset_type} dataset scores: \", \"\\n\".join([f\"{key}: {value}\" for key, value in metrics_dict.items()]))\n",
        "\n",
        "\n",
        "def train(model: ForwardNet_Unsupervised, pos_dataloader: DataLoader, neg_dataloader: DataLoader):\n",
        "    model.train()\n",
        "    model.train_ff_layers(pos_dataloader, neg_dataloader)\n",
        "    return model.train_last_layer(pos_dataloader)\n"
      ],
      "metadata": {
        "id": "J6Gn2w7DSoG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
        "pos_dataset = torchvision.datasets.MNIST(root='./', download=False, transform=transform, train=True)\n",
        "pos_dataloader = DataLoader(pos_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "prepare_data()\n",
        "neg_dataset = torch.load('negatives.pt')\n",
        "neg_dataloader = DataLoader(neg_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "test_dataset = torchvision.datasets.MNIST(root='./', train=False, download=False, transform=transform)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=64, shuffle=True, num_workers=4)\n",
        "\n",
        "u_ff = ForwardNet_Unsupervised(device=device, n_epochs=2)\n",
        "loss = train(u_ff, pos_dataloader, neg_dataloader)\n",
        "u_ff.evaluate(pos_dataloader, dataset_type=\"Train\")\n",
        "u_ff.evaluate(test_dataloader, dataset_type=\"Test\")\n",
        "\n",
        "# fig = plt.figure()\n",
        "# plt.plot(list(range(len(loss))), loss)\n",
        "# plt.xlabel(\"Epochs\")\n",
        "# plt.ylabel(\"Loss\")\n",
        "# plt.title(\"Loss Plot\")\n",
        "# ## plt.savefig(\"Loss Plot.png\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "vwR0KDDrgV9q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}