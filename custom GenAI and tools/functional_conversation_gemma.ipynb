{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "y-IVZ1D-YKuK",
      "metadata": {
        "id": "y-IVZ1D-YKuK"
      },
      "source": [
        "This notebook depends on another notebook that shows how we finetuned gemma model for function calling `function_calling_finetune_gemma.ipynb`. [notebook](https://github.com/VladimerKhasia/ML-in-Notebooks/blob/main/custom%20GenAI%20and%20tools/function_calling_finetune_gemma.ipynb)\n",
        "\n",
        "Reference to used [training data](https://huggingface.co/datasets/NickyNicky/function-calling_chatml_gemma_v1).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "LCNre7Kh7mUi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LCNre7Kh7mUi",
        "outputId": "9d223559-49d4-45fe-bd1d-51c6060baa19"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "## This notebook depend on another notebook where we finetuned gemma model for function calling\n",
        "## and saved it on the mounted google drive at \"./gdrive/MyDrive/fine-tuned-gemma/model\"\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')   # run it again if it fails first time - yes that actualy happens in the begginging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "cFfWP5bs-nyc",
      "metadata": {
        "id": "cFfWP5bs-nyc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = userdata.get('LANGCHAIN_API_KEY')\n",
        "os.environ[\"HF_TOKEN\"] = userdata.get('HF_TOKEN')\n",
        "\n",
        "# from dotenv import load_dotenv, find_dotenv\n",
        "# _ = load_dotenv(find_dotenv()) # read local .env file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "CnKk-DDG-1TD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnKk-DDG-1TD",
        "outputId": "89f3d1e5-7db6-4741-d64e-4feacc7769b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.6/302.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "## pay attention to langchain and pydantic version compatibility: https://python.langchain.com/v0.1/docs/guides/development/pydantic_compatibility\n",
        "!pip install -qU transformers langchain>=0.0.267 langchain_community bs4\n",
        "!pip install -qU accelerate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "EBPOqwwrHcp8",
      "metadata": {
        "id": "EBPOqwwrHcp8"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    AutoConfig,\n",
        "    BitsAndBytesConfig,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    pipeline,\n",
        "    GenerationConfig,\n",
        "    TextIteratorStreamer,\n",
        "    StoppingCriteria,\n",
        "    StoppingCriteriaList,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "OE63E1gb_C1V",
      "metadata": {
        "id": "OE63E1gb_C1V"
      },
      "source": [
        "# Gemma model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "AF16vCbw-qr6",
      "metadata": {
        "id": "AF16vCbw-qr6"
      },
      "outputs": [],
      "source": [
        "model_id = \"google/gemma-1.1-2b-it\"\n",
        "path_to_finetuned = \"./gdrive/MyDrive/fine-tuned-gemma/model\"\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "WKMXy4i-_OAS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "a24b1e19036f4523b113f4f8ae881636",
            "5432d95694aa477da6463ae357b4d033",
            "5d3311d7545349e593a755e9e0fec8d4",
            "66aaf69fac98449f950a7320108d0a51",
            "28040d4a229c4c9d8ef8dce1088bce47",
            "9e952ce43976401f8e830d67fc55e1f5",
            "9dc4cf1bbbec43a384a461b25ad140b5",
            "845915b167f04f54b3572f5487ecc55c",
            "a3d56b972a4940338e03ce528280adb7",
            "9761496178f94730b236bba528226c8d",
            "3938de22cac449068a1d00637019cbb9",
            "5ffa4cca3b5f4067845d3beee221ef85",
            "65f4a5cf9ffb4e82abfa42119f679111",
            "426510d855534f6d81d934a709a63aff",
            "9a779fe6d32b40cc906a72b835adb58c",
            "656bf197ad1e4d0ab754195ce2018844",
            "c91de0df3eec4b43a051b3fc554a7497",
            "fc4b4ac0d0924f179551a880e0c2bc8c",
            "b39c2bc74eba4ed7ae5171ff9533fbc3",
            "2ee310f0d77244dabf75b41ade9473f5",
            "0933c0b2905747e0b9b771942f903c2f",
            "4171cc45da1247a4a45bac0d31448d58",
            "f5477c5669654acc84ed095c511be908",
            "54464083b17e4893abddcec08268fba8",
            "4c020b6eea634d68866f4956b472e354",
            "e9ecdbafc1b9403982ba2e33bc933126",
            "75510d21c9c34740ba8fcafce1b4394d",
            "83c5da0792474524a00d2d64ea323078",
            "aa69d6e295aa4192a0c98c12e7910f14",
            "1432456dbac149bf9199cdfd99788fd9",
            "b87cf4fd1f504787a69929be42f0d45a",
            "235dd00d5aff4fdb88047d3d2a7f6ab7",
            "4ea7ce1455474e0b8ea4caf1d80ff332",
            "ecdda8c95f3542da8d70eca4ba77c75b",
            "241a9d2ca1e4472b929aad632701643a",
            "b5ec91fc973148c78e645f7feb743c6e",
            "86db5583690b4a02b099cf96d42ac174",
            "a45bf42393224c21a884289a51add9e3",
            "7e8e37a3d4394729bfc70886c9f69702",
            "709954020b544744bb742be40bf78711",
            "0290fa7a2fe24bdaab6e470bbc55163a",
            "cd6c738d0efb4112868590fa5d9bf5d3",
            "4979ec6811734a9bb6970dddd2f9984f",
            "78e38ffe259d40d1aff135fd9ac8371b",
            "d6199a631df34aaa949ef70847da87eb",
            "93c2547bcada4dd684cb3eb29a6b50ab",
            "2eee47b4d0474034b2e8309902475eea",
            "88ac7b5630ab40dab061912f7308310d",
            "f1823978509b48ba9bc40fd0c973055a",
            "cfbb42006293437984dd6aa357a1cd0c",
            "919194c2af574adb881843370ee6f20b",
            "a04743b9c5974046841a13e2a8b1dc03",
            "0662b61903f642118339d935fe96600c",
            "af92b247fda54b159b0a28a5f24d2fcf",
            "3424c8f510b3492fabf055a8894c484f"
          ]
        },
        "id": "WKMXy4i-_OAS",
        "outputId": "7b286e31-d970-4282-d095-5ce8d9985a54"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a24b1e19036f4523b113f4f8ae881636",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/34.2k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ffa4cca3b5f4067845d3beee221ef85",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/4.24M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f5477c5669654acc84ed095c511be908",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.5M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ecdda8c95f3542da8d70eca4ba77c75b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/636 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d6199a631df34aaa949ef70847da87eb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, add_eos_token=True)\n",
        "model = AutoModelForCausalLM.from_pretrained(path_to_finetuned,\n",
        "                                             device_map=\"auto\" if device!=torch.device('cpu') else None,\n",
        "                                            #  torch_dtype=torch.bfloat16\n",
        "                                            )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bgwHvqEaXhao",
      "metadata": {
        "id": "bgwHvqEaXhao"
      },
      "source": [
        "This is how to use langchain ChatModel. It is possible to do the same with just gemma and huggingface with internal custom memory state and [here is the example of that](https://github.com/VladimerKhasia/fastapi_X/blob/main/app/ai_model/chat_service.py)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "gdBEdXh3BhTl",
      "metadata": {
        "id": "gdBEdXh3BhTl"
      },
      "outputs": [],
      "source": [
        "from typing import Any, AsyncIterator, Dict, Iterator, List, Optional\n",
        "\n",
        "from langchain_core.callbacks import (\n",
        "    AsyncCallbackManagerForLLMRun,\n",
        "    CallbackManagerForLLMRun,\n",
        ")\n",
        "from langchain_core.messages.ai import AIMessage\n",
        "from langchain_core.language_models import BaseChatModel, SimpleChatModel\n",
        "from langchain_core.messages import AIMessageChunk, BaseMessage, HumanMessage\n",
        "from langchain_core.outputs import ChatGeneration, ChatGenerationChunk, ChatResult\n",
        "from langchain_core.runnables import run_in_executor\n",
        "from transformers import pipeline\n",
        "import re\n",
        "import json\n",
        "from typing import Any\n",
        "\n",
        "\n",
        "class ListOfTokensStoppingCriteria(StoppingCriteria):\n",
        "    \"\"\"\n",
        "    Class to define a stopping criterion based on a list of specific tokens.\n",
        "    \"\"\"\n",
        "    def __init__(self, tokenizer, stop_tokens):\n",
        "        self.tokenizer = tokenizer\n",
        "        # Encode each stop token and store their IDs in a list\n",
        "        self.stop_token_ids_list = [tokenizer.encode(stop_token, add_special_tokens=False) for stop_token in stop_tokens]\n",
        "\n",
        "    def __call__(self, input_ids, scores, **kwargs):\n",
        "        # Check if the last tokens generated match any of the stop token sequences\n",
        "        for stop_token_ids in self.stop_token_ids_list:\n",
        "            len_stop_tokens = len(stop_token_ids)\n",
        "            if len(input_ids[0]) >= len_stop_tokens:\n",
        "                if input_ids[0, -len_stop_tokens:].tolist() == stop_token_ids:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "# Define a list of stop tokens\n",
        "stop_tokens = [\"<end_of_turn>\"]\n",
        "\n",
        "# Initialize the stopping criteria with the tokenizer and the list of stop tokens\n",
        "stopping_criteria = ListOfTokensStoppingCriteria(tokenizer, stop_tokens)\n",
        "\n",
        "# Add the custom stopping criteria to a StoppingCriteriaList\n",
        "stopping_criteria_list = StoppingCriteriaList([stopping_criteria])\n",
        "\n",
        "\n",
        "\n",
        "class GemmaChatModel(BaseChatModel):\n",
        "    \"\"\"\n",
        "    A custom chat model powered by Gemma from Hugging Face, designed to be informative, comprehensive, and engaging.\n",
        "    See the custom model guide here: https://python.langchain.com/docs/modules/model_io/chat/custom_chat_model/\n",
        "    \"\"\"\n",
        "\n",
        "    model_name: str = \"gemma_chat_model\"  # Replace with the actual Gemma model name\n",
        "    task: str = \"conversational\"  # Task for the pipeline (conversational or summarization)\n",
        "    #temperature = 0.0\n",
        "    #n: int = 1500\n",
        "    model : Any = None\n",
        "    tokenizer : Any = None\n",
        "    generation_config = GenerationConfig(\n",
        "              max_new_tokens = 1500,\n",
        "              temperature=0.20,\n",
        "              # top_p=0.55,\n",
        "              top_k=3, #50,\n",
        "              repetition_penalty=1.,\n",
        "              do_sample=True,)\n",
        "    stopping_criteria_list = stopping_criteria_list\n",
        "\n",
        "    def _generate(\n",
        "        self,\n",
        "        messages: List[BaseMessage],\n",
        "        stop: Optional[List[str]] = None,\n",
        "        run_manager: Optional[CallbackManagerForLLMRun] = None,\n",
        "        **kwargs: Any,\n",
        "    ) -> ChatResult:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            messages: The list of prompt messages.\n",
        "            stop: Optional list of stop tokens.\n",
        "            run_manager: Optional callback manager.\n",
        "            **kwargs: Additional keyword arguments.\n",
        "\n",
        "        Returns:\n",
        "            A ChatResult object containing the generated response.\n",
        "        \"\"\"\n",
        "\n",
        "        prompt = messages[-1].content #[: self.n]\n",
        "        input_ids = self.tokenizer.encode(prompt,\n",
        "                          return_tensors=\"pt\",\n",
        "                          add_special_tokens=False).to(self.model.device) ##self.tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "        outputs = self.model.generate(generation_config=self.generation_config,\n",
        "                         input_ids=input_ids,\n",
        "                         stopping_criteria=self.stopping_criteria_list,) #self.model.generate(**input_ids, max_new_tokens=self.n)  # , temperature=self.temperature\n",
        "        text = self.tokenizer.decode(outputs[0], skip_special_tokens=False)  #self.tokenizer.decode(outputs[0])\n",
        "        #text = \" \".join(text.split(\"\\n\"))\n",
        "\n",
        "        start_index, end_index = text.find(\"\"), text.rfind(\"\")\n",
        "        response = text[start_index+len(\"\"):end_index].strip()\n",
        "\n",
        "        message = AIMessage(content=response, additional_kwargs={}, response_metadata={\"time_in_seconds\": 3})\n",
        "        return ChatResult(generations=[ChatGeneration(message=message)])\n",
        "\n",
        "    @property\n",
        "    def _llm_type(self) -> str:\n",
        "        \"\"\"\n",
        "        Returns the type of language model used: \"gemma_chat_model\".\n",
        "        \"\"\"\n",
        "        return \"gemma_chat_model\"\n",
        "\n",
        "    @property\n",
        "    def _identifying_params(self) -> Dict[str, Any]:\n",
        "        \"\"\"\n",
        "        Returns a dictionary of identifying parameters for LangChain callbacks.\n",
        "        \"\"\"\n",
        "        return {\"model_name\": self.model_name, \"task\": self.task}\n",
        "\n",
        "llm = GemmaChatModel()\n",
        "llm.model = model               # This is simple but not production level way of doing things. It's just for avoiding colab run out of memory on CPU\n",
        "llm.tokenizer = tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79a3f6a4-8348-4cd6-a336-10ecb9cfaaa3",
      "metadata": {
        "id": "79a3f6a4-8348-4cd6-a336-10ecb9cfaaa3"
      },
      "source": [
        "# Conversational agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "gHszjKz3mAZY",
      "metadata": {
        "id": "gHszjKz3mAZY"
      },
      "outputs": [],
      "source": [
        "from typing import Any, List, Mapping, Optional\n",
        "\n",
        "from langchain_core.callbacks.manager import CallbackManagerForLLMRun\n",
        "from langchain_core.language_models.llms import LLM\n",
        "\n",
        "from langchain_core.tools import tool\n",
        "from langchain_core.output_parsers import JsonOutputParser\n",
        "from langchain.tools.render import render_text_description\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from operator import itemgetter\n",
        "\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.tools.render import format_tool_to_openai_function\n",
        "from langchain.agents.output_parsers import OpenAIFunctionsAgentOutputParser\n",
        "\n",
        "from langchain.agents.format_scratchpad import format_to_openai_functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "aa7406eb-334b-43d0-8110-31656a55b2fd",
      "metadata": {
        "id": "aa7406eb-334b-43d0-8110-31656a55b2fd"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from pydantic.v1 import BaseModel, Field\n",
        "import datetime\n",
        "\n",
        "# Define the input schema\n",
        "class OpenMeteoInput(BaseModel):\n",
        "    latitude: float = Field(..., description=\"Latitude of the location to fetch weather data for\")\n",
        "    longitude: float = Field(..., description=\"Longitude of the location to fetch weather data for\")\n",
        "\n",
        "@tool(args_schema=OpenMeteoInput)\n",
        "def get_current_temperature(latitude: float, longitude: float) -> dict:\n",
        "    \"\"\"Fetch current temperature for given coordinates.\"\"\"\n",
        "\n",
        "    BASE_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
        "\n",
        "    # Parameters for the request\n",
        "    params = {\n",
        "        'latitude': latitude,\n",
        "        'longitude': longitude,\n",
        "        'hourly': 'temperature_2m',\n",
        "        'forecast_days': 1,\n",
        "    }\n",
        "\n",
        "    # Make the request\n",
        "    response = requests.get(BASE_URL, params=params)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        results = response.json()\n",
        "    else:\n",
        "        raise Exception(f\"API Request failed with status code: {response.status_code}\")\n",
        "\n",
        "    current_utc_time = datetime.datetime.utcnow()\n",
        "    time_list = [datetime.datetime.fromisoformat(time_str.replace('Z', '+00:00')) for time_str in results['hourly']['time']]\n",
        "    temperature_list = results['hourly']['temperature_2m']\n",
        "\n",
        "    closest_time_index = min(range(len(time_list)), key=lambda i: abs(time_list[i] - current_utc_time))\n",
        "    current_temperature = temperature_list[closest_time_index]\n",
        "\n",
        "    return f'The current temperature is {current_temperature}°C'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "q7JcOoaFGpkX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q7JcOoaFGpkX",
        "outputId": "c179e4f5-7b42-4cf4-d823-f5f85c73bbc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wikipedia (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -qU wikipedia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "G00pDv_8GkQg",
      "metadata": {
        "id": "G00pDv_8GkQg"
      },
      "outputs": [],
      "source": [
        "import wikipedia\n",
        "\n",
        "@tool\n",
        "def search_wikipedia(query: str) -> str:\n",
        "    \"\"\"Run Wikipedia search and get page summaries.\"\"\"\n",
        "    page_titles = wikipedia.search(query)\n",
        "    summaries = []\n",
        "    for page_title in page_titles[: 3]:\n",
        "        try:\n",
        "            wiki_page =  wikipedia.page(title=page_title, auto_suggest=False)\n",
        "            summaries.append(f\"Page: {page_title}\\nSummary: {wiki_page.summary}\")\n",
        "        except (\n",
        "            self.wiki_client.exceptions.PageError,\n",
        "            self.wiki_client.exceptions.DisambiguationError,\n",
        "        ):\n",
        "            pass\n",
        "    if not summaries:\n",
        "        return \"No good Wikipedia Search Result was found\"\n",
        "    return \"\\n\\n\".join(summaries)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "zTq6EaKJ3AQa",
      "metadata": {
        "id": "zTq6EaKJ3AQa"
      },
      "outputs": [],
      "source": [
        "@tool\n",
        "def something_else(query: str) -> str:\n",
        "    \"\"\"This function can do whatever you would like once you fill it in \"\"\"\n",
        "    #print(type(query))\n",
        "    return query[::-1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4856d233-0916-4b97-8a7c-b494d5f2b8e0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4856d233-0916-4b97-8a7c-b494d5f2b8e0",
        "outputId": "51f82a3a-946b-4245-9909-cca4633f9817"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The function `format_tool_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.3.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ],
      "source": [
        "tools = [get_current_temperature, search_wikipedia]  #, something_else\n",
        "tool_map = {tool.name: tool for tool in tools}\n",
        "\n",
        "def tool_chain(dictionary, tool_map=tool_map):\n",
        "  chosen_tool = tool_map[dictionary[\"name\"]]\n",
        "  return itemgetter(\"arguments\") | chosen_tool\n",
        "\n",
        "functions = [format_tool_to_openai_function(f) for f in tools]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "id": "933ce7cb-099c-4f43-a548-b355a5b66511",
      "metadata": {
        "id": "933ce7cb-099c-4f43-a548-b355a5b66511"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"You are a helpful assistant with access to the functions, which you use if required.\"\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"user\", \"{input}\"),\n",
        "])\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "def ResponseParser(output):\n",
        "  # Regular expression to find the last pair of <function_call> and </function_call>\n",
        "  pattern = r'<function_call>(.*?)</function_call>'\n",
        "\n",
        "  # Using re.findall to find all matches\n",
        "  #string = output.return_values['output'] # if additionally using OpenAIFunctionsAgentOutputParser() #output.__dict__  dict_keys(['return_values', 'log', 'type'])\n",
        "  string = output.content # if not using OpenAIFunctionsAgentOutputParser()\n",
        "  matches = re.findall(pattern, string, re.DOTALL)\n",
        "\n",
        "  # Extracting the last match\n",
        "  if matches:\n",
        "      last_match = matches[-1]\n",
        "      #return json.loads(last_match.strip())\n",
        "      #output.additional_kwargs = {'function_call' : json.loads(last_match.strip())}\n",
        "      dictionary = json.loads(last_match.strip())\n",
        "      dictionary[\"arguments\"] = json.dumps(dictionary[\"arguments\"]) # It is done for openAI specs\n",
        "      output.additional_kwargs = {'function_call' : dictionary}\n",
        "      #output.content = ''\n",
        "      return output\n",
        "\n",
        "## chain = prompt | llm | ResponseParser | RunnablePassthrough.assign(output=tool_chain) ## or instead just do: | tool_chain\n",
        "chain = prompt | llm | ResponseParser | OpenAIFunctionsAgentOutputParser() #| RunnablePassthrough.assign(output=tool_chain) ## or instead just do: | tool_chain\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "cJU97pjyIt7t",
      "metadata": {
        "id": "cJU97pjyIt7t"
      },
      "outputs": [],
      "source": [
        "input = \"what is the weather in sf?\" #\"what does wikipedia say about Feyerabend\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "id": "4281a2d8-7884-40e0-b34d-09c39eecbb7a",
      "metadata": {
        "id": "4281a2d8-7884-40e0-b34d-09c39eecbb7a"
      },
      "outputs": [],
      "source": [
        "def templater(input: str, functions: list = functions):\n",
        "\n",
        "  input_template = f\"\"\"<bos><start_of_turn>system\n",
        "  You are a helpful assistant with access to the following functions.\n",
        "  Use them if required:\n",
        "  <tool>\n",
        "  {functions}\n",
        "  </tool>\n",
        "\n",
        "  To use these functions respond with:\n",
        "  <function_call> {{\"name\": \"function_name\", \"arguments\": {{\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", ...}}}} </function_call>\n",
        "\n",
        "  Contains properties essential for the model to respond according to the tasks:\n",
        "  <observation> {{\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", \"arg_3\": \"value_3\", ...}} </observation>\n",
        "\n",
        "  Edge cases you must handle:\n",
        "  - If there are no functions that match the user request, you will respond politely that you cannot help.\n",
        "  <end_of_turn>\n",
        "  <start_of_turn>user\n",
        "  {input}<end_of_turn>\n",
        "  <start_of_turn>function_call\n",
        "  \"\"\"\n",
        "  return input_template\n",
        "\n",
        "result = chain.invoke({\"input\": templater(input)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "id": "3H-AQh2Y0Hzm",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "3H-AQh2Y0Hzm",
        "outputId": "f028c8ce-aa47-4816-b0c8-913b8e275bfe"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<bos><start_of_turn>system\\n  You are a helpful assistant with access to the following functions.\\n  Use them if required:\\n  <tool>\\n  [{\\'name\\': \\'get_current_temperature\\', \\'description\\': \\'Fetch current temperature for given coordinates.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'latitude\\': {\\'description\\': \\'Latitude of the location to fetch weather data for\\', \\'type\\': \\'number\\'}, \\'longitude\\': {\\'description\\': \\'Longitude of the location to fetch weather data for\\', \\'type\\': \\'number\\'}}, \\'required\\': [\\'latitude\\', \\'longitude\\']}}, {\\'name\\': \\'search_wikipedia\\', \\'description\\': \\'Run Wikipedia search and get page summaries.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'query\\': {\\'type\\': \\'string\\'}}, \\'required\\': [\\'query\\']}}]\\n  </tool>\\n\\n  To use these functions respond with:\\n  <function_call> {\"name\": \"function_name\", \"arguments\": {\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", ...}} </function_call>\\n\\n  Contains properties essential for the model to respond according to the tasks:\\n  <observation> {\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", \"arg_3\": \"value_3\", ...} </observation>\\n\\n  Edge cases you must handle:\\n  - If there are no functions that match the user request, you will respond politely that you cannot help.\\n  <end_of_turn>\\n  <start_of_turn>user\\n  what is the weather in sf?<end_of_turn>\\n  <start_of_turn>function_call\\n  <function_call> {\"name\": \"get_current_temperature\", \"arguments\": {\"latitude\": 37.7833, \"longitude\": -122.4167}} </function_call><end_of_turn>'"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# result.__dict__.keys() without OpenAIFunctionsAgentOutputParser:\n",
        "# dict_keys(['content', 'additional_kwargs', 'response_metadata', 'type', 'name', 'id', 'example', 'tool_calls', 'invalid_tool_calls', 'usage_metadata'])\n",
        "result.__dict__.keys()  # with OpenAIFunctionsAgentOutputParser:   dict_keys(['tool', 'tool_input', 'log', 'type', 'message_log'])\n",
        "# result.message_log[0]  #dict_keys(['content', 'additional_kwargs', 'response_metadata', 'type', 'name', 'id', 'example', 'tool_calls', 'invalid_tool_calls', 'usage_metadata'])\n",
        "result.message_log[0].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "id": "BP9vr4x9mQWT",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "BP9vr4x9mQWT",
        "outputId": "a117631a-30f9-46b4-ba2b-8d76466f1d80"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<bos><start_of_turn>system\\n  You are a helpful assistant with access to the following functions.\\n  Use them if required:\\n  <tool>\\n  [{\\'name\\': \\'get_current_temperature\\', \\'description\\': \\'Fetch current temperature for given coordinates.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'latitude\\': {\\'description\\': \\'Latitude of the location to fetch weather data for\\', \\'type\\': \\'number\\'}, \\'longitude\\': {\\'description\\': \\'Longitude of the location to fetch weather data for\\', \\'type\\': \\'number\\'}}, \\'required\\': [\\'latitude\\', \\'longitude\\']}}, {\\'name\\': \\'search_wikipedia\\', \\'description\\': \\'Run Wikipedia search and get page summaries.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'query\\': {\\'type\\': \\'string\\'}}, \\'required\\': [\\'query\\']}}]\\n  </tool>\\n\\n  To use these functions respond with:\\n  <function_call> {\"name\": \"function_name\", \"arguments\": {\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", ...}} </function_call>\\n\\n  Contains properties essential for the model to respond according to the tasks:\\n  <observation> {\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", \"arg_3\": \"value_3\", ...} </observation>\\n\\n  Edge cases you must handle:\\n  - If there are no functions that match the user request, you will respond politely that you cannot help.\\n  <end_of_turn>\\n  '"
            ]
          },
          "execution_count": 62,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "latest_output = re.split(r'(<start_of_turn>user)', result.message_log[0].content)\n",
        "latest_output[0]\n",
        "if len(latest_output) > 2:\n",
        "    header = latest_output[0]\n",
        "    output = ''.join(latest_output[1:])\n",
        "header"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "id": "fV1mjAUynCze",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "fV1mjAUynCze",
        "outputId": "4e380cec-bdaa-4164-e374-cc03cb597f97"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<start_of_turn>user\\n  what is the weather in sf?<end_of_turn>\\n  <start_of_turn>function_call\\n  <function_call> {\"name\": \"get_current_temperature\", \"arguments\": {\"latitude\": 37.7833, \"longitude\": -122.4167}} </function_call><end_of_turn>'"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "id": "vG46BXlz8H01",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG46BXlz8H01",
        "outputId": "2a1ca7d1-b259-4462-cc8b-ee7f594baf18"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'function_call': {'name': 'get_current_temperature',\n",
              "  'arguments': '{\"latitude\": 37.7833, \"longitude\": -122.4167}'}}"
            ]
          },
          "execution_count": 64,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#dict_keys(['content', 'additional_kwargs', 'response_metadata', 'type', 'name', 'id', 'example', 'tool_calls', 'invalid_tool_calls', 'usage_metadata'])\n",
        "function_call = result.message_log[0].additional_kwargs\n",
        "function_call"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "id": "SmKIQe02DvXs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "SmKIQe02DvXs",
        "outputId": "82069b44-faae-4446-d670-f3469f4aaada"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hi'"
            ]
          },
          "execution_count": 65,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result.message_log[0].model_output = \"Hi\"  # there is no model_output by default but we can create it\n",
        "result.message_log[0].model_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "id": "NWSw9hwoonmS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "NWSw9hwoonmS",
        "outputId": "3c14d526-9a94-451d-b5bd-1fed36fa6953"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'The current temperature is 13.5°C'"
            ]
          },
          "execution_count": 66,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_output = tool_map[result.tool].run(result.tool_input)\n",
        "model_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "id": "rZwu67AqoaFj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rZwu67AqoaFj",
        "outputId": "db3e5ff0-cd69-490f-b135-593ac53a61cd"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "class Memory(BaseModel):\n",
        "  history: str = Field(default=\"\")\n",
        "  api_memory: List[dict] | list = Field(default=[])\n",
        "\n",
        "memory = Memory()\n",
        "memory.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "id": "LQX1SOrj4UuZ",
      "metadata": {
        "id": "LQX1SOrj4UuZ"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def splitter(result):\n",
        "  latest_output = re.split(r'(<start_of_turn>user)', result.message_log[0].content)\n",
        "  if len(latest_output) > 2:\n",
        "      header = latest_output[0]\n",
        "      output = ''.join(latest_output[1:])\n",
        "  return (header, output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "id": "8J9Ix9CizMBx",
      "metadata": {
        "id": "8J9Ix9CizMBx"
      },
      "outputs": [],
      "source": [
        "def agent(user_input, templater=templater, chain=chain, tool_map=tool_map,\n",
        "          memory=memory, splitter=splitter, max_symbols=20000):\n",
        "\n",
        "  #while True:\n",
        "    input = memory.history + user_input\n",
        "    result = chain.invoke({\"input\": templater(input)})\n",
        "    model_output = tool_map[result.tool].run(result.tool_input)\n",
        "    header, output = splitter(result)\n",
        "    memory.history += output + \" <start_of_turn>model\\n  \" + model_output + \"<end_of_turn>\\n\"\n",
        "\n",
        "    result.message_log[0].user_input = user_input\n",
        "    result.message_log[0].model_output = model_output\n",
        "\n",
        "    if len(memory.history) > max_symbols:\n",
        "      print(\"Maximal memory storage used\")\n",
        "      memory.history = ''\n",
        "      return #memory.history\n",
        "\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "id": "12AOkT7oNbnJ",
      "metadata": {
        "id": "12AOkT7oNbnJ"
      },
      "outputs": [],
      "source": [
        "def printer(result):\n",
        "  return print(f\"\"\"user input:\\n\\n{result.message_log[0].user_input}, \\n\\nused tool:\\n\\n{result.tool},\n",
        "          \\n\\nproposed data for the tool:\\n\\n{result.tool_input}, \\n\\nresult:\\n\\n {result.message_log[0].model_output}\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "id": "jcrN4io2_nAo",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jcrN4io2_nAo",
        "outputId": "33af0ed7-9d67-4696-b31e-0b0aefe5fae4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user input:\n",
            "\n",
            "what is the weather in sf?, \n",
            "\n",
            "used tool:\n",
            "\n",
            "get_current_temperature,\n",
            "          \n",
            "\n",
            "proposed data for the tool:\n",
            "\n",
            "{'latitude': 37.78, 'longitude': -122.42}, \n",
            "\n",
            "result:\n",
            "\n",
            " The current temperature is 13.6°C\n"
          ]
        }
      ],
      "source": [
        "input = \"what is the weather in sf?\" #\"what does wikipedia say about Feyerabend\"\n",
        "result1 = agent(input)\n",
        "\n",
        "printer(result1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "LTTBUAtjMj4X",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTTBUAtjMj4X",
        "outputId": "9f169829-deb8-4663-be54-d947a38ed09a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user input:\n",
            "\n",
            "what is the weather in Tbilisi?, \n",
            "\n",
            "used tool:\n",
            "\n",
            "get_current_temperature,\n",
            "          \n",
            "\n",
            "proposed data for the tool:\n",
            "\n",
            "{'latitude': 43.73, 'longitude': 43.65}, \n",
            "\n",
            "result:\n",
            "\n",
            " The current temperature is 34.2°C\n"
          ]
        }
      ],
      "source": [
        "input = \"what is the weather in Tbilisi?\"\n",
        "result2 = agent(input)\n",
        "\n",
        "printer(result2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "id": "ps4aoh9DdPjq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "ps4aoh9DdPjq",
        "outputId": "c81b7773-a47c-4221-eff7-f67bb8020320"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<bos><start_of_turn>system\\n  You are a helpful assistant with access to the following functions.\\n  Use them if required:\\n  <tool>\\n  [{\\'name\\': \\'get_current_temperature\\', \\'description\\': \\'Fetch current temperature for given coordinates.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'latitude\\': {\\'description\\': \\'Latitude of the location to fetch weather data for\\', \\'type\\': \\'number\\'}, \\'longitude\\': {\\'description\\': \\'Longitude of the location to fetch weather data for\\', \\'type\\': \\'number\\'}}, \\'required\\': [\\'latitude\\', \\'longitude\\']}}, {\\'name\\': \\'search_wikipedia\\', \\'description\\': \\'Run Wikipedia search and get page summaries.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'query\\': {\\'type\\': \\'string\\'}}, \\'required\\': [\\'query\\']}}]\\n  </tool>\\n\\n  To use these functions respond with:\\n  <function_call> {\"name\": \"function_name\", \"arguments\": {\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", ...}} </function_call>\\n\\n  Contains properties essential for the model to respond according to the tasks:\\n  <observation> {\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", \"arg_3\": \"value_3\", ...} </observation>\\n\\n  Edge cases you must handle:\\n  - If there are no functions that match the user request, you will respond politely that you cannot help.\\n  <end_of_turn>\\n  <start_of_turn>user\\n  <start_of_turn>user\\n  what is the weather in sf?<end_of_turn>\\n  <start_of_turn>function_call\\n  <function_call> {\"name\": \"get_current_temperature\", \"arguments\": {\"latitude\": 37.78, \"longitude\": -122.42}} </function_call><end_of_turn> <start_of_turn>model\\n  The current temperature is 13.6°C<end_of_turn>\\nwhat is the weather in Tbilisi?<end_of_turn>\\n  <start_of_turn>function_call\\n  <function_call> {\"name\": \"get_current_temperature\", \"arguments\": {\"latitude\": 43.73, \"longitude\": 43.65}} </function_call><end_of_turn>'"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<bos><start_of_turn>system\\n  You are a helpful assistant with access to the following functions.\\n  Use them if required:\\n  <tool>\\n  [{\\'name\\': \\'get_current_temperature\\', \\'description\\': \\'Fetch current temperature for given coordinates.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'latitude\\': {\\'description\\': \\'Latitude of the location to fetch weather data for\\', \\'type\\': \\'number\\'}, \\'longitude\\': {\\'description\\': \\'Longitude of the location to fetch weather data for\\', \\'type\\': \\'number\\'}}, \\'required\\': [\\'latitude\\', \\'longitude\\']}}, {\\'name\\': \\'search_wikipedia\\', \\'description\\': \\'Run Wikipedia search and get page summaries.\\', \\'parameters\\': {\\'type\\': \\'object\\', \\'properties\\': {\\'query\\': {\\'type\\': \\'string\\'}}, \\'required\\': [\\'query\\']}}]\\n  </tool>\\n\\n  To use these functions respond with:\\n  <function_call> {\"name\": \"function_name\", \"arguments\": {\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", ...}} </function_call>\\n\\n  Contains properties essential for the model to respond according to the tasks:\\n  <observation> {\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", \"arg_3\": \"value_3\", ...} </observation>\\n\\n  Edge cases you must handle:\\n  - If there are no functions that match the user request, you will respond politely that you cannot help.\\n  <end_of_turn>\\n  <start_of_turn>user\\n  <start_of_turn>user\\n  what is the weather in sf?<end_of_turn>\\n  <start_of_turn>function_call\\n  <function_call> {\"name\": \"get_current_temperature\", \"arguments\": {\"latitude\": 37.78, \"longitude\": -122.42}} </function_call><end_of_turn> <start_of_turn>model\\n  The current temperature is 13.6°C<end_of_turn>\\nwhat is the weather in Tbilisi?<end_of_turn>\\n  <start_of_turn>function_call\\n  <function_call> {\"name\": \"get_current_temperature\", \"arguments\": {\"latitude\": 43.73, \"longitude\": 43.65}} </function_call><end_of_turn>'"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "result2.message_log[0].content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "aC0to1ELoSVq",
      "metadata": {
        "id": "aC0to1ELoSVq"
      },
      "outputs": [],
      "source": [
        "class ChatState:\n",
        "  \"\"\"\n",
        "  \"\"\"\n",
        "  def __init__(self, tools=tools, chain=chain, memory = Memory(), max_symbols=20000):\n",
        "    self.tools = tools\n",
        "    self.functions = [format_tool_to_openai_function(f) for f in self.tools]\n",
        "    self.tool_map = {tool.name: tool for tool in self.tools}\n",
        "    self.chain = chain\n",
        "    self.memory = memory\n",
        "    self.max_symbols = max_symbols\n",
        "\n",
        "  def templater(self, input: str):\n",
        "    input_template = f\"\"\"<bos><start_of_turn>system\n",
        "    You are a helpful assistant with access to the following functions.\n",
        "    Use them if required:\n",
        "    <tool>\n",
        "    {self.functions}\n",
        "    </tool>\n",
        "\n",
        "    To use these functions respond with:\n",
        "    <function_call> {{\"name\": \"function_name\", \"arguments\": {{\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", ...}}}} </function_call>\n",
        "\n",
        "    Contains properties essential for the model to respond according to the tasks:\n",
        "    <observation> {{\"arg_1\": \"value_1\", \"arg_2\": \"value_2\", \"arg_3\": \"value_3\", ...}} </observation>\n",
        "\n",
        "    Edge cases you must handle:\n",
        "    - If there are no functions that match the user request, you will respond politely that you cannot help.\n",
        "    <end_of_turn>\n",
        "    <start_of_turn>user\n",
        "    {input}<end_of_turn>\n",
        "    <start_of_turn>function_call\n",
        "    \"\"\"\n",
        "    return input_template\n",
        "\n",
        "  def splitter(self):\n",
        "    latest_output = re.split(r'(<start_of_turn>user)', self.result.message_log[0].content)\n",
        "    if len(latest_output) > 2:\n",
        "        header = latest_output[0]\n",
        "        output = ''.join(latest_output[1:])\n",
        "    return (header, output)\n",
        "\n",
        "\n",
        "  def agent(self, user_input):\n",
        "\n",
        "      input = self.memory.history + user_input\n",
        "      self.result = self.chain.invoke({\"input\": self.templater(input)})\n",
        "      model_output = self.tool_map[self.result.tool].run(self.result.tool_input)\n",
        "      header, output = self.splitter()\n",
        "      self.memory.history += output + \" <start_of_turn>model\\n  \" + model_output + \"<end_of_turn>\\n\"\n",
        "\n",
        "      self.memory.api_memory.append({\"user\": user_input,\n",
        "                                     \"model\": model_output,\n",
        "                                     \"tool\": self.result.tool,\n",
        "                                     \"tool_input\": self.result.tool_input\n",
        "                                     })\n",
        "\n",
        "      if len(self.memory.history) > self.max_symbols:\n",
        "        #print(\"Maximal memory storage used\")\n",
        "        self.memory.history = ''\n",
        "        del self.result\n",
        "        return self.memory.api_memory\n",
        "\n",
        "      return self.memory.api_memory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "2Et9RIYDyaKB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Et9RIYDyaKB",
        "outputId": "6ee37eed-b467-491d-950a-60274f60b41e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'user': 'what is the weather in Tbilisi?',\n",
              "  'model': 'The current temperature is 36.3°C',\n",
              "  'tool': 'get_current_temperature',\n",
              "  'tool_input': {'latitude': 43.75, 'longitude': 44.45}}]"
            ]
          },
          "execution_count": 83,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chatstate = ChatState()\n",
        "\n",
        "input = \"what is the weather in Tbilisi?\"\n",
        "chatstate.agent(input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "YFZZGIB81Y8E",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFZZGIB81Y8E",
        "outputId": "de455ac6-e1a3-4814-e177-86992239e48d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'user': 'what is the weather in Tbilisi?',\n",
              "  'model': 'The current temperature is 36.3°C',\n",
              "  'tool': 'get_current_temperature',\n",
              "  'tool_input': {'latitude': 43.75, 'longitude': 44.45}},\n",
              " {'user': 'what does wikipedia say about Feyerabend',\n",
              "  'model': 'Page: Paul Feyerabend\\nSummary: Paul Karl Feyerabend (German: [ˈfaɪɐˌʔaːbm̩t]; January 13, 1924 – February 11, 1994) was an Austrian philosopher best known for his work in the philosophy of science. He started his academic career as lecturer in the philosophy of science at the University of Bristol (1955–1958); afterwards, he moved to the University of California, Berkeley, where he taught for three decades (1958–1989). At various points in his life, he held joint appointments at the University College London (1967–1970), the London School of Economics (1967), the FU Berlin (1968), Yale University (1969), the University of Auckland (1972, 1975), the University of Sussex (1974), and, finally, the ETH Zurich (1980–1990). He gave lectures and lecture series at the University of Minnesota (1958-1962), Stanford University (1967), the University of Kassel (1977) and the University of Trento (1992).\\nFeyerabend\\'s most famous work is Against Method (1975), wherein he argued that there are no universally valid methodological rules for scientific inquiry. He also wrote on topics related to the politics of science in several essays and in his book Science in a Free Society (1978). Feyerabend\\'s later works include Wissenschaft als Kunst (Science as Art) (1984), Farewell to Reason (1987), Three Dialogues on Knowledge (1991), and Conquest of Abundance (released posthumously in 1999) which collect essays from the 1970s until Feyerabend\\'s death in 1994. The uncompleted draft of an earlier work was released posthumously, in 2009, as Naturphilosophie (English translation of 2016 Philosophy of Nature). This work contains Feyerabend\\'s reconstruction of the history of natural philosophy from the Homeric Period until the mid-20th century. In these works and other publications, Feyerabend wrote about numerous issues at the interface between history and philosophy of science and ethics, ancient philosophy, philosophy of art, political philosophy, medicine, and physics. Feyerabend\\'s final work was his autobiography, entitled Killing Time, which he completed on his deathbed. Feyerabend\\'s extensive correspondence and other materials from his Nachlass continue to be published.\\nPaul Feyerabend is recognized as one of the most important philosophers of science of the 20th century. In a 2010 poll, he was ranked as the 8th most significant philosopher of science. He is often mentioned alongside Thomas Kuhn, Imre Lakatos, and N.R. Hanson as a crucial figure in the historical turn in philosophy of science, and his work on scientific pluralism has been markedly influential on the Stanford School and on much contemporary philosophy of science. Feyerabend was also a significant figure in the sociology of scientific knowledge. His lectures were extremely well-attended, attracting international attention.  His multifaceted personality is eloquently summarized in his obituary by Ian Hacking: \"Humanists, in my old-fashioned sense, need to be part of both arts and sciences. Paul Feyerabend was a humanist. He was also fun.\"\\nIn line with this humanistic interpretation and the concerns apparent in his later work, the Paul K. Feyerabend Foundation was founded in 2006 in his honor. The Foundation \"...promotes the empowerment and wellbeing of disadvantaged human communities. By strengthening intra and inter-community solidarity, it strives to improve local capacities, promote the respect of human rights, and sustain cultural and biological diversity.\"  In 1970, the Loyola University of Chicago assigned to Feyerabend its Doctor of Humane Letters Degree honoris causa. Asteroid (22356) Feyerabend is named after him.\\n\\nPage: Feyerabend\\nSummary: Feyerabend is a German surname. Notable people with the surname include:\\n\\nGerhard Feyerabend (1898–1965), German WWII general in the Wehrmacht\\nHenry Feyerabend (1931–2006), Canadian Adventist evangelist, singer, and author\\nMarkus Feyerabend (born 1971), German glider aerobatic pilot\\nPaul Feyerabend (1924–1994), Austrian philosopher of science\\nSigmund Feyerabend (1528–1590), German printer\\n\\nPage: Gerhard Feyerabend\\nSummary: Gerhard Feyerabend (29 April 1898 – 6 November 1965) was a German general in the Wehrmacht of Nazi Germany during World War II who commanded several divisions. He was a recipient of the Knight\\'s Cross of the Iron Cross. Feyerabend surrendered to the Soviet forces in the Courland Pocket; he was released in 1947.',\n",
              "  'tool': 'search_wikipedia',\n",
              "  'tool_input': {'query': ' Feyerabend'}}]"
            ]
          },
          "execution_count": 84,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chatstate.agent(\"what does wikipedia say about Feyerabend\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ykM68fbX2QfR",
      "metadata": {
        "id": "ykM68fbX2QfR"
      },
      "source": [
        "LangChain team introduced functional conversation tutorial with OpenAI at deeplearning.ai [see here](https://www.deeplearning.ai/short-courses/functions-tools-agents-langchain/). \n",
        "\n",
        "That same tutorial with useful explanations can be found [here](https://teetracker.medium.com/building-an-agent-from-scratch-with-langchain-2e1d1ef2f57f)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "OE63E1gb_C1V",
        "b-AFoFHwdj7g"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0290fa7a2fe24bdaab6e470bbc55163a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0662b61903f642118339d935fe96600c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0933c0b2905747e0b9b771942f903c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1432456dbac149bf9199cdfd99788fd9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "235dd00d5aff4fdb88047d3d2a7f6ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "241a9d2ca1e4472b929aad632701643a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e8e37a3d4394729bfc70886c9f69702",
            "placeholder": "​",
            "style": "IPY_MODEL_709954020b544744bb742be40bf78711",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "28040d4a229c4c9d8ef8dce1088bce47": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2ee310f0d77244dabf75b41ade9473f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2eee47b4d0474034b2e8309902475eea": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a04743b9c5974046841a13e2a8b1dc03",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0662b61903f642118339d935fe96600c",
            "value": 2
          }
        },
        "3424c8f510b3492fabf055a8894c484f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3938de22cac449068a1d00637019cbb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4171cc45da1247a4a45bac0d31448d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "426510d855534f6d81d934a709a63aff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b39c2bc74eba4ed7ae5171ff9533fbc3",
            "max": 4241003,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2ee310f0d77244dabf75b41ade9473f5",
            "value": 4241003
          }
        },
        "4979ec6811734a9bb6970dddd2f9984f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c020b6eea634d68866f4956b472e354": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1432456dbac149bf9199cdfd99788fd9",
            "max": 17518497,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b87cf4fd1f504787a69929be42f0d45a",
            "value": 17518497
          }
        },
        "4ea7ce1455474e0b8ea4caf1d80ff332": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5432d95694aa477da6463ae357b4d033": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e952ce43976401f8e830d67fc55e1f5",
            "placeholder": "​",
            "style": "IPY_MODEL_9dc4cf1bbbec43a384a461b25ad140b5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "54464083b17e4893abddcec08268fba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83c5da0792474524a00d2d64ea323078",
            "placeholder": "​",
            "style": "IPY_MODEL_aa69d6e295aa4192a0c98c12e7910f14",
            "value": "tokenizer.json: 100%"
          }
        },
        "5d3311d7545349e593a755e9e0fec8d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_845915b167f04f54b3572f5487ecc55c",
            "max": 34173,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a3d56b972a4940338e03ce528280adb7",
            "value": 34173
          }
        },
        "5ffa4cca3b5f4067845d3beee221ef85": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_65f4a5cf9ffb4e82abfa42119f679111",
              "IPY_MODEL_426510d855534f6d81d934a709a63aff",
              "IPY_MODEL_9a779fe6d32b40cc906a72b835adb58c"
            ],
            "layout": "IPY_MODEL_656bf197ad1e4d0ab754195ce2018844"
          }
        },
        "656bf197ad1e4d0ab754195ce2018844": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "65f4a5cf9ffb4e82abfa42119f679111": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c91de0df3eec4b43a051b3fc554a7497",
            "placeholder": "​",
            "style": "IPY_MODEL_fc4b4ac0d0924f179551a880e0c2bc8c",
            "value": "tokenizer.model: 100%"
          }
        },
        "66aaf69fac98449f950a7320108d0a51": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9761496178f94730b236bba528226c8d",
            "placeholder": "​",
            "style": "IPY_MODEL_3938de22cac449068a1d00637019cbb9",
            "value": " 34.2k/34.2k [00:00&lt;00:00, 2.18MB/s]"
          }
        },
        "709954020b544744bb742be40bf78711": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "75510d21c9c34740ba8fcafce1b4394d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e38ffe259d40d1aff135fd9ac8371b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e8e37a3d4394729bfc70886c9f69702": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83c5da0792474524a00d2d64ea323078": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "845915b167f04f54b3572f5487ecc55c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86db5583690b4a02b099cf96d42ac174": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4979ec6811734a9bb6970dddd2f9984f",
            "placeholder": "​",
            "style": "IPY_MODEL_78e38ffe259d40d1aff135fd9ac8371b",
            "value": " 636/636 [00:00&lt;00:00, 48.4kB/s]"
          }
        },
        "88ac7b5630ab40dab061912f7308310d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af92b247fda54b159b0a28a5f24d2fcf",
            "placeholder": "​",
            "style": "IPY_MODEL_3424c8f510b3492fabf055a8894c484f",
            "value": " 2/2 [01:40&lt;00:00, 42.26s/it]"
          }
        },
        "919194c2af574adb881843370ee6f20b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "93c2547bcada4dd684cb3eb29a6b50ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cfbb42006293437984dd6aa357a1cd0c",
            "placeholder": "​",
            "style": "IPY_MODEL_919194c2af574adb881843370ee6f20b",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "9761496178f94730b236bba528226c8d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a779fe6d32b40cc906a72b835adb58c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0933c0b2905747e0b9b771942f903c2f",
            "placeholder": "​",
            "style": "IPY_MODEL_4171cc45da1247a4a45bac0d31448d58",
            "value": " 4.24M/4.24M [00:00&lt;00:00, 40.9MB/s]"
          }
        },
        "9dc4cf1bbbec43a384a461b25ad140b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9e952ce43976401f8e830d67fc55e1f5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a04743b9c5974046841a13e2a8b1dc03": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a24b1e19036f4523b113f4f8ae881636": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5432d95694aa477da6463ae357b4d033",
              "IPY_MODEL_5d3311d7545349e593a755e9e0fec8d4",
              "IPY_MODEL_66aaf69fac98449f950a7320108d0a51"
            ],
            "layout": "IPY_MODEL_28040d4a229c4c9d8ef8dce1088bce47"
          }
        },
        "a3d56b972a4940338e03ce528280adb7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a45bf42393224c21a884289a51add9e3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa69d6e295aa4192a0c98c12e7910f14": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af92b247fda54b159b0a28a5f24d2fcf": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b39c2bc74eba4ed7ae5171ff9533fbc3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5ec91fc973148c78e645f7feb743c6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0290fa7a2fe24bdaab6e470bbc55163a",
            "max": 636,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_cd6c738d0efb4112868590fa5d9bf5d3",
            "value": 636
          }
        },
        "b87cf4fd1f504787a69929be42f0d45a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c91de0df3eec4b43a051b3fc554a7497": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6c738d0efb4112868590fa5d9bf5d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "cfbb42006293437984dd6aa357a1cd0c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6199a631df34aaa949ef70847da87eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_93c2547bcada4dd684cb3eb29a6b50ab",
              "IPY_MODEL_2eee47b4d0474034b2e8309902475eea",
              "IPY_MODEL_88ac7b5630ab40dab061912f7308310d"
            ],
            "layout": "IPY_MODEL_f1823978509b48ba9bc40fd0c973055a"
          }
        },
        "e9ecdbafc1b9403982ba2e33bc933126": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_235dd00d5aff4fdb88047d3d2a7f6ab7",
            "placeholder": "​",
            "style": "IPY_MODEL_4ea7ce1455474e0b8ea4caf1d80ff332",
            "value": " 17.5M/17.5M [00:00&lt;00:00, 134MB/s]"
          }
        },
        "ecdda8c95f3542da8d70eca4ba77c75b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_241a9d2ca1e4472b929aad632701643a",
              "IPY_MODEL_b5ec91fc973148c78e645f7feb743c6e",
              "IPY_MODEL_86db5583690b4a02b099cf96d42ac174"
            ],
            "layout": "IPY_MODEL_a45bf42393224c21a884289a51add9e3"
          }
        },
        "f1823978509b48ba9bc40fd0c973055a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5477c5669654acc84ed095c511be908": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54464083b17e4893abddcec08268fba8",
              "IPY_MODEL_4c020b6eea634d68866f4956b472e354",
              "IPY_MODEL_e9ecdbafc1b9403982ba2e33bc933126"
            ],
            "layout": "IPY_MODEL_75510d21c9c34740ba8fcafce1b4394d"
          }
        },
        "fc4b4ac0d0924f179551a880e0c2bc8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
